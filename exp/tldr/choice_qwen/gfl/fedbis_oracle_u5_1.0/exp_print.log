2025-10-10 04:17:43 (root:426) INFO: [logger] file handler -> exp/tldr/choice_qwen/gfl/fedbis_oracle_u5_1.0/exp_print.log
2025-10-10 04:17:43 (root:51) INFO: [main] outdir=exp/tldr/choice_qwen/gfl/fedbis_oracle_u5_1.0
2025-10-10 04:18:06 (federatedscope.core.data.base_translator:234) INFO: Main process: Completion file found. Skipping generation.
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:264) INFO: [Final Split Summary][loaded][server=0][rank=0/4] Train=92858, Val=33082, Test=50715, Total=176655
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=1][rank=0/4] Train=2793, Val=146, Test=40, Total=2979
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=2][rank=0/4] Train=214, Val=11, Test=40, Total=265
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=3][rank=0/4] Train=691, Val=36, Test=40, Total=767
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=4][rank=0/4] Train=213, Val=11, Test=40, Total=264
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=5][rank=0/4] Train=285, Val=14, Test=40, Total=339
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=6][rank=0/4] Train=2547, Val=134, Test=40, Total=2721
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=7][rank=0/4] Train=1088, Val=57, Test=40, Total=1185
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=8][rank=0/4] Train=1316, Val=69, Test=40, Total=1425
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=9][rank=0/4] Train=3572, Val=188, Test=40, Total=3800
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=10][rank=0/4] Train=1209, Val=63, Test=40, Total=1312
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=11][rank=0/4] Train=621, Val=32, Test=40, Total=693
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=12][rank=0/4] Train=2605, Val=137, Test=40, Total=2782
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=13][rank=0/4] Train=1372, Val=72, Test=40, Total=1484
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=14][rank=0/4] Train=3055, Val=160, Test=40, Total=3255
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=15][rank=0/4] Train=14550, Val=200, Test=40, Total=14790
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=16][rank=0/4] Train=2589, Val=136, Test=40, Total=2765
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=17][rank=0/4] Train=5883, Val=200, Test=40, Total=6123
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=18][rank=0/4] Train=2576, Val=135, Test=40, Total=2751
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=19][rank=0/4] Train=2102, Val=110, Test=40, Total=2252
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=20][rank=0/4] Train=2399, Val=126, Test=40, Total=2565
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=21][rank=0/4] Train=2915, Val=153, Test=40, Total=3108
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=22][rank=0/4] Train=224, Val=11, Test=40, Total=275
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=23][rank=0/4] Train=583, Val=30, Test=40, Total=653
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=24][rank=0/4] Train=4944, Val=200, Test=40, Total=5184
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=25][rank=0/4] Train=4647, Val=200, Test=40, Total=4887
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=26][rank=0/4] Train=3063, Val=161, Test=40, Total=3264
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=27][rank=0/4] Train=2342, Val=123, Test=40, Total=2505
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=28][rank=0/4] Train=1434, Val=75, Test=40, Total=1549
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=29][rank=0/4] Train=6191, Val=200, Test=40, Total=6431
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=30][rank=0/4] Train=3247, Val=170, Test=40, Total=3457
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=31][rank=0/4] Train=3679, Val=193, Test=40, Total=3912
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=32][rank=0/4] Train=2144, Val=112, Test=40, Total=2296
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=33][rank=0/4] Train=1409, Val=74, Test=40, Total=1523
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=34][rank=0/4] Train=4486, Val=200, Test=40, Total=4726
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=35][rank=0/4] Train=4736, Val=200, Test=40, Total=4976
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=36][rank=0/4] Train=1030, Val=54, Test=40, Total=1124
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=37][rank=0/4] Train=4273, Val=200, Test=40, Total=4513
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=38][rank=0/4] Train=6171, Val=200, Test=40, Total=6411
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=39][rank=0/4] Train=1594, Val=83, Test=40, Total=1717
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=40][rank=0/4] Train=4005, Val=200, Test=40, Total=4245
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=41][rank=0/4] Train=2275, Val=119, Test=40, Total=2434
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=42][rank=0/4] Train=5772, Val=200, Test=40, Total=6012
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=43][rank=0/4] Train=1694, Val=89, Test=40, Total=1823
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=44][rank=0/4] Train=7916, Val=200, Test=40, Total=8156
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=45][rank=0/4] Train=1901, Val=100, Test=40, Total=2041
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=46][rank=0/4] Train=2100, Val=110, Test=40, Total=2250
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=47][rank=0/4] Train=2812, Val=147, Test=40, Total=2999
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=48][rank=0/4] Train=880, Val=46, Test=40, Total=966
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=49][rank=0/4] Train=2521, Val=132, Test=40, Total=2693
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=50][rank=0/4] Train=2527, Val=133, Test=40, Total=2700
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=51][rank=0/4] Train=1580, Val=83, Test=40, Total=1703
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=52][rank=0/4] Train=3589, Val=188, Test=40, Total=3817
2025-10-10 04:18:48 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=53][rank=0/4] Train=6791, Val=200, Test=40, Total=7031
2025-10-10 04:18:49 (federatedscope.core.configs.config:256) INFO: the used configs are: 
adapter:
  use: False
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  load_splits: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  save_splits: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.9, 0.09, 0.01]
  splits_path: ./final_data_splits
  splitter: meta
  splitter_args: []
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: reddit-tldr-comparison-choice@llm
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 2
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 0
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: False
  freq: 500
  metrics: ['loss', 'acc']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['val', 'test']
expname: 
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_idx_for_local_train: 0
  client_num: 53
  data_weighted_aggr: False
  ignore_weight: True
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 5
  sample_client_rate: -1.0
  sampler: cluster
  save_client_model: False
  save_freq: 100
  save_to: checkpoints_1.0_oracle/tldr_choice_qwen_fedbis_oracle_u5.ckpt
  share_local_model: True
  total_round_num: 210
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  use: False
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: -1.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
llm:
  accelerator:
    config: 
    use: True
  adapter:
    args: [{'adapter_package': 'peft', 'adapter_method': 'lora', 'r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']}]
    balance: True
    boundaries: []
    cluster_runtime: {'schedule_file': 'exp/tldr/choice_qwen/gfl/fedbis_oracle_u5_1.0/cluster_schedule/cluster_schedule_u5.json'}
    clusters: [[2, 8, 11], [1, 6, 15, 16, 20, 22, 26, 28, 29, 34, 40, 43, 45, 47, 48, 51], [3, 5, 21, 31, 32, 36, 37, 41, 50], [4, 24, 25, 27, 30, 33, 42, 44], [7, 9, 10, 12, 13, 14, 17, 18, 19, 23, 35, 38, 39, 46, 49, 52, 53]]
    clusters_file: fedbiscuit_script/tldr/clusters_u5_53.json
    count: 5
    grouping:
      round: 50
      use: False
    local_only: False
    mv_to_cpu: False
    per_client_target: 18.867924528301888
    round_budget: 200
    round_ends: [19, 80, 114, 145, 210]
    round_physical: []
    sample_num_per_adapter: [3, 5, 5, 5, 5]
    target_per_round: 5
    use: True
    warmup:
      round: 0
      use: True
  cache:
    model: 
  chat:
    max_history_len: 10
    max_len: 1024
  deepspeed:
    ds_config: 
    use: False
  fedrlhf:
    config_file: 
    frequency: 100
    pretrained: False
    train:
      batch_or_epoch: batch
      local_update_steps: 10
    use: False
  grad_accum_step: 2
  max_new_token: 60
  num_completions: 2
  offsite_tuning:
    emu_align:
      data:
        root: data
        splits: [0.8, 0.1, 0.1]
        type: alpaca@llm
      exit_after_align: False
      init_enable_ground_truth: False
      initial_only: True
      kl_divergence: raw
      layerwise_distill: False
      restore_from: 
      save_to: 
      sim_loss: l2
      train:
        batch_or_epoch: batch
        enable_ground_truth: False
        initial_update_rounds: 50
        kd_loss_weight: 0.9
        lm_loss_weight: 0.1
        local_update_steps: 10
        optimizer:
          lr: 0.01
          type: SGD
      use: False
    emu_l: 1
    emu_r: 10
    eval_type: emu
    kwargs: [{}]
    llm_generated:
      ratio: 0.1
      use: False
    save_full_model: False
    strategy: drop_layer
    use: False
  retry_on_nan_loss: False
  reward_coeff: 0.1
  rlhf: False
  tok_len: 1024
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  llm_kwargs: [{}]
  llm_type: CausalLM
  load_from_local_pretrained_fs_config: 
  load_from_local_pretrained_model_path: 
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 1
  pretrain_tasks: []
  stage: 
  task: node
  type: Qwen/Qwen2-0.5B@huggingface_llm
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp/tldr/choice_qwen/gfl/fedbis_oracle_u5_1.0
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 30
  lr: 1e-05
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.0
  type: 
seed: 0
sgdmf:
  use: False
train:
  batch_or_epoch: batch
  data_para_dids: []
  is_enable_half: True
  local_update_steps: 30
  optimizer:
    betas: (0.9, 0.95)
    lr: 1e-05
    type: AdamW
  scheduler:
    gamma: 1.0
    milestones: [75, 125]
    type: 
    warmup_ratio: 0.0
trainer:
  choices: ['A', 'B']
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: llmrewardchoicetrainer
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-10-10 04:18:50 (federatedscope.core.auxiliaries.utils:175) INFO: The device information file is not provided
2025-10-10 04:18:50 (federatedscope.core.auxiliaries.model_builder:139) WARNING: The input shape is None. Please specify the `data.input_shape`(a tuple) or give the representative data to `get_model` if necessary
2025-10-10 04:19:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-build][rank=0] tok_len=151643 | base=Qwen2ForCausalLM | in_emb=(Embedding) num=151646 ptr=140258120622144 | out_emb=(Linear) num=151646 ptr=140258120622144 | lora_ptr=None
2025-10-10 04:19:06 (federatedscope.core.fed_runner:211) INFO: Server has been set up ... 
2025-10-10 04:19:07 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:10 (federatedscope.core.fed_runner:275) INFO: Client 1 has been set up ... 
2025-10-10 04:19:10 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:12 (federatedscope.core.fed_runner:275) INFO: Client 2 has been set up ... 
2025-10-10 04:19:12 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:15 (federatedscope.core.fed_runner:275) INFO: Client 3 has been set up ... 
2025-10-10 04:19:15 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:18 (federatedscope.core.fed_runner:275) INFO: Client 4 has been set up ... 
2025-10-10 04:19:18 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:20 (federatedscope.core.fed_runner:275) INFO: Client 5 has been set up ... 
2025-10-10 04:19:20 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:23 (federatedscope.core.fed_runner:275) INFO: Client 6 has been set up ... 
2025-10-10 04:19:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:26 (federatedscope.core.fed_runner:275) INFO: Client 7 has been set up ... 
2025-10-10 04:19:26 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:28 (federatedscope.core.fed_runner:275) INFO: Client 8 has been set up ... 
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:31 (federatedscope.core.fed_runner:275) INFO: Client 9 has been set up ... 
2025-10-10 04:19:31 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:33 (federatedscope.core.fed_runner:275) INFO: Client 10 has been set up ... 
2025-10-10 04:19:34 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:36 (federatedscope.core.fed_runner:275) INFO: Client 11 has been set up ... 
2025-10-10 04:19:36 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:39 (federatedscope.core.fed_runner:275) INFO: Client 12 has been set up ... 
2025-10-10 04:19:39 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:42 (federatedscope.core.fed_runner:275) INFO: Client 13 has been set up ... 
2025-10-10 04:19:43 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:45 (federatedscope.core.fed_runner:275) INFO: Client 14 has been set up ... 
2025-10-10 04:19:45 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:48 (federatedscope.core.fed_runner:275) INFO: Client 15 has been set up ... 
2025-10-10 04:19:48 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:50 (federatedscope.core.fed_runner:275) INFO: Client 16 has been set up ... 
2025-10-10 04:19:50 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:53 (federatedscope.core.fed_runner:275) INFO: Client 17 has been set up ... 
2025-10-10 04:19:53 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:55 (federatedscope.core.fed_runner:275) INFO: Client 18 has been set up ... 
2025-10-10 04:19:56 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:19:58 (federatedscope.core.fed_runner:275) INFO: Client 19 has been set up ... 
2025-10-10 04:19:58 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:01 (federatedscope.core.fed_runner:275) INFO: Client 20 has been set up ... 
2025-10-10 04:20:01 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:03 (federatedscope.core.fed_runner:275) INFO: Client 21 has been set up ... 
2025-10-10 04:20:03 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:06 (federatedscope.core.fed_runner:275) INFO: Client 22 has been set up ... 
2025-10-10 04:20:06 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:08 (federatedscope.core.fed_runner:275) INFO: Client 23 has been set up ... 
2025-10-10 04:20:09 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:11 (federatedscope.core.fed_runner:275) INFO: Client 24 has been set up ... 
2025-10-10 04:20:11 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:14 (federatedscope.core.fed_runner:275) INFO: Client 25 has been set up ... 
2025-10-10 04:20:14 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:16 (federatedscope.core.fed_runner:275) INFO: Client 26 has been set up ... 
2025-10-10 04:20:16 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:20 (federatedscope.core.fed_runner:275) INFO: Client 27 has been set up ... 
2025-10-10 04:20:20 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:22 (federatedscope.core.fed_runner:275) INFO: Client 28 has been set up ... 
2025-10-10 04:20:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:25 (federatedscope.core.fed_runner:275) INFO: Client 29 has been set up ... 
2025-10-10 04:20:25 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:28 (federatedscope.core.fed_runner:275) INFO: Client 30 has been set up ... 
2025-10-10 04:20:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:30 (federatedscope.core.fed_runner:275) INFO: Client 31 has been set up ... 
2025-10-10 04:20:30 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:33 (federatedscope.core.fed_runner:275) INFO: Client 32 has been set up ... 
2025-10-10 04:20:33 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:35 (federatedscope.core.fed_runner:275) INFO: Client 33 has been set up ... 
2025-10-10 04:20:35 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:38 (federatedscope.core.fed_runner:275) INFO: Client 34 has been set up ... 
2025-10-10 04:20:38 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:41 (federatedscope.core.fed_runner:275) INFO: Client 35 has been set up ... 
2025-10-10 04:20:41 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:43 (federatedscope.core.fed_runner:275) INFO: Client 36 has been set up ... 
2025-10-10 04:20:43 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:46 (federatedscope.core.fed_runner:275) INFO: Client 37 has been set up ... 
2025-10-10 04:20:46 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:48 (federatedscope.core.fed_runner:275) INFO: Client 38 has been set up ... 
2025-10-10 04:20:48 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:51 (federatedscope.core.fed_runner:275) INFO: Client 39 has been set up ... 
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:54 (federatedscope.core.fed_runner:275) INFO: Client 40 has been set up ... 
2025-10-10 04:20:55 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:57 (federatedscope.core.fed_runner:275) INFO: Client 41 has been set up ... 
2025-10-10 04:20:57 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:20:59 (federatedscope.core.fed_runner:275) INFO: Client 42 has been set up ... 
2025-10-10 04:21:00 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:02 (federatedscope.core.fed_runner:275) INFO: Client 43 has been set up ... 
2025-10-10 04:21:02 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:05 (federatedscope.core.fed_runner:275) INFO: Client 44 has been set up ... 
2025-10-10 04:21:05 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:07 (federatedscope.core.fed_runner:275) INFO: Client 45 has been set up ... 
2025-10-10 04:21:08 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:10 (federatedscope.core.fed_runner:275) INFO: Client 46 has been set up ... 
2025-10-10 04:21:10 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:13 (federatedscope.core.fed_runner:275) INFO: Client 47 has been set up ... 
2025-10-10 04:21:13 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:15 (federatedscope.core.fed_runner:275) INFO: Client 48 has been set up ... 
2025-10-10 04:21:15 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:18 (federatedscope.core.fed_runner:275) INFO: Client 49 has been set up ... 
2025-10-10 04:21:18 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:20 (federatedscope.core.fed_runner:275) INFO: Client 50 has been set up ... 
2025-10-10 04:21:21 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:23 (federatedscope.core.fed_runner:275) INFO: Client 51 has been set up ... 
2025-10-10 04:21:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:26 (federatedscope.core.fed_runner:275) INFO: Client 52 has been set up ... 
2025-10-10 04:21:26 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-10 04:21:28 (federatedscope.core.fed_runner:275) INFO: Client 53 has been set up ... 
2025-10-10 04:21:28 (federatedscope.core.trainers.trainer:569) INFO: Model meta-info: <class 'federatedscope.llm.model.adapter_builder.AdapterModel'>.
2025-10-10 04:21:30 (federatedscope.core.trainers.trainer:584) INFO: Num of original para names: 2016.
2025-10-10 04:21:30 (federatedscope.core.trainers.trainer:585) INFO: Num of original trainable para names: 2306.
2025-10-10 04:21:30 (federatedscope.core.trainers.trainer:587) INFO: Num of preserved para names in local update: 2016. 
Preserved para names in local update: {'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_4.weight'}.
2025-10-10 04:21:30 (federatedscope.core.trainers.trainer:591) INFO: Num of filtered para names in local update: 0. 
Filtered para names in local update: set().
2025-10-10 04:21:30 (federatedscope.core.trainers.trainer:599) INFO: After register default hooks,
	the hooks_in_train is:
	{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init",
	    "_hook_on_fit_start_calculate_model_size"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward",
	    "_hook_on_batch_forward_regularizer",
	    "_hook_on_batch_forward_flop_count"
	  ],
	  "on_batch_backward": [
	    "_hook_on_batch_backward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	};
	the hooks_in_eval is:
            t{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	}
2025-10-10 04:21:30 (federatedscope.llm.llm_local.server:200) INFO: Waited all clients join, start now...
2025-10-10 04:21:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=0 aidx=0 | s=3 (candidates=3)
2025-10-10 04:21:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:21:30 (federatedscope.llm.llm_local.server:217) INFO: ----------- Starting training (Round #0) -------------
2025-10-10 04:21:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:21:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:21:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-10 04:21:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:21:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140258120622144 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:21:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:21:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:21:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:21:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:22:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:22:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.507202, avg_loss=0.715640, seen=480, correct=245, accuracy=0.510417
2025-10-10 04:22:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:22:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:22:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2152MB allocated=1810MB
2025-10-10 04:22:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.73548412322998, 'train_avg_loss': 0.6894623676935832, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:22:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 04:22:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 04:22:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:22:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:22:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:23:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:23:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.818420, avg_loss=0.728788, seen=480, correct=239, accuracy=0.497917
2025-10-10 04:23:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:23:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:23:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2102MB allocated=1818MB
2025-10-10 04:23:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.20781219005585, 'train_avg_loss': 0.7350651015837987, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:23:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 04:23:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 04:23:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:23:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:23:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:23:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:23:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.106598, avg_loss=0.716889, seen=480, correct=247, accuracy=0.514583
2025-10-10 04:23:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:23:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:23:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2132MB allocated=1827MB
2025-10-10 04:23:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35116511583328, 'train_avg_loss': 0.7112597092986107, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 04:23:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:23:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:23:41 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #1) -------------
2025-10-10 04:23:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=1 aidx=0 | s=3 (candidates=3)
2025-10-10 04:23:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-10 04:23:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:23:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:23:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:24:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:24:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.385162, avg_loss=0.700802, seen=480, correct=244, accuracy=0.508333
2025-10-10 04:24:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:24:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:24:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:24:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2108MB allocated=1836MB
2025-10-10 04:24:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.13114798069, 'train_avg_loss': 0.69275956650575, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:24:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:24:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:24:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:24:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:24:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-10 04:24:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:24:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:24:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:24:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:24:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:24:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:25:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:25:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.703796, avg_loss=0.688966, seen=480, correct=267, accuracy=0.556250
2025-10-10 04:25:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:25:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:25:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2134MB allocated=1836MB
2025-10-10 04:25:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5049124956131, 'train_avg_loss': 0.6708742707967759, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:25:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:25:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:25:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:25:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:25:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:25:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:25:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.041077, avg_loss=0.712586, seen=480, correct=220, accuracy=0.458333
2025-10-10 04:25:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:25:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:25:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2108MB allocated=1836MB
2025-10-10 04:25:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.07169830799103, 'train_avg_loss': 0.7339308192332585, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 04:25:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-10 04:25:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-10 04:25:48 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #2) -------------
2025-10-10 04:25:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=2 aidx=0 | s=3 (candidates=3)
2025-10-10 04:25:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-10 04:25:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:25:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:25:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:26:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:26:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.687683, avg_loss=0.688933, seen=480, correct=267, accuracy=0.556250
2025-10-10 04:26:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:26:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:26:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:26:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2118MB allocated=1794MB
2025-10-10 04:26:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.57040596008301, 'train_avg_loss': 0.6797533830006918, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:26:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:26:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:26:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:26:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:27:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:27:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.460876, avg_loss=0.694710, seen=480, correct=248, accuracy=0.516667
2025-10-10 04:27:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:27:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:27:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2058MB allocated=1794MB
2025-10-10 04:27:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26306587457657, 'train_avg_loss': 0.6855255489548048, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:27:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:27:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:27:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:27:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:27:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-10 04:27:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:27:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:27:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:27:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:27:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:27:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:27:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.472687, avg_loss=0.703068, seen=480, correct=230, accuracy=0.479167
2025-10-10 04:27:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:27:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:27:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2058MB allocated=1794MB
2025-10-10 04:27:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.45049595832825, 'train_avg_loss': 0.7204207996527354, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 04:27:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 04:27:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 04:27:53 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #3) -------------
2025-10-10 04:27:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=3 aidx=0 | s=3 (candidates=3)
2025-10-10 04:27:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-10 04:27:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:27:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:27:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-10 04:27:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:27:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:27:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:27:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:27:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:28:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:28:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.902496, avg_loss=0.695630, seen=480, correct=251, accuracy=0.522917
2025-10-10 04:28:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:28:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:28:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:28:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2058MB allocated=1794MB
2025-10-10 04:28:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.23512667417526, 'train_avg_loss': 0.6852927222847939, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:28:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:28:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:28:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:28:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:29:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:29:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.400818, avg_loss=0.688335, seen=480, correct=261, accuracy=0.543750
2025-10-10 04:29:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:29:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:29:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:29:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2116MB allocated=1794MB
2025-10-10 04:29:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36512249708176, 'train_avg_loss': 0.6780426874756813, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 04:29:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 04:29:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 04:29:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:29:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:29:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-10 04:29:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:29:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:29:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:29:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:29:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:29:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:29:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:29:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.227051, avg_loss=0.696306, seen=480, correct=235, accuracy=0.489583
2025-10-10 04:29:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:29:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:29:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:29:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2058MB allocated=1794MB
2025-10-10 04:29:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.23240876197815, 'train_avg_loss': 0.7102700730164846, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 04:29:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:29:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:29:58 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #4) -------------
2025-10-10 04:29:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=4 aidx=0 | s=3 (candidates=3)
2025-10-10 04:29:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:29:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:30:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:30:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:30:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:30:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.066833, avg_loss=0.691806, seen=480, correct=259, accuracy=0.539583
2025-10-10 04:30:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:30:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:30:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2058MB allocated=1794MB
2025-10-10 04:30:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78275382518768, 'train_avg_loss': 0.6815229485432307, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:30:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:30:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:30:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:30:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:30:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:31:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:31:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.110687, avg_loss=0.687731, seen=480, correct=251, accuracy=0.522917
2025-10-10 04:31:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:31:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:31:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:31:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2058MB allocated=1794MB
2025-10-10 04:31:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43496245145798, 'train_avg_loss': 0.7036246870954831, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 04:31:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:31:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:31:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:31:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:31:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:32:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:32:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.966553, avg_loss=0.689514, seen=480, correct=254, accuracy=0.529167
2025-10-10 04:32:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:32:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:32:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2114MB allocated=1794MB
2025-10-10 04:32:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61819326877594, 'train_avg_loss': 0.6801516105731328, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:32:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:32:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:32:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #5) -------------
2025-10-10 04:32:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=5 aidx=0 | s=3 (candidates=3)
2025-10-10 04:32:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-10 04:32:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:32:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:32:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:32:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:32:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.566833, avg_loss=0.688681, seen=480, correct=248, accuracy=0.516667
2025-10-10 04:32:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:32:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:32:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2058MB allocated=1794MB
2025-10-10 04:32:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36256206035614, 'train_avg_loss': 0.7030213505029679, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 04:32:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:32:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:32:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:32:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:32:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-10 04:32:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:32:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:32:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:32:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:32:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:33:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:33:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.035797, avg_loss=0.670908, seen=480, correct=292, accuracy=0.608333
2025-10-10 04:33:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:33:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:33:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2116MB allocated=1794MB
2025-10-10 04:33:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.89446496963501, 'train_avg_loss': 0.6491205414136251, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 04:33:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 04:33:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 04:33:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:33:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:33:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-10 04:33:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:33:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:33:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:33:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:33:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:34:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:34:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.006592, avg_loss=0.689597, seen=480, correct=253, accuracy=0.527083
2025-10-10 04:34:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:34:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:34:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:34:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2058MB allocated=1794MB
2025-10-10 04:34:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00579881668091, 'train_avg_loss': 0.6833816568056742, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:34:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 04:34:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 04:34:14 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #6) -------------
2025-10-10 04:34:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=6 aidx=0 | s=3 (candidates=3)
2025-10-10 04:34:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-10 04:34:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:34:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:34:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:34:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:34:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.547180, avg_loss=0.686557, seen=480, correct=252, accuracy=0.525000
2025-10-10 04:34:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:34:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:34:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:34:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2058MB allocated=1794MB
2025-10-10 04:34:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91427558660507, 'train_avg_loss': 0.6992856298883756, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 04:34:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 04:34:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 04:34:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:35:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:35:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:35:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:35:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.589355, avg_loss=0.682478, seen=480, correct=261, accuracy=0.543750
2025-10-10 04:35:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:35:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:35:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:35:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2058MB allocated=1794MB
2025-10-10 04:35:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31017792224884, 'train_avg_loss': 0.6775848160187403, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 04:35:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 04:35:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 04:35:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:35:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:35:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:36:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:36:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.385193, avg_loss=0.669552, seen=480, correct=285, accuracy=0.593750
2025-10-10 04:36:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:36:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:36:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2116MB allocated=1794MB
2025-10-10 04:36:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.98893570899963, 'train_avg_loss': 0.6415744642416636, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 04:36:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 04:36:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 04:36:23 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #7) -------------
2025-10-10 04:36:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=7 aidx=0 | s=3 (candidates=3)
2025-10-10 04:36:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-10 04:36:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:36:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:36:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:36:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:36:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.651855, avg_loss=0.653441, seen=480, correct=303, accuracy=0.631250
2025-10-10 04:36:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:36:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:37:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2116MB allocated=1794MB
2025-10-10 04:37:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.47630774974823, 'train_avg_loss': 0.6123025645812352, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-10 04:37:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 04:37:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 04:37:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:37:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:37:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-10 04:37:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:37:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:37:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:37:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:37:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:37:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:37:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.685181, avg_loss=0.682677, seen=480, correct=265, accuracy=0.552083
2025-10-10 04:37:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:37:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:37:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2058MB allocated=1794MB
2025-10-10 04:37:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3387656211853, 'train_avg_loss': 0.7028230468432108, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 04:37:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 04:37:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 04:37:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:37:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:37:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:38:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:38:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.277679, avg_loss=0.679745, seen=480, correct=268, accuracy=0.558333
2025-10-10 04:38:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:38:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:38:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:38:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2058MB allocated=1794MB
2025-10-10 04:38:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.89459085464478, 'train_avg_loss': 0.6824549237887064, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:38:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 04:38:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 04:38:30 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #8) -------------
2025-10-10 04:38:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=8 aidx=0 | s=3 (candidates=3)
2025-10-10 04:38:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-10 04:38:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:38:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:38:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-10 04:38:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:38:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:38:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:38:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:38:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:38:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:39:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:39:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.234589, avg_loss=0.648405, seen=480, correct=296, accuracy=0.616667
2025-10-10 04:39:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:39:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:39:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2116MB allocated=1794MB
2025-10-10 04:39:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.88585126399994, 'train_avg_loss': 0.5990487605333328, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-10 04:39:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:39:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:39:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:39:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:39:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:39:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.676086, avg_loss=0.680575, seen=480, correct=270, accuracy=0.562500
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:39:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:39:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2058MB allocated=1794MB
2025-10-10 04:39:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76200836896896, 'train_avg_loss': 0.6980167364080747, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 04:39:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:39:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:39:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:39:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:39:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-10 04:39:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:39:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:39:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:39:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:39:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:40:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:40:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.695984, avg_loss=0.672283, seen=480, correct=278, accuracy=0.579167
2025-10-10 04:40:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:40:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2058MB allocated=1794MB
2025-10-10 04:40:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.30701225996017, 'train_avg_loss': 0.6775584354996681, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:40:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:40:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:40:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #9) -------------
2025-10-10 04:40:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=9 aidx=0 | s=3 (candidates=3)
2025-10-10 04:40:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-10 04:40:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:40:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:40:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:41:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:41:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.007690, avg_loss=0.677099, seen=480, correct=277, accuracy=0.577083
2025-10-10 04:41:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:41:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:41:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2058MB allocated=1794MB
2025-10-10 04:41:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37361490726471, 'train_avg_loss': 0.6947801242272059, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 04:41:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 04:41:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 04:41:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:41:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:41:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:41:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:41:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.169403, avg_loss=0.646186, seen=480, correct=307, accuracy=0.639583
2025-10-10 04:41:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:41:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:41:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2116MB allocated=1794MB
2025-10-10 04:41:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.40612703561783, 'train_avg_loss': 0.5867177252968152, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-10 04:41:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:41:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:41:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:42:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:42:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:42:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:42:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.378815, avg_loss=0.663289, seen=480, correct=294, accuracy=0.612500
2025-10-10 04:42:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:42:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:42:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2058MB allocated=1794MB
2025-10-10 04:42:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32211339473724, 'train_avg_loss': 0.6776842782894771, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:42:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 04:42:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 04:42:43 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #10) -------------
2025-10-10 04:42:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=10 aidx=0 | s=3 (candidates=3)
2025-10-10 04:42:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-10 04:42:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:42:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:42:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:43:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:43:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.820343, avg_loss=0.641292, seen=480, correct=306, accuracy=0.637500
2025-10-10 04:43:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:43:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:43:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:43:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2116MB allocated=1794MB
2025-10-10 04:43:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.6660236120224, 'train_avg_loss': 0.57221686343352, 'train_seen': 120, 'train_correct': 96, 'train_acc': 0.8}}
2025-10-10 04:43:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 04:43:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 04:43:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:43:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:44:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:44:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.011841, avg_loss=0.652108, seen=480, correct=300, accuracy=0.625000
2025-10-10 04:44:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:44:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:44:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2058MB allocated=1794MB
2025-10-10 04:44:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58709412813187, 'train_avg_loss': 0.6798924510677655, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:44:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:44:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:44:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:44:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:44:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:44:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.083282, avg_loss=0.673090, seen=480, correct=291, accuracy=0.606250
2025-10-10 04:44:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:44:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:44:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2058MB allocated=1794MB
2025-10-10 04:44:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.89620369672775, 'train_avg_loss': 0.6908016974727312, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:44:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 04:44:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 04:44:48 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #11) -------------
2025-10-10 04:44:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=11 aidx=0 | s=3 (candidates=3)
2025-10-10 04:44:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-10 04:44:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:44:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:44:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:45:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:45:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.298523, avg_loss=0.642289, seen=480, correct=298, accuracy=0.620833
2025-10-10 04:45:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:45:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:45:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:45:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2116MB allocated=1794MB
2025-10-10 04:45:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.58907896280289, 'train_avg_loss': 0.5632423246900241, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-10 04:45:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 04:45:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 04:45:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:45:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:45:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-10 04:45:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:45:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:45:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:45:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:45:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:45:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:46:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:46:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.341614, avg_loss=0.650712, seen=480, correct=302, accuracy=0.629167
2025-10-10 04:46:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:46:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:46:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2058MB allocated=1794MB
2025-10-10 04:46:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51112282276154, 'train_avg_loss': 0.6792593568563461, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:46:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 04:46:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 04:46:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:46:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:46:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-10 04:46:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:46:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:46:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:46:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:46:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:46:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:46:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.864807, avg_loss=0.662218, seen=480, correct=305, accuracy=0.635417
2025-10-10 04:46:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:46:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:46:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2058MB allocated=1794MB
2025-10-10 04:46:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.8111914396286, 'train_avg_loss': 0.6817599286635717, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:46:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 04:46:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 04:46:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #12) -------------
2025-10-10 04:46:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=12 aidx=0 | s=3 (candidates=3)
2025-10-10 04:46:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:46:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:46:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:46:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:47:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:47:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.985474, avg_loss=0.649970, seen=480, correct=299, accuracy=0.622917
2025-10-10 04:47:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:47:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:47:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2058MB allocated=1794MB
2025-10-10 04:47:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3515152335167, 'train_avg_loss': 0.6779292936126391, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:47:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:47:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:47:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:47:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:47:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-10 04:47:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:47:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:47:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:47:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:47:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:48:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:48:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.884888, avg_loss=0.647677, seen=480, correct=315, accuracy=0.656250
2025-10-10 04:48:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:48:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:48:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:48:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2058MB allocated=1794MB
2025-10-10 04:48:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.91449916362762, 'train_avg_loss': 0.6659541596968969, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 04:48:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 04:48:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 04:48:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:48:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:48:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-10 04:48:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:48:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:48:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:48:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:48:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:48:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:48:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:48:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.338409, avg_loss=0.640288, seen=480, correct=288, accuracy=0.600000
2025-10-10 04:48:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:48:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:49:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2114MB allocated=1794MB
2025-10-10 04:49:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 66.64774137735367, 'train_avg_loss': 0.5553978448112805, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-10 04:49:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 04:49:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 04:49:02 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #13) -------------
2025-10-10 04:49:02 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=13 aidx=0 | s=3 (candidates=3)
2025-10-10 04:49:02 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:49:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:49:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:49:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-10 04:49:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:49:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:49:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:49:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:49:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:49:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:49:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.430603, avg_loss=0.646730, seen=480, correct=300, accuracy=0.625000
2025-10-10 04:49:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:49:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:49:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2058MB allocated=1794MB
2025-10-10 04:49:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51490885019302, 'train_avg_loss': 0.6792909070849419, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:49:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:49:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:49:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:49:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:49:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:50:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:50:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.227966, avg_loss=0.648392, seen=480, correct=312, accuracy=0.650000
2025-10-10 04:50:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:50:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:50:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2058MB allocated=1794MB
2025-10-10 04:50:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.1418896317482, 'train_avg_loss': 0.6678490802645684, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:50:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 04:50:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 04:50:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:50:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:50:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:51:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:51:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.259674, avg_loss=0.615124, seen=480, correct=307, accuracy=0.639583
2025-10-10 04:51:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:51:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:51:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2114MB allocated=1794MB
2025-10-10 04:51:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 61.59288287162781, 'train_avg_loss': 0.5132740239302317, 'train_seen': 120, 'train_correct': 100, 'train_acc': 0.8333333333333334}}
2025-10-10 04:51:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:51:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:51:10 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #14) -------------
2025-10-10 04:51:10 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=14 aidx=0 | s=3 (candidates=3)
2025-10-10 04:51:10 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:51:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:51:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:51:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-10 04:51:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:51:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:51:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:51:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:51:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:51:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:51:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.833984, avg_loss=0.647571, seen=480, correct=296, accuracy=0.616667
2025-10-10 04:51:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:51:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:51:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2058MB allocated=1794MB
2025-10-10 04:51:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.78102868795395, 'train_avg_loss': 0.6898419057329496, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:51:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:51:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:51:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:51:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:51:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:52:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:52:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.685913, avg_loss=0.651429, seen=480, correct=303, accuracy=0.631250
2025-10-10 04:52:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:52:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:52:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:52:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2058MB allocated=1794MB
2025-10-10 04:52:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.92884594202042, 'train_avg_loss': 0.6744070495168368, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 04:52:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 04:52:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 04:52:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:52:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:52:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:53:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:53:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=281.481232, avg_loss=0.586419, seen=480, correct=320, accuracy=0.666667
2025-10-10 04:53:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:53:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:53:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2116MB allocated=1794MB
2025-10-10 04:53:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 55.6625372171402, 'train_avg_loss': 0.46385447680950165, 'train_seen': 120, 'train_correct': 99, 'train_acc': 0.825}}
2025-10-10 04:53:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:53:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:53:23 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #15) -------------
2025-10-10 04:53:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=15 aidx=0 | s=3 (candidates=3)
2025-10-10 04:53:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-10 04:53:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:53:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:53:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:54:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:54:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.517212, avg_loss=0.651078, seen=480, correct=299, accuracy=0.622917
2025-10-10 04:54:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:54:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:54:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2058MB allocated=1794MB
2025-10-10 04:54:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73923271894455, 'train_avg_loss': 0.6978269393245379, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:54:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:54:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:54:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:54:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:54:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:54:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:54:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=265.641907, avg_loss=0.553421, seen=480, correct=345, accuracy=0.718750
2025-10-10 04:54:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:54:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:54:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2116MB allocated=1794MB
2025-10-10 04:54:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.19089776277542, 'train_avg_loss': 0.4099241480231285, 'train_seen': 120, 'train_correct': 102, 'train_acc': 0.85}}
2025-10-10 04:54:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 04:54:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 04:54:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:54:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:54:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:55:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:55:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.475037, avg_loss=0.655156, seen=480, correct=299, accuracy=0.622917
2025-10-10 04:55:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:55:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:55:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:55:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2058MB allocated=1794MB
2025-10-10 04:55:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.03508114814758, 'train_avg_loss': 0.6752923429012299, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 04:55:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:55:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:55:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #16) -------------
2025-10-10 04:55:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=16 aidx=0 | s=3 (candidates=3)
2025-10-10 04:55:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-10 04:55:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:55:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:55:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-10 04:55:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:55:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:55:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:55:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:55:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:55:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:56:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:56:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.327637, avg_loss=0.631933, seen=480, correct=322, accuracy=0.670833
2025-10-10 04:56:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:56:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:56:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2058MB allocated=1794MB
2025-10-10 04:56:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77711009979248, 'train_avg_loss': 0.6481425841649373, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 04:56:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 04:56:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 04:56:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:56:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:56:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:57:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:57:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.692871, avg_loss=0.645193, seen=480, correct=300, accuracy=0.625000
2025-10-10 04:57:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:57:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:57:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2058MB allocated=1794MB
2025-10-10 04:57:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69966812431812, 'train_avg_loss': 0.6724972343693177, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:57:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:57:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 04:57:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:57:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:57:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:57:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:57:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=267.268585, avg_loss=0.556810, seen=480, correct=334, accuracy=0.695833
2025-10-10 04:57:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:57:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:57:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2114MB allocated=1794MB
2025-10-10 04:57:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.542654275894165, 'train_avg_loss': 0.412855452299118, 'train_seen': 120, 'train_correct': 101, 'train_acc': 0.8416666666666667}}
2025-10-10 04:57:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 04:57:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 04:57:44 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #17) -------------
2025-10-10 04:57:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=17 aidx=0 | s=3 (candidates=3)
2025-10-10 04:57:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-10 04:57:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 04:57:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:57:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:58:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:58:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.400726, avg_loss=0.652918, seen=480, correct=296, accuracy=0.616667
2025-10-10 04:58:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:58:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:58:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:58:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2058MB allocated=1794MB
2025-10-10 04:58:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.20344313979149, 'train_avg_loss': 0.693362026164929, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 04:58:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:58:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 04:58:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 04:58:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:58:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:59:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:59:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.625122, avg_loss=0.640886, seen=480, correct=305, accuracy=0.635417
2025-10-10 04:59:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:59:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:59:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2058MB allocated=1794MB
2025-10-10 04:59:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.54380449652672, 'train_avg_loss': 0.662865037471056, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:59:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 04:59:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 04:59:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:59:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:59:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:59:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:59:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=250.474762, avg_loss=0.521822, seen=480, correct=357, accuracy=0.743750
2025-10-10 04:59:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:59:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2116MB allocated=1794MB
2025-10-10 04:59:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 42.83199381828308, 'train_avg_loss': 0.35693328181902567, 'train_seen': 120, 'train_correct': 106, 'train_acc': 0.8833333333333333}}
2025-10-10 04:59:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-10 04:59:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-10 04:59:53 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #18) -------------
2025-10-10 04:59:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=18 aidx=0 | s=3 (candidates=3)
2025-10-10 04:59:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-10 04:59:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 04:59:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:59:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-10 04:59:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-10 04:59:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:59:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:59:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:59:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:00:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:00:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=236.825241, avg_loss=0.493386, seen=480, correct=358, accuracy=0.745833
2025-10-10 05:00:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:00:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:00:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:00:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2116MB allocated=1794MB
2025-10-10 05:00:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 37.55860389769077, 'train_avg_loss': 0.3129883658140898, 'train_seen': 120, 'train_correct': 104, 'train_acc': 0.8666666666666667}}
2025-10-10 05:00:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-10 05:00:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-10 05:00:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-10 05:00:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:01:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:01:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.656219, avg_loss=0.659700, seen=480, correct=302, accuracy=0.629167
2025-10-10 05:01:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:01:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:01:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:01:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2058MB allocated=1794MB
2025-10-10 05:01:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.59631188213825, 'train_avg_loss': 0.7133025990178188, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:01:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 05:01:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 05:01:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:01:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:01:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-10 05:01:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-10 05:01:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:01:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:01:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:01:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:01:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:01:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:01:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.746979, avg_loss=0.649473, seen=480, correct=306, accuracy=0.637500
2025-10-10 05:01:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:01:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:01:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:01:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2058MB allocated=1794MB
2025-10-10 05:01:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09234061837196, 'train_avg_loss': 0.684102838486433, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:01:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 05:01:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 05:02:00 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #19) -------------
2025-10-10 05:02:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=19 aidx=1 | s=5 (candidates=16)
2025-10-10 05:02:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 43, 22, 26, 51] (from 16)
2025-10-10 05:02:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:02:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:02:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-10 05:02:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:02:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:02:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:02:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:02:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:02:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:02:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.205597, avg_loss=0.719178, seen=480, correct=237, accuracy=0.493750
2025-10-10 05:02:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:02:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:02:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2144MB allocated=1844MB
2025-10-10 05:02:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.59301769733429, 'train_avg_loss': 0.7132751474777858, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:02:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.2055969238281, 'train_avg_loss': 0.7191783269246419, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:02:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 345.2055969238281, 'train_avg_loss': 0.7191783269246419, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:02:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 05:02:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:03:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:03:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.751556, avg_loss=0.701566, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:03:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:03:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:03:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:03:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2174MB allocated=1852MB
2025-10-10 05:03:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.04123878479004, 'train_avg_loss': 0.7086769898732503, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:03:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7515563964844, 'train_avg_loss': 0.7015657424926758, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:03:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 336.7515563964844, 'train_avg_loss': 0.7015657424926758, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:03:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:03:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:03:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-10 05:03:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 05:03:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:03:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:03:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:03:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:03:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:04:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:04:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.349457, avg_loss=0.709061, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:04:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:04:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:04:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2132MB allocated=1861MB
2025-10-10 05:04:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5105294585228, 'train_avg_loss': 0.68758774548769, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:04:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.3494567871094, 'train_avg_loss': 0.7090613683064778, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:04:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 340.3494567871094, 'train_avg_loss': 0.7090613683064778, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:04:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:04:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:04:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:04:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:04:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.350830, avg_loss=0.713231, seen=480, correct=239, accuracy=0.497917
2025-10-10 05:04:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:04:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:04:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2092MB allocated=1869MB
2025-10-10 05:04:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.12541753053665, 'train_avg_loss': 0.7093784794211387, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:04:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.350830078125, 'train_avg_loss': 0.7132308959960938, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:04:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 342.350830078125, 'train_avg_loss': 0.7132308959960938, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:04:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:04:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:04:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-10 05:04:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 05:04:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:04:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:04:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:04:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:05:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:05:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.125763, avg_loss=0.704429, seen=480, correct=261, accuracy=0.543750
2025-10-10 05:05:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:05:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:05:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:05:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2144MB allocated=1878MB
2025-10-10 05:05:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.65072512626648, 'train_avg_loss': 0.7137560427188874, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:05:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.1257629394531, 'train_avg_loss': 0.7044286727905273, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:05:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 338.1257629394531, 'train_avg_loss': 0.7044286727905273, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:05:35 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #20) -------------
2025-10-10 05:05:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=20 aidx=1 | s=5 (candidates=16)
2025-10-10 05:05:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 28, 48, 34, 29] (from 16)
2025-10-10 05:05:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 05:05:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:05:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:06:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:06:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.020416, avg_loss=0.700043, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:06:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:06:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:06:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:06:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2192MB allocated=1928MB
2025-10-10 05:06:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.43614590167999, 'train_avg_loss': 0.686967882514, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 05:06:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.0204162597656, 'train_avg_loss': 0.7000425338745118, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:06:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 336.0204162597656, 'train_avg_loss': 0.7000425338745118, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:06:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:06:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:06:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-10 05:06:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 05:06:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:06:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:06:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:06:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:06:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:07:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:07:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.857880, avg_loss=0.693454, seen=480, correct=243, accuracy=0.506250
2025-10-10 05:07:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:07:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:07:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2134MB allocated=1937MB
2025-10-10 05:07:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.72051870822906, 'train_avg_loss': 0.6976709892352422, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:07:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8578796386719, 'train_avg_loss': 0.6934539159138997, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:07:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 332.8578796386719, 'train_avg_loss': 0.6934539159138997, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:07:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:07:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:07:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-10 05:07:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 05:07:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:07:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:07:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:07:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:07:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:07:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.298676, avg_loss=0.706872, seen=480, correct=237, accuracy=0.493750
2025-10-10 05:07:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:07:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:07:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2148MB allocated=1945MB
2025-10-10 05:07:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.07516384124756, 'train_avg_loss': 0.708959698677063, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:07:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.2986755371094, 'train_avg_loss': 0.7068722407023112, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:07:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 339.2986755371094, 'train_avg_loss': 0.7068722407023112, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:07:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:07:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:07:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-10 05:07:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:07:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:07:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:07:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:07:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:08:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:08:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.984192, avg_loss=0.712467, seen=480, correct=239, accuracy=0.497917
2025-10-10 05:08:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:08:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:08:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:08:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2146MB allocated=1954MB
2025-10-10 05:08:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49927860498428, 'train_avg_loss': 0.7041606550415357, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:08:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.98419189453125, 'train_avg_loss': 0.7124670664469401, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:08:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 341.98419189453125, 'train_avg_loss': 0.7124670664469401, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:08:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:08:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:08:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:09:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:09:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.826263, avg_loss=0.705888, seen=480, correct=238, accuracy=0.495833
2025-10-10 05:09:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:09:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:09:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:09:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2128MB allocated=1912MB
2025-10-10 05:09:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.13698619604111, 'train_avg_loss': 0.7178082183003426, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:09:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.8262634277344, 'train_avg_loss': 0.70588804880778, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:09:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 338.8262634277344, 'train_avg_loss': 0.70588804880778, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:09:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #21) -------------
2025-10-10 05:09:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=21 aidx=1 | s=5 (candidates=16)
2025-10-10 05:09:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 45, 22, 1, 43] (from 16)
2025-10-10 05:09:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 05:09:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:09:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:09:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:09:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.121002, avg_loss=0.687752, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:09:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:09:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:10:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2150MB allocated=1920MB
2025-10-10 05:10:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.32387202978134, 'train_avg_loss': 0.6943656002481778, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:10:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1210021972656, 'train_avg_loss': 0.6877520879109701, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:10:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 330.1210021972656, 'train_avg_loss': 0.6877520879109701, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:10:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:10:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:10:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-10 05:10:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:10:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:10:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:10:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:10:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:10:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:10:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.763153, avg_loss=0.689090, seen=480, correct=270, accuracy=0.562500
2025-10-10 05:10:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:10:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:10:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2102MB allocated=1929MB
2025-10-10 05:10:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.46835714578629, 'train_avg_loss': 0.6955696428815524, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:10:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7631530761719, 'train_avg_loss': 0.6890899022420247, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 05:10:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 330.7631530761719, 'train_avg_loss': 0.6890899022420247, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 05:10:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:10:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:10:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-10 05:10:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 05:10:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:10:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:10:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:10:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:11:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:11:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.832275, avg_loss=0.697567, seen=480, correct=258, accuracy=0.537500
2025-10-10 05:11:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:11:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:11:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:11:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2074MB allocated=1887MB
2025-10-10 05:11:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.014089345932, 'train_avg_loss': 0.6834507445494334, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:11:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.832275390625, 'train_avg_loss': 0.6975672403971355, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:11:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 334.832275390625, 'train_avg_loss': 0.6975672403971355, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:11:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:11:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:11:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-10 05:11:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:11:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:11:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:11:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:11:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:11:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:12:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:12:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.620575, avg_loss=0.711710, seen=480, correct=237, accuracy=0.493750
2025-10-10 05:12:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:12:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:12:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:12:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2092MB allocated=1937MB
2025-10-10 05:12:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.35610830783844, 'train_avg_loss': 0.702967569231987, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:12:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.6205749511719, 'train_avg_loss': 0.7117095311482747, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:12:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 341.6205749511719, 'train_avg_loss': 0.7117095311482747, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:12:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:12:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:12:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-10 05:12:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 05:12:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:12:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:12:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:12:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:12:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:12:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:12:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.342102, avg_loss=0.690296, seen=480, correct=261, accuracy=0.543750
2025-10-10 05:12:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:12:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:12:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:12:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2126MB allocated=1895MB
2025-10-10 05:12:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1877293586731, 'train_avg_loss': 0.7098977446556092, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:12:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.34210205078125, 'train_avg_loss': 0.6902960459391276, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:12:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 331.34210205078125, 'train_avg_loss': 0.6902960459391276, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:12:59 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #22) -------------
2025-10-10 05:13:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=22 aidx=1 | s=5 (candidates=16)
2025-10-10 05:13:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 15, 51, 1, 47] (from 16)
2025-10-10 05:13:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:13:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:13:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-10 05:13:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:13:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:13:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:13:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:13:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:13:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:13:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:13:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.935486, avg_loss=0.704032, seen=480, correct=249, accuracy=0.518750
2025-10-10 05:13:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:13:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:13:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:13:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2100MB allocated=1946MB
2025-10-10 05:13:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.14385139942169, 'train_avg_loss': 0.7095320949951808, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:13:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.93548583984375, 'train_avg_loss': 0.7040322621663412, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:13:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 337.93548583984375, 'train_avg_loss': 0.7040322621663412, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:13:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:13:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:13:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-10 05:13:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:13:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:13:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:13:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:13:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:13:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:14:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:14:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.578247, avg_loss=0.688705, seen=480, correct=260, accuracy=0.541667
2025-10-10 05:14:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:14:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:14:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2092MB allocated=1954MB
2025-10-10 05:14:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.30464094877243, 'train_avg_loss': 0.7108720079064369, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 05:14:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.5782470703125, 'train_avg_loss': 0.6887046813964843, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:14:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 330.5782470703125, 'train_avg_loss': 0.6887046813964843, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:14:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:14:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:14:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-10 05:14:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 05:14:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:14:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:14:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:14:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:15:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:15:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.383331, avg_loss=0.684132, seen=480, correct=268, accuracy=0.558333
2025-10-10 05:15:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:15:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:15:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2114MB allocated=1912MB
2025-10-10 05:15:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.14305353164673, 'train_avg_loss': 0.6845254460970561, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:15:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3833312988281, 'train_avg_loss': 0.684131940205892, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:15:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 328.3833312988281, 'train_avg_loss': 0.684131940205892, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:15:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:15:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:15:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:15:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:15:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.380341, avg_loss=0.711209, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:15:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:15:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:15:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2064MB allocated=1912MB
2025-10-10 05:15:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.27200949192047, 'train_avg_loss': 0.7106000790993373, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:15:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.3803405761719, 'train_avg_loss': 0.7112090428670247, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:15:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 341.3803405761719, 'train_avg_loss': 0.7112090428670247, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:15:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:15:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:15:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-10 05:15:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:15:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:15:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:15:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:15:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:16:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:16:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.429260, avg_loss=0.684228, seen=480, correct=265, accuracy=0.552083
2025-10-10 05:16:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:16:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:16:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:16:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2094MB allocated=1963MB
2025-10-10 05:16:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1229190826416, 'train_avg_loss': 0.6926909923553467, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:16:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.42926025390625, 'train_avg_loss': 0.6842276255289713, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:16:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 328.42926025390625, 'train_avg_loss': 0.6842276255289713, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:16:32 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #23) -------------
2025-10-10 05:16:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=23 aidx=1 | s=5 (candidates=16)
2025-10-10 05:16:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 51, 26, 29, 47] (from 16)
2025-10-10 05:16:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:16:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:16:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:17:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:17:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.324310, avg_loss=0.690259, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:17:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:17:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:17:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2108MB allocated=1963MB
2025-10-10 05:17:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.0429619550705, 'train_avg_loss': 0.7086913496255874, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:17:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3243103027344, 'train_avg_loss': 0.6902589797973633, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:17:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 331.3243103027344, 'train_avg_loss': 0.6902589797973633, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:17:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 05:17:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:17:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:17:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:17:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.109924, avg_loss=0.681479, seen=480, correct=273, accuracy=0.568750
2025-10-10 05:17:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:17:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:17:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2152MB allocated=1963MB
2025-10-10 05:17:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.58778578042984, 'train_avg_loss': 0.6882315481702487, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:17:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.10992431640625, 'train_avg_loss': 0.681479008992513, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:17:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 327.10992431640625, 'train_avg_loss': 0.681479008992513, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:17:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:18:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:18:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-10 05:18:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:18:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:18:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:18:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:18:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:18:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:18:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:18:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.325531, avg_loss=0.704845, seen=480, correct=238, accuracy=0.495833
2025-10-10 05:18:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:18:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:18:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:18:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2108MB allocated=1963MB
2025-10-10 05:18:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.30632519721985, 'train_avg_loss': 0.6942193766434988, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:18:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.3255310058594, 'train_avg_loss': 0.704844856262207, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:18:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 338.3255310058594, 'train_avg_loss': 0.704844856262207, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:18:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:18:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:18:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:19:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:19:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.396484, avg_loss=0.696659, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:19:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:19:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:19:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2134MB allocated=1963MB
2025-10-10 05:19:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.40624248981476, 'train_avg_loss': 0.7033853540817897, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:19:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.396484375, 'train_avg_loss': 0.6966593424479167, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:19:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 334.396484375, 'train_avg_loss': 0.6966593424479167, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:19:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:19:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:19:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:20:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:20:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.618622, avg_loss=0.682539, seen=480, correct=268, accuracy=0.558333
2025-10-10 05:20:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:20:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:20:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2112MB allocated=1963MB
2025-10-10 05:20:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.70474660396576, 'train_avg_loss': 0.697539555033048, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:20:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6186218261719, 'train_avg_loss': 0.6825387954711915, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:20:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 327.6186218261719, 'train_avg_loss': 0.6825387954711915, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:20:09 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #24) -------------
2025-10-10 05:20:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=24 aidx=1 | s=5 (candidates=16)
2025-10-10 05:20:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 28, 26, 34, 48] (from 16)
2025-10-10 05:20:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:20:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:20:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:20:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:20:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.137421, avg_loss=0.689870, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:20:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:20:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:20:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2068MB allocated=1921MB
2025-10-10 05:20:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.35393559932709, 'train_avg_loss': 0.6946161299943924, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:20:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1374206542969, 'train_avg_loss': 0.6898696263631184, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:20:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 331.1374206542969, 'train_avg_loss': 0.6898696263631184, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:20:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 05:20:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:20:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:21:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:21:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.286102, avg_loss=0.694346, seen=480, correct=243, accuracy=0.506250
2025-10-10 05:21:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:21:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:21:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:21:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2064MB allocated=1921MB
2025-10-10 05:21:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.70109176635742, 'train_avg_loss': 0.6975090980529786, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 05:21:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2861022949219, 'train_avg_loss': 0.6943460464477539, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:21:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 333.2861022949219, 'train_avg_loss': 0.6943460464477539, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:21:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:21:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:21:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:22:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:22:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.440582, avg_loss=0.700918, seen=480, correct=237, accuracy=0.493750
2025-10-10 05:22:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:22:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:22:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:22:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2064MB allocated=1921MB
2025-10-10 05:22:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.48153185844421, 'train_avg_loss': 0.6873460988203685, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 05:22:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4405822753906, 'train_avg_loss': 0.7009178797403971, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:22:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 336.4405822753906, 'train_avg_loss': 0.7009178797403971, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 05:22:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:22:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:22:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:23:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:23:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.506958, avg_loss=0.705223, seen=480, correct=236, accuracy=0.491667
2025-10-10 05:23:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:23:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:23:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2084MB allocated=1921MB
2025-10-10 05:23:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.4167628288269, 'train_avg_loss': 0.7034730235735576, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 05:23:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.5069580078125, 'train_avg_loss': 0.7052228291829427, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:23:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 338.5069580078125, 'train_avg_loss': 0.7052228291829427, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:23:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 05:23:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:23:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:23:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:23:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.936768, avg_loss=0.701952, seen=480, correct=247, accuracy=0.514583
2025-10-10 05:23:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:23:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2086MB allocated=1921MB
2025-10-10 05:23:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.46394073963165, 'train_avg_loss': 0.7121995061635971, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:23:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.936767578125, 'train_avg_loss': 0.7019515991210937, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 05:23:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 336.936767578125, 'train_avg_loss': 0.7019515991210937, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 05:23:45 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #25) -------------
2025-10-10 05:23:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=25 aidx=1 | s=5 (candidates=16)
2025-10-10 05:23:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 6, 20, 29, 22] (from 16)
2025-10-10 05:23:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:23:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:23:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:24:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:24:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.785461, avg_loss=0.705803, seen=480, correct=240, accuracy=0.500000
2025-10-10 05:24:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:24:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2064MB allocated=1921MB
2025-10-10 05:24:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.13661909103394, 'train_avg_loss': 0.7011384924252828, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:24:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.78546142578125, 'train_avg_loss': 0.7058030446370442, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:24:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 338.78546142578125, 'train_avg_loss': 0.7058030446370442, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:24:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:24:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:24:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-10 05:24:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:24:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:24:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:24:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:24:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:24:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:25:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:25:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.161011, avg_loss=0.696169, seen=480, correct=248, accuracy=0.516667
2025-10-10 05:25:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:25:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:25:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2074MB allocated=1921MB
2025-10-10 05:25:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.64048421382904, 'train_avg_loss': 0.7053373684485753, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:25:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1610107421875, 'train_avg_loss': 0.6961687723795573, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:25:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 334.1610107421875, 'train_avg_loss': 0.6961687723795573, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:25:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:25:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:25:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-10 05:25:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 05:25:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:25:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:25:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:25:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:25:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:25:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.896393, avg_loss=0.683117, seen=480, correct=273, accuracy=0.568750
2025-10-10 05:25:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:25:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:25:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2100MB allocated=1921MB
2025-10-10 05:25:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.05378115177155, 'train_avg_loss': 0.6921148429314296, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:25:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8963928222656, 'train_avg_loss': 0.6831174850463867, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:25:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 327.8963928222656, 'train_avg_loss': 0.6831174850463867, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:25:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:25:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:25:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:26:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:26:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.220459, avg_loss=0.692126, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:26:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:26:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:26:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:26:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2088MB allocated=1921MB
2025-10-10 05:26:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3462073802948, 'train_avg_loss': 0.7028850615024567, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:26:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.220458984375, 'train_avg_loss': 0.6921259562174479, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:26:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 332.220458984375, 'train_avg_loss': 0.6921259562174479, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:26:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 05:26:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:26:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:27:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:27:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.052521, avg_loss=0.691776, seen=480, correct=265, accuracy=0.552083
2025-10-10 05:27:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:27:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:27:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:27:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2102MB allocated=1921MB
2025-10-10 05:27:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.33452689647675, 'train_avg_loss': 0.6861210574706396, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:27:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0525207519531, 'train_avg_loss': 0.6917760848999024, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:27:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 332.0525207519531, 'train_avg_loss': 0.6917760848999024, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:27:18 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #26) -------------
2025-10-10 05:27:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=26 aidx=1 | s=5 (candidates=16)
2025-10-10 05:27:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 28, 22, 1] (from 16)
2025-10-10 05:27:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:27:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:27:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:28:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:28:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.564331, avg_loss=0.690759, seen=480, correct=261, accuracy=0.543750
2025-10-10 05:28:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:28:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:28:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2088MB allocated=1921MB
2025-10-10 05:28:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.31409233808517, 'train_avg_loss': 0.7026174361507098, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:28:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5643310546875, 'train_avg_loss': 0.690759023030599, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:28:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 331.5643310546875, 'train_avg_loss': 0.690759023030599, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:28:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:28:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:28:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-10 05:28:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:28:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:28:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:28:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:28:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:28:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:28:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.326294, avg_loss=0.684013, seen=480, correct=262, accuracy=0.545833
2025-10-10 05:28:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:28:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:28:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2068MB allocated=1921MB
2025-10-10 05:28:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.34630233049393, 'train_avg_loss': 0.6862191860874494, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:28:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3262939453125, 'train_avg_loss': 0.6840131123860677, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:28:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 328.3262939453125, 'train_avg_loss': 0.6840131123860677, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:28:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:28:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:28:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-10 05:28:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 05:28:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:28:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:28:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:28:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:29:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:29:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.648315, avg_loss=0.686767, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:29:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:29:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:29:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:29:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2064MB allocated=1921MB
2025-10-10 05:29:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.81188833713531, 'train_avg_loss': 0.6900990694761276, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:29:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6483154296875, 'train_avg_loss': 0.6867673238118489, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:29:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 329.6483154296875, 'train_avg_loss': 0.6867673238118489, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:29:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 05:29:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:29:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:30:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:30:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.691376, avg_loss=0.672274, seen=480, correct=282, accuracy=0.587500
2025-10-10 05:30:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:30:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:30:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:30:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2102MB allocated=1921MB
2025-10-10 05:30:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.5295227766037, 'train_avg_loss': 0.6627460231383642, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 05:30:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6913757324219, 'train_avg_loss': 0.6722736994425456, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 05:30:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 322.6913757324219, 'train_avg_loss': 0.6722736994425456, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 05:30:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:30:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:30:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:30:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:30:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.462708, avg_loss=0.703047, seen=480, correct=243, accuracy=0.506250
2025-10-10 05:30:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:30:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:30:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:30:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2064MB allocated=1921MB
2025-10-10 05:30:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.37301647663116, 'train_avg_loss': 0.703108470638593, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:30:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.46270751953125, 'train_avg_loss': 0.7030473073323568, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:30:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 337.46270751953125, 'train_avg_loss': 0.7030473073323568, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:30:58 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #27) -------------
2025-10-10 05:30:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=27 aidx=1 | s=5 (candidates=16)
2025-10-10 05:30:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 34, 15, 6, 43] (from 16)
2025-10-10 05:30:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:30:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:30:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-10 05:31:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 05:31:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:31:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:31:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:31:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:31:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:31:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:31:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.488678, avg_loss=0.686435, seen=480, correct=260, accuracy=0.541667
2025-10-10 05:31:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:31:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:31:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:31:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2064MB allocated=1921MB
2025-10-10 05:31:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.40011930465698, 'train_avg_loss': 0.6866676608721415, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:31:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4886779785156, 'train_avg_loss': 0.6864347457885742, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:31:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 329.4886779785156, 'train_avg_loss': 0.6864347457885742, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:31:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:31:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:31:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:32:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:32:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.776978, avg_loss=0.701619, seen=480, correct=238, accuracy=0.495833
2025-10-10 05:32:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:32:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:32:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2086MB allocated=1921MB
2025-10-10 05:32:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.17323362827301, 'train_avg_loss': 0.7014436135689418, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:32:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7769775390625, 'train_avg_loss': 0.7016187032063802, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:32:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 336.7769775390625, 'train_avg_loss': 0.7016187032063802, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 05:32:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:32:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:32:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-10 05:32:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:32:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:32:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:32:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:32:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:33:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:33:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.163635, avg_loss=0.683674, seen=480, correct=261, accuracy=0.543750
2025-10-10 05:33:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:33:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:33:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2064MB allocated=1921MB
2025-10-10 05:33:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.48919451236725, 'train_avg_loss': 0.6957432876030604, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:33:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.16363525390625, 'train_avg_loss': 0.6836742401123047, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:33:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 328.16363525390625, 'train_avg_loss': 0.6836742401123047, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 05:33:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:33:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:33:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:33:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:33:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.829163, avg_loss=0.693394, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:33:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:33:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:33:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2074MB allocated=1921MB
2025-10-10 05:33:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.8618506193161, 'train_avg_loss': 0.6988487551609676, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:33:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.82916259765625, 'train_avg_loss': 0.6933940887451172, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:33:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 332.82916259765625, 'train_avg_loss': 0.6933940887451172, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:33:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 05:33:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:33:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:34:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:34:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.732147, avg_loss=0.676525, seen=480, correct=288, accuracy=0.600000
2025-10-10 05:34:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:34:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:34:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:34:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2126MB allocated=1921MB
2025-10-10 05:34:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1759467124939, 'train_avg_loss': 0.6931328892707824, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:34:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7321472167969, 'train_avg_loss': 0.6765253067016601, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 05:34:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 324.7321472167969, 'train_avg_loss': 0.6765253067016601, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 05:34:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #28) -------------
2025-10-10 05:34:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=28 aidx=1 | s=5 (candidates=16)
2025-10-10 05:34:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 6, 22, 34, 20] (from 16)
2025-10-10 05:34:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:34:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:34:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-10 05:34:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:34:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:34:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:34:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:34:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:34:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:35:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:35:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.014923, avg_loss=0.697948, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:35:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:35:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:35:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2064MB allocated=1921MB
2025-10-10 05:35:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.83410429954529, 'train_avg_loss': 0.6819508691628774, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:35:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.0149230957031, 'train_avg_loss': 0.6979477564493816, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:35:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 335.0149230957031, 'train_avg_loss': 0.6979477564493816, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:35:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:35:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:35:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-10 05:35:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:35:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:35:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:35:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:35:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:35:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:36:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:36:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.838715, avg_loss=0.693414, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:36:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:36:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:36:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2074MB allocated=1921MB
2025-10-10 05:36:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.87622451782227, 'train_avg_loss': 0.6989685376485189, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:36:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8387145996094, 'train_avg_loss': 0.6934139887491862, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:36:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 332.8387145996094, 'train_avg_loss': 0.6934139887491862, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:36:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:36:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:36:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-10 05:36:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 05:36:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:36:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:36:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:36:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:36:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:36:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.081848, avg_loss=0.673087, seen=480, correct=281, accuracy=0.585417
2025-10-10 05:36:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:36:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:36:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2102MB allocated=1921MB
2025-10-10 05:36:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.31318891048431, 'train_avg_loss': 0.669276574254036, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:36:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.08184814453125, 'train_avg_loss': 0.6730871836344401, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 05:36:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 323.08184814453125, 'train_avg_loss': 0.6730871836344401, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 05:36:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:36:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:36:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-10 05:36:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:36:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:36:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:36:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:36:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:37:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:37:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.929260, avg_loss=0.701936, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:37:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:37:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:37:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:37:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2086MB allocated=1921MB
2025-10-10 05:37:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.44803082942963, 'train_avg_loss': 0.7037335902452468, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:37:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.92926025390625, 'train_avg_loss': 0.7019359588623046, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:37:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 336.92926025390625, 'train_avg_loss': 0.7019359588623046, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:37:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 05:37:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:37:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:38:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:38:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.586823, avg_loss=0.678306, seen=480, correct=273, accuracy=0.568750
2025-10-10 05:38:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:38:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:38:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2100MB allocated=1921MB
2025-10-10 05:38:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.69623827934265, 'train_avg_loss': 0.6891353189945221, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:38:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.5868225097656, 'train_avg_loss': 0.6783058802286784, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:38:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 325.5868225097656, 'train_avg_loss': 0.6783058802286784, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:38:11 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #29) -------------
2025-10-10 05:38:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=29 aidx=1 | s=5 (candidates=16)
2025-10-10 05:38:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 47, 45, 40, 6] (from 16)
2025-10-10 05:38:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:38:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:38:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-10 05:38:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:38:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:38:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:38:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:38:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:38:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:38:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.156372, avg_loss=0.683659, seen=480, correct=272, accuracy=0.566667
2025-10-10 05:38:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:38:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:38:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2064MB allocated=1921MB
2025-10-10 05:38:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.01777398586273, 'train_avg_loss': 0.7001481165488561, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:38:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1563720703125, 'train_avg_loss': 0.6836591084798177, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:38:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 328.1563720703125, 'train_avg_loss': 0.6836591084798177, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:38:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:38:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:38:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:39:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:39:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.139648, avg_loss=0.671124, seen=480, correct=276, accuracy=0.575000
2025-10-10 05:39:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:39:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:39:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:39:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2068MB allocated=1921MB
2025-10-10 05:39:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.30980610847473, 'train_avg_loss': 0.6859150509039561, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:39:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1396484375, 'train_avg_loss': 0.671124267578125, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 05:39:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 322.1396484375, 'train_avg_loss': 0.671124267578125, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 05:39:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:39:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:39:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:40:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:40:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.728333, avg_loss=0.682767, seen=480, correct=258, accuracy=0.537500
2025-10-10 05:40:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:40:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:40:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:40:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2068MB allocated=1921MB
2025-10-10 05:40:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24807596206665, 'train_avg_loss': 0.6854006330172221, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:40:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.72833251953125, 'train_avg_loss': 0.6827673594156901, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:40:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 327.72833251953125, 'train_avg_loss': 0.6827673594156901, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:40:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:40:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:40:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-10 05:40:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 05:40:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:40:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:40:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:40:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:40:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:41:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:41:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.967285, avg_loss=0.697849, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:41:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:41:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:41:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2092MB allocated=1971MB
2025-10-10 05:41:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.86758637428284, 'train_avg_loss': 0.7155632197856903, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 05:41:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.96728515625, 'train_avg_loss': 0.6978485107421875, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:41:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 334.96728515625, 'train_avg_loss': 0.6978485107421875, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:41:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:41:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:41:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:41:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:41:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.323120, avg_loss=0.688173, seen=480, correct=256, accuracy=0.533333
2025-10-10 05:41:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:41:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2074MB allocated=1929MB
2025-10-10 05:41:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93642890453339, 'train_avg_loss': 0.6911369075377782, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:41:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3231201171875, 'train_avg_loss': 0.6881731669108073, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 05:41:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 330.3231201171875, 'train_avg_loss': 0.6881731669108073, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 05:41:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #30) -------------
2025-10-10 05:41:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=30 aidx=1 | s=5 (candidates=16)
2025-10-10 05:41:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 51, 48, 40, 34] (from 16)
2025-10-10 05:41:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:41:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:41:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-10 05:41:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:41:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:41:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:41:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:41:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:42:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:42:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.895813, avg_loss=0.678950, seen=480, correct=267, accuracy=0.556250
2025-10-10 05:42:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:42:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:42:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:42:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2064MB allocated=1929MB
2025-10-10 05:42:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.17116117477417, 'train_avg_loss': 0.7014263431231181, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:42:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.89581298828125, 'train_avg_loss': 0.6789496103922527, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:42:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 325.89581298828125, 'train_avg_loss': 0.6789496103922527, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:42:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 05:42:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:43:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:43:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.609619, avg_loss=0.670020, seen=480, correct=283, accuracy=0.589583
2025-10-10 05:43:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:43:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:43:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2110MB allocated=1929MB
2025-10-10 05:43:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.93347084522247, 'train_avg_loss': 0.6827789237101872, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:43:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.609619140625, 'train_avg_loss': 0.6700200398763021, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 05:43:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 321.609619140625, 'train_avg_loss': 0.6700200398763021, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 05:43:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 05:43:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:43:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:43:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.158447, avg_loss=0.689913, seen=480, correct=253, accuracy=0.527083
2025-10-10 05:43:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:43:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:43:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2088MB allocated=1929MB
2025-10-10 05:43:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.88763946294785, 'train_avg_loss': 0.7073969955245654, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:43:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.158447265625, 'train_avg_loss': 0.6899134318033854, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 05:43:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 331.158447265625, 'train_avg_loss': 0.6899134318033854, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 05:43:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 05:43:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:44:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:44:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.379974, avg_loss=0.696625, seen=480, correct=244, accuracy=0.508333
2025-10-10 05:44:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:44:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:44:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:44:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2064MB allocated=1929MB
2025-10-10 05:44:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.91089487075806, 'train_avg_loss': 0.7159241239229838, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 05:44:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.3799743652344, 'train_avg_loss': 0.6966249465942382, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 05:44:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 334.3799743652344, 'train_avg_loss': 0.6966249465942382, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 05:44:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:44:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:44:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:45:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:45:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.718201, avg_loss=0.699413, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:45:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:45:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:45:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2084MB allocated=1929MB
2025-10-10 05:45:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9936032295227, 'train_avg_loss': 0.6999466935793559, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:45:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.71820068359375, 'train_avg_loss': 0.6994129180908203, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:45:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 335.71820068359375, 'train_avg_loss': 0.6994129180908203, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:45:15 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #31) -------------
2025-10-10 05:45:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=31 aidx=1 | s=5 (candidates=16)
2025-10-10 05:45:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 47, 20, 28, 15] (from 16)
2025-10-10 05:45:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 05:45:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:45:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:45:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:45:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.313507, avg_loss=0.694403, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:45:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:45:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:45:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2064MB allocated=1929MB
2025-10-10 05:45:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.19143545627594, 'train_avg_loss': 0.7099286288022995, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:45:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3135070800781, 'train_avg_loss': 0.6944031397501628, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:45:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 333.3135070800781, 'train_avg_loss': 0.6944031397501628, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:45:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:45:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:45:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:46:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:46:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.329437, avg_loss=0.671520, seen=480, correct=282, accuracy=0.587500
2025-10-10 05:46:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:46:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2068MB allocated=1929MB
2025-10-10 05:46:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.87887042760849, 'train_avg_loss': 0.6656572535634041, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:46:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.3294372558594, 'train_avg_loss': 0.671519660949707, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 05:46:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 322.3294372558594, 'train_avg_loss': 0.671519660949707, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 05:46:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 05:46:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:46:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:47:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:47:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.244843, avg_loss=0.667177, seen=480, correct=287, accuracy=0.597917
2025-10-10 05:47:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:47:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:47:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:47:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2102MB allocated=1929MB
2025-10-10 05:47:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98864710330963, 'train_avg_loss': 0.6832387258609136, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:47:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.2448425292969, 'train_avg_loss': 0.6671767552693685, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 05:47:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 320.2448425292969, 'train_avg_loss': 0.6671767552693685, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 05:47:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 05:47:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:47:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:48:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:48:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.027527, avg_loss=0.683391, seen=480, correct=255, accuracy=0.531250
2025-10-10 05:48:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:48:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:48:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2064MB allocated=1929MB
2025-10-10 05:48:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.63126915693283, 'train_avg_loss': 0.6885939096411069, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:48:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.02752685546875, 'train_avg_loss': 0.6833906809488932, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:48:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 328.02752685546875, 'train_avg_loss': 0.6833906809488932, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:48:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:48:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:48:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:48:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:48:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.863251, avg_loss=0.678882, seen=480, correct=266, accuracy=0.554167
2025-10-10 05:48:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:48:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:48:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2064MB allocated=1929MB
2025-10-10 05:48:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.39941954612732, 'train_avg_loss': 0.6949951628843943, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:48:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.8632507324219, 'train_avg_loss': 0.6788817723592122, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 05:48:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 325.8632507324219, 'train_avg_loss': 0.6788817723592122, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 05:48:50 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #32) -------------
2025-10-10 05:48:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=32 aidx=1 | s=5 (candidates=16)
2025-10-10 05:48:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 43, 40, 45, 34] (from 16)
2025-10-10 05:48:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:48:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:48:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:49:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:49:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.182129, avg_loss=0.679546, seen=480, correct=267, accuracy=0.556250
2025-10-10 05:49:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:49:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:49:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2074MB allocated=1929MB
2025-10-10 05:49:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.94674396514893, 'train_avg_loss': 0.6828895330429077, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 05:49:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.18212890625, 'train_avg_loss': 0.6795461018880208, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:49:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 326.18212890625, 'train_avg_loss': 0.6795461018880208, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:49:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 05:49:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:49:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:50:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:50:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.354858, avg_loss=0.663239, seen=480, correct=304, accuracy=0.633333
2025-10-10 05:50:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:50:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:50:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:50:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2126MB allocated=1929MB
2025-10-10 05:50:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.77850413322449, 'train_avg_loss': 0.6814875344435374, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:50:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3548583984375, 'train_avg_loss': 0.6632392883300782, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 05:50:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 318.3548583984375, 'train_avg_loss': 0.6632392883300782, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 05:50:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 05:50:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:50:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:51:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:51:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.736694, avg_loss=0.697368, seen=480, correct=250, accuracy=0.520833
2025-10-10 05:51:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:51:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:51:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2064MB allocated=1929MB
2025-10-10 05:51:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.59415984153748, 'train_avg_loss': 0.7132846653461457, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 05:51:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.7366943359375, 'train_avg_loss': 0.6973681131998698, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 05:51:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 334.7366943359375, 'train_avg_loss': 0.6973681131998698, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 05:51:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:51:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:51:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-10 05:51:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:51:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:51:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:51:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:51:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:51:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:51:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.952026, avg_loss=0.683233, seen=480, correct=258, accuracy=0.537500
2025-10-10 05:51:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:51:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:51:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2068MB allocated=1929MB
2025-10-10 05:51:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.4671681523323, 'train_avg_loss': 0.6872264012694359, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:51:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9520263671875, 'train_avg_loss': 0.6832333882649739, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:51:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 327.9520263671875, 'train_avg_loss': 0.6832333882649739, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:51:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:51:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:51:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:52:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:52:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.582214, avg_loss=0.690796, seen=480, correct=255, accuracy=0.531250
2025-10-10 05:52:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:52:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:52:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2084MB allocated=1929MB
2025-10-10 05:52:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.41232705116272, 'train_avg_loss': 0.695102725426356, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:52:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.58221435546875, 'train_avg_loss': 0.6907962799072266, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:52:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 331.58221435546875, 'train_avg_loss': 0.6907962799072266, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:52:29 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #33) -------------
2025-10-10 05:52:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=33 aidx=1 | s=5 (candidates=16)
2025-10-10 05:52:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 15, 45, 47, 6] (from 16)
2025-10-10 05:52:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:52:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:52:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:53:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:53:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.851562, avg_loss=0.693441, seen=480, correct=250, accuracy=0.520833
2025-10-10 05:53:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:53:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:53:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2064MB allocated=1929MB
2025-10-10 05:53:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.2200984954834, 'train_avg_loss': 0.693500820795695, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:53:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8515625, 'train_avg_loss': 0.6934407552083334, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 05:53:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 332.8515625, 'train_avg_loss': 0.6934407552083334, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 05:53:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 05:53:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:53:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:53:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:53:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.052795, avg_loss=0.670943, seen=480, correct=277, accuracy=0.577083
2025-10-10 05:53:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:53:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:53:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2064MB allocated=1929MB
2025-10-10 05:53:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.76982307434082, 'train_avg_loss': 0.6897485256195068, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:53:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.05279541015625, 'train_avg_loss': 0.6709433237711588, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:53:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 322.05279541015625, 'train_avg_loss': 0.6709433237711588, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:53:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:53:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:53:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-10 05:53:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:53:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:53:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:53:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:53:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:54:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:54:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.681824, avg_loss=0.686837, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:54:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:54:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:54:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:54:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2068MB allocated=1929MB
2025-10-10 05:54:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.21452283859253, 'train_avg_loss': 0.6851210236549378, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:54:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.68182373046875, 'train_avg_loss': 0.6868371327718099, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:54:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 329.68182373046875, 'train_avg_loss': 0.6868371327718099, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:54:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:54:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:54:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:55:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:55:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.835480, avg_loss=0.672574, seen=480, correct=286, accuracy=0.595833
2025-10-10 05:55:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:55:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:55:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2068MB allocated=1929MB
2025-10-10 05:55:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.18434703350067, 'train_avg_loss': 0.6682028919458389, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:55:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8354797363281, 'train_avg_loss': 0.6725739161173503, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 05:55:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 322.8354797363281, 'train_avg_loss': 0.6725739161173503, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 05:55:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 05:55:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:55:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:56:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:56:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.097687, avg_loss=0.681454, seen=480, correct=271, accuracy=0.564583
2025-10-10 05:56:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:56:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:56:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2074MB allocated=1929MB
2025-10-10 05:56:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.04939693212509, 'train_avg_loss': 0.6837449744343758, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 05:56:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0976867675781, 'train_avg_loss': 0.6814535140991211, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 05:56:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 327.0976867675781, 'train_avg_loss': 0.6814535140991211, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 05:56:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #34) -------------
2025-10-10 05:56:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=34 aidx=1 | s=5 (candidates=16)
2025-10-10 05:56:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 1, 43, 45, 20] (from 16)
2025-10-10 05:56:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:56:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:56:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:56:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:56:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.525269, avg_loss=0.692761, seen=480, correct=262, accuracy=0.545833
2025-10-10 05:56:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:56:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:56:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2064MB allocated=1929MB
2025-10-10 05:56:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.79400169849396, 'train_avg_loss': 0.681616680820783, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:56:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5252685546875, 'train_avg_loss': 0.692760976155599, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:56:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 332.5252685546875, 'train_avg_loss': 0.692760976155599, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:56:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:56:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:56:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:57:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:57:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.762329, avg_loss=0.697422, seen=480, correct=240, accuracy=0.500000
2025-10-10 05:57:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:57:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:57:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:57:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2064MB allocated=1929MB
2025-10-10 05:57:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.54174971580505, 'train_avg_loss': 0.6961812476317087, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 05:57:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.7623291015625, 'train_avg_loss': 0.6974215189615885, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:57:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 334.7623291015625, 'train_avg_loss': 0.6974215189615885, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:57:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:57:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:57:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-10 05:57:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 05:57:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:57:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:57:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:57:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:57:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:58:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:58:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.912933, avg_loss=0.662319, seen=480, correct=295, accuracy=0.614583
2025-10-10 05:58:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:58:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:58:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2126MB allocated=1929MB
2025-10-10 05:58:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66319620609283, 'train_avg_loss': 0.6805266350507736, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:58:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.9129333496094, 'train_avg_loss': 0.6623186111450196, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 05:58:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 317.9129333496094, 'train_avg_loss': 0.6623186111450196, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 05:58:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:58:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:58:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-10 05:58:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:58:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:58:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:58:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:58:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:58:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:58:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.231445, avg_loss=0.685899, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:58:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:58:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:58:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2068MB allocated=1929MB
2025-10-10 05:58:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24238777160645, 'train_avg_loss': 0.6853532314300537, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:58:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2314453125, 'train_avg_loss': 0.6858988444010417, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:58:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 329.2314453125, 'train_avg_loss': 0.6858988444010417, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:58:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:58:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:58:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-10 05:58:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 05:58:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:58:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:58:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:58:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:59:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:59:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.889923, avg_loss=0.658104, seen=480, correct=313, accuracy=0.652083
2025-10-10 05:59:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:59:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:59:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:59:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2102MB allocated=1929MB
2025-10-10 05:59:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.40565979480743, 'train_avg_loss': 0.6700471649567287, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 05:59:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.8899230957031, 'train_avg_loss': 0.6581040064493815, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 05:59:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 315.8899230957031, 'train_avg_loss': 0.6581040064493815, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 05:59:42 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #35) -------------
2025-10-10 05:59:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=35 aidx=1 | s=5 (candidates=16)
2025-10-10 05:59:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 16, 47, 45, 51] (from 16)
2025-10-10 05:59:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 05:59:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:59:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:00:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:00:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.206848, avg_loss=0.694181, seen=480, correct=259, accuracy=0.539583
2025-10-10 06:00:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:00:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:00:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:00:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2064MB allocated=1929MB
2025-10-10 06:00:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.59447598457336, 'train_avg_loss': 0.721620633204778, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 06:00:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.20684814453125, 'train_avg_loss': 0.6941809336344401, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:00:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 333.20684814453125, 'train_avg_loss': 0.6941809336344401, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:00:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 06:00:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:00:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:01:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:01:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.667419, avg_loss=0.674307, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:01:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:01:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:01:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2104MB allocated=1929MB
2025-10-10 06:01:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.60730761289597, 'train_avg_loss': 0.6467275634407997, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:01:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.66741943359375, 'train_avg_loss': 0.674307123819987, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:01:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 323.66741943359375, 'train_avg_loss': 0.674307123819987, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:01:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:01:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:01:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:01:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:01:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.502289, avg_loss=0.665630, seen=480, correct=290, accuracy=0.604167
2025-10-10 06:01:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:01:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:01:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2068MB allocated=1929MB
2025-10-10 06:01:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.53804588317871, 'train_avg_loss': 0.6711503823598226, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:01:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.5022888183594, 'train_avg_loss': 0.665629768371582, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:01:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 319.5022888183594, 'train_avg_loss': 0.665629768371582, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:01:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:01:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:01:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-10 06:01:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:01:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:01:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:01:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:01:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:02:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:02:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.930450, avg_loss=0.683188, seen=480, correct=265, accuracy=0.552083
2025-10-10 06:02:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:02:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:02:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:02:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2068MB allocated=1929MB
2025-10-10 06:02:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.29678231477737, 'train_avg_loss': 0.6858065192898114, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:02:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9304504394531, 'train_avg_loss': 0.6831884384155273, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 06:02:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 327.9304504394531, 'train_avg_loss': 0.6831884384155273, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 06:02:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 06:02:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:02:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:03:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.821564, avg_loss=0.662128, seen=480, correct=286, accuracy=0.595833
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:03:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:03:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2110MB allocated=1929MB
2025-10-10 06:03:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.77718698978424, 'train_avg_loss': 0.6981432249148687, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 06:03:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8215637207031, 'train_avg_loss': 0.6621282577514649, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 06:03:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 317.8215637207031, 'train_avg_loss': 0.6621282577514649, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 06:03:19 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #36) -------------
2025-10-10 06:03:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=36 aidx=1 | s=5 (candidates=16)
2025-10-10 06:03:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 22, 6, 26, 15] (from 16)
2025-10-10 06:03:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:03:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:03:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-10 06:03:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 06:03:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:03:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:03:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:03:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:04:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:04:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.246277, avg_loss=0.694263, seen=480, correct=264, accuracy=0.550000
2025-10-10 06:04:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:04:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:04:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2064MB allocated=1929MB
2025-10-10 06:04:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.86862295866013, 'train_avg_loss': 0.7239051913221677, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 06:04:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.24627685546875, 'train_avg_loss': 0.6942630767822265, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:04:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 333.24627685546875, 'train_avg_loss': 0.6942630767822265, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:04:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:04:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:04:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:04:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:04:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.320587, avg_loss=0.656918, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:04:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:04:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:04:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2104MB allocated=1929MB
2025-10-10 06:04:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.61928856372833, 'train_avg_loss': 0.6634940713644027, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:04:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.3205871582031, 'train_avg_loss': 0.6569178899129232, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:04:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 315.3205871582031, 'train_avg_loss': 0.6569178899129232, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:04:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:04:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:04:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-10 06:04:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 06:04:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:04:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:04:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:04:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:05:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:05:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.790588, avg_loss=0.664147, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:05:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:05:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:05:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:05:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2074MB allocated=1929MB
2025-10-10 06:05:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.06132823228836, 'train_avg_loss': 0.6671777352690696, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:05:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.79058837890625, 'train_avg_loss': 0.6641470591227213, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:05:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 318.79058837890625, 'train_avg_loss': 0.6641470591227213, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:05:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:05:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:06:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:06:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.321045, avg_loss=0.688169, seen=480, correct=267, accuracy=0.556250
2025-10-10 06:06:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:06:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:06:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2064MB allocated=1929MB
2025-10-10 06:06:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.67527723312378, 'train_avg_loss': 0.6806273102760315, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:06:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.321044921875, 'train_avg_loss': 0.6881688435872396, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:06:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 330.321044921875, 'train_avg_loss': 0.6881688435872396, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:06:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:06:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:06:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:06:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.367981, avg_loss=0.671600, seen=480, correct=281, accuracy=0.585417
2025-10-10 06:06:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:06:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:06:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2064MB allocated=1929MB
2025-10-10 06:06:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.39058423042297, 'train_avg_loss': 0.7032548685868582, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:06:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.36798095703125, 'train_avg_loss': 0.6715999603271484, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:06:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 322.36798095703125, 'train_avg_loss': 0.6715999603271484, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:06:52 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #37) -------------
2025-10-10 06:06:52 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=37 aidx=1 | s=5 (candidates=16)
2025-10-10 06:06:52 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 47, 45, 26, 28] (from 16)
2025-10-10 06:06:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:06:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:06:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-10 06:06:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:06:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:06:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:06:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:06:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:07:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:07:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.159149, avg_loss=0.696165, seen=480, correct=254, accuracy=0.529167
2025-10-10 06:07:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:07:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:07:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:07:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2064MB allocated=1929MB
2025-10-10 06:07:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.4187490940094, 'train_avg_loss': 0.686822909116745, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:07:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1591491699219, 'train_avg_loss': 0.696164894104004, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:07:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 334.1591491699219, 'train_avg_loss': 0.696164894104004, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:07:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:07:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:07:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:08:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:08:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.713776, avg_loss=0.663987, seen=480, correct=285, accuracy=0.593750
2025-10-10 06:08:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:08:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:08:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:08:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2068MB allocated=1929MB
2025-10-10 06:08:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.67080187797546, 'train_avg_loss': 0.6639233489831289, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:08:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.7137756347656, 'train_avg_loss': 0.6639870325724284, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:08:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 318.7137756347656, 'train_avg_loss': 0.6639870325724284, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:08:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:08:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:08:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:08:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:08:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.878601, avg_loss=0.680997, seen=480, correct=268, accuracy=0.558333
2025-10-10 06:08:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:08:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:08:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:08:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2068MB allocated=1929MB
2025-10-10 06:08:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66222888231277, 'train_avg_loss': 0.6805185740192731, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:08:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.87860107421875, 'train_avg_loss': 0.680997085571289, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:08:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 326.87860107421875, 'train_avg_loss': 0.680997085571289, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:08:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:09:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:09:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:09:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:09:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.516083, avg_loss=0.686492, seen=480, correct=268, accuracy=0.558333
2025-10-10 06:09:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:09:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:09:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2064MB allocated=1929MB
2025-10-10 06:09:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58060187101364, 'train_avg_loss': 0.6798383489251136, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:09:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5160827636719, 'train_avg_loss': 0.6864918390909831, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:09:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 329.5160827636719, 'train_avg_loss': 0.6864918390909831, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:09:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:09:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:09:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:10:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:10:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.645874, avg_loss=0.678429, seen=480, correct=264, accuracy=0.550000
2025-10-10 06:10:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:10:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:10:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:10:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2064MB allocated=1929MB
2025-10-10 06:10:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.21264749765396, 'train_avg_loss': 0.685105395813783, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 06:10:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6458740234375, 'train_avg_loss': 0.6784289042154948, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:10:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 325.6458740234375, 'train_avg_loss': 0.6784289042154948, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:10:24 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #38) -------------
2025-10-10 06:10:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=38 aidx=1 | s=5 (candidates=16)
2025-10-10 06:10:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 20, 51, 40, 1] (from 16)
2025-10-10 06:10:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 06:10:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:10:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:11:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:11:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.282013, avg_loss=0.667254, seen=480, correct=272, accuracy=0.566667
2025-10-10 06:11:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:11:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:11:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2096MB allocated=1929MB
2025-10-10 06:11:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.87333983182907, 'train_avg_loss': 0.6739444985985756, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:11:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.2820129394531, 'train_avg_loss': 0.6672541936238606, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:11:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 320.2820129394531, 'train_avg_loss': 0.6672541936238606, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:11:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 06:11:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:11:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:11:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:11:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.841644, avg_loss=0.637170, seen=480, correct=310, accuracy=0.645833
2025-10-10 06:11:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:11:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:11:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2102MB allocated=1929MB
2025-10-10 06:11:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.52962666749954, 'train_avg_loss': 0.6544135555624961, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:11:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.8416442871094, 'train_avg_loss': 0.6371700922648112, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:11:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 305.8416442871094, 'train_avg_loss': 0.6371700922648112, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:11:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 06:11:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:11:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:12:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:12:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.461945, avg_loss=0.648879, seen=480, correct=302, accuracy=0.629167
2025-10-10 06:12:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:12:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:12:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2110MB allocated=1929MB
2025-10-10 06:12:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62543749809265, 'train_avg_loss': 0.6802119791507721, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:12:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.4619445800781, 'train_avg_loss': 0.6488790512084961, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:12:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 311.4619445800781, 'train_avg_loss': 0.6488790512084961, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:12:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:12:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:12:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-10 06:12:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 06:12:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:12:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:12:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:12:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:13:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:13:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.909363, avg_loss=0.689395, seen=480, correct=267, accuracy=0.556250
2025-10-10 06:13:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:13:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:13:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:13:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2064MB allocated=1929MB
2025-10-10 06:13:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.27168029546738, 'train_avg_loss': 0.7189306691288948, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 06:13:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.90936279296875, 'train_avg_loss': 0.6893945058186849, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:13:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 330.90936279296875, 'train_avg_loss': 0.6893945058186849, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:13:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:13:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:13:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-10 06:13:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:13:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:13:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:13:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:13:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:13:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:13:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:13:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.091736, avg_loss=0.696024, seen=480, correct=256, accuracy=0.533333
2025-10-10 06:13:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:13:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:14:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2064MB allocated=1929MB
2025-10-10 06:14:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74333477020264, 'train_avg_loss': 0.6895277897516886, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:14:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.09173583984375, 'train_avg_loss': 0.6960244496663411, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 06:14:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 334.09173583984375, 'train_avg_loss': 0.6960244496663411, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 06:14:01 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #39) -------------
2025-10-10 06:14:02 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=39 aidx=1 | s=5 (candidates=16)
2025-10-10 06:14:02 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 15, 28, 22, 16] (from 16)
2025-10-10 06:14:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:14:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:14:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:14:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:14:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.629395, avg_loss=0.680478, seen=480, correct=267, accuracy=0.556250
2025-10-10 06:14:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:14:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:14:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2086MB allocated=1929MB
2025-10-10 06:14:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.6030837893486, 'train_avg_loss': 0.7050256982445717, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 06:14:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.62939453125, 'train_avg_loss': 0.6804779052734375, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:14:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 326.62939453125, 'train_avg_loss': 0.6804779052734375, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:14:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:14:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:14:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:15:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:15:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.812439, avg_loss=0.664193, seen=480, correct=291, accuracy=0.606250
2025-10-10 06:15:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:15:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:15:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2064MB allocated=1929MB
2025-10-10 06:15:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.01186019182205, 'train_avg_loss': 0.6917655015985171, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:15:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.81243896484375, 'train_avg_loss': 0.6641925811767578, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 06:15:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 318.81243896484375, 'train_avg_loss': 0.6641925811767578, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 06:15:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:15:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:15:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:16:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:16:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.031708, avg_loss=0.668816, seen=480, correct=280, accuracy=0.583333
2025-10-10 06:16:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:16:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:16:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2064MB allocated=1929MB
2025-10-10 06:16:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39324861764908, 'train_avg_loss': 0.669943738480409, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:16:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.0317077636719, 'train_avg_loss': 0.6688160578409831, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:16:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 321.0317077636719, 'train_avg_loss': 0.6688160578409831, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:16:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:16:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:16:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-10 06:16:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:16:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:16:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:16:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:16:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:16:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:16:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.854675, avg_loss=0.655947, seen=480, correct=302, accuracy=0.629167
2025-10-10 06:16:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:16:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:16:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2104MB allocated=1929MB
2025-10-10 06:16:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.87633013725281, 'train_avg_loss': 0.6573027511437733, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:16:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.85467529296875, 'train_avg_loss': 0.6559472401936849, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:16:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 314.85467529296875, 'train_avg_loss': 0.6559472401936849, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:16:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 06:16:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:16:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:17:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:17:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.334015, avg_loss=0.673613, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:17:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:17:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:17:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:17:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2104MB allocated=1929MB
2025-10-10 06:17:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.88469815254211, 'train_avg_loss': 0.640705817937851, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:17:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.3340148925781, 'train_avg_loss': 0.6736125310262044, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:17:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 323.3340148925781, 'train_avg_loss': 0.6736125310262044, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:17:34 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #40) -------------
2025-10-10 06:17:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=40 aidx=1 | s=5 (candidates=16)
2025-10-10 06:17:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 20, 40, 48, 6] (from 16)
2025-10-10 06:17:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:17:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:17:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:18:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:18:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.418549, avg_loss=0.684205, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:18:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:18:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:18:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2064MB allocated=1929MB
2025-10-10 06:18:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.46884828805923, 'train_avg_loss': 0.670573735733827, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:18:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4185485839844, 'train_avg_loss': 0.6842053095499675, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:18:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 328.4185485839844, 'train_avg_loss': 0.6842053095499675, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:18:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:18:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:18:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-10 06:18:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 06:18:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:18:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:18:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:18:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:19:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:19:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.703003, avg_loss=0.641048, seen=480, correct=310, accuracy=0.645833
2025-10-10 06:19:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:19:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:19:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2102MB allocated=1929MB
2025-10-10 06:19:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.39862143993378, 'train_avg_loss': 0.6616551786661148, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:19:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.7030029296875, 'train_avg_loss': 0.6410479227701823, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:19:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 307.7030029296875, 'train_avg_loss': 0.6410479227701823, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:19:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:19:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:19:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-10 06:19:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 06:19:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:19:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:19:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:19:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:19:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:19:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.937256, avg_loss=0.687369, seen=480, correct=274, accuracy=0.570833
2025-10-10 06:19:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:19:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:19:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2064MB allocated=1929MB
2025-10-10 06:19:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.27498972415924, 'train_avg_loss': 0.7106249143679937, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 06:19:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.937255859375, 'train_avg_loss': 0.6873692830403646, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:19:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 329.937255859375, 'train_avg_loss': 0.6873692830403646, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:19:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:19:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:19:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:20:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:20:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.467957, avg_loss=0.678058, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:20:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:20:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:20:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:20:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2086MB allocated=1929MB
2025-10-10 06:20:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93353569507599, 'train_avg_loss': 0.6994461307922999, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 06:20:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.46795654296875, 'train_avg_loss': 0.6780582427978515, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:20:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 325.46795654296875, 'train_avg_loss': 0.6780582427978515, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:20:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 06:20:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:20:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:21:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:21:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.636169, avg_loss=0.667992, seen=480, correct=281, accuracy=0.585417
2025-10-10 06:21:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:21:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:21:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2074MB allocated=1929MB
2025-10-10 06:21:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.23891484737396, 'train_avg_loss': 0.6686576237281163, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 06:21:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.63616943359375, 'train_avg_loss': 0.6679920196533203, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:21:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 320.63616943359375, 'train_avg_loss': 0.6679920196533203, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:21:18 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #41) -------------
2025-10-10 06:21:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=41 aidx=1 | s=5 (candidates=16)
2025-10-10 06:21:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 6, 40, 22, 28] (from 16)
2025-10-10 06:21:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:21:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:21:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:22:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:22:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.764679, avg_loss=0.676593, seen=480, correct=275, accuracy=0.572917
2025-10-10 06:22:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:22:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:22:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2086MB allocated=1929MB
2025-10-10 06:22:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.38706493377686, 'train_avg_loss': 0.7032255411148072, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 06:22:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7646789550781, 'train_avg_loss': 0.6765930811564128, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:22:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 324.7646789550781, 'train_avg_loss': 0.6765930811564128, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:22:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:22:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:22:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-10 06:22:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 06:22:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:22:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:22:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:22:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:22:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:22:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.094116, avg_loss=0.654363, seen=480, correct=290, accuracy=0.604167
2025-10-10 06:22:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:22:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:22:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2074MB allocated=1929MB
2025-10-10 06:22:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.71612504124641, 'train_avg_loss': 0.6476343753437201, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:22:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.0941162109375, 'train_avg_loss': 0.6543627421061198, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:22:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 314.0941162109375, 'train_avg_loss': 0.6543627421061198, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:22:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 06:22:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:22:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:23:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:23:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.287201, avg_loss=0.688098, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:23:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:23:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:23:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:23:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2064MB allocated=1929MB
2025-10-10 06:23:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.31323105096817, 'train_avg_loss': 0.7192769254247348, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 06:23:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.2872009277344, 'train_avg_loss': 0.6880983352661133, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:23:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 330.2872009277344, 'train_avg_loss': 0.6880983352661133, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:23:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:23:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:23:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:24:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:24:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.172668, avg_loss=0.652443, seen=480, correct=298, accuracy=0.620833
2025-10-10 06:24:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:24:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:24:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2104MB allocated=1929MB
2025-10-10 06:24:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.40953534841537, 'train_avg_loss': 0.6700794612367947, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:24:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.17266845703125, 'train_avg_loss': 0.6524430592854817, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 06:24:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 313.17266845703125, 'train_avg_loss': 0.6524430592854817, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 06:24:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:24:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:24:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:24:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:24:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.866150, avg_loss=0.666388, seen=480, correct=281, accuracy=0.585417
2025-10-10 06:24:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:24:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:24:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2064MB allocated=1929MB
2025-10-10 06:24:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.91920125484467, 'train_avg_loss': 0.6743266771237055, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:24:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.86614990234375, 'train_avg_loss': 0.6663878122965495, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:24:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 319.86614990234375, 'train_avg_loss': 0.6663878122965495, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:24:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #42) -------------
2025-10-10 06:24:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=42 aidx=1 | s=5 (candidates=16)
2025-10-10 06:24:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 51, 34, 45, 43] (from 16)
2025-10-10 06:24:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:24:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:24:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:25:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:25:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.133545, avg_loss=0.658612, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:25:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:25:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:25:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2064MB allocated=1929MB
2025-10-10 06:25:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.69345200061798, 'train_avg_loss': 0.6891121000051499, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:25:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.133544921875, 'train_avg_loss': 0.658611551920573, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:25:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 316.133544921875, 'train_avg_loss': 0.658611551920573, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:25:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:25:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:25:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-10 06:25:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 06:25:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:25:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:25:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:25:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:25:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:26:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:26:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.242126, avg_loss=0.648421, seen=480, correct=296, accuracy=0.616667
2025-10-10 06:26:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:26:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:26:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:26:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2110MB allocated=1929MB
2025-10-10 06:26:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.53554916381836, 'train_avg_loss': 0.6794629096984863, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:26:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.24212646484375, 'train_avg_loss': 0.6484210968017579, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:26:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 311.24212646484375, 'train_avg_loss': 0.6484210968017579, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:26:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:26:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:27:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:27:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.508362, avg_loss=0.678142, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:27:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:27:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:27:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2082MB allocated=1929MB
2025-10-10 06:27:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.92695009708405, 'train_avg_loss': 0.6910579174757003, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:27:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.50836181640625, 'train_avg_loss': 0.6781424204508464, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:27:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 325.50836181640625, 'train_avg_loss': 0.6781424204508464, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:27:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:27:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:27:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:27:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.951477, avg_loss=0.679066, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:27:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:27:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:27:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2068MB allocated=1929MB
2025-10-10 06:27:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.27704405784607, 'train_avg_loss': 0.6773087004820506, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:27:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.95147705078125, 'train_avg_loss': 0.6790655771891276, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:27:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 325.95147705078125, 'train_avg_loss': 0.6790655771891276, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:27:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 06:27:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:27:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:28:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:28:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.376709, avg_loss=0.648701, seen=480, correct=294, accuracy=0.612500
2025-10-10 06:28:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:28:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:28:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:28:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2124MB allocated=1929MB
2025-10-10 06:28:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.25424575805664, 'train_avg_loss': 0.6687853813171387, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:28:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.376708984375, 'train_avg_loss': 0.6487014770507813, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 06:28:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 311.376708984375, 'train_avg_loss': 0.6487014770507813, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 06:28:31 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #43) -------------
2025-10-10 06:28:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=43 aidx=1 | s=5 (candidates=16)
2025-10-10 06:28:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 47, 20, 45, 1] (from 16)
2025-10-10 06:28:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 06:28:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:28:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:29:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:29:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.072205, avg_loss=0.664734, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:29:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:29:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:29:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2096MB allocated=1929MB
2025-10-10 06:29:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.26329100131989, 'train_avg_loss': 0.6688607583443323, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:29:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.07220458984375, 'train_avg_loss': 0.6647337595621745, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:29:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 319.07220458984375, 'train_avg_loss': 0.6647337595621745, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:29:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:29:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:29:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:29:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:29:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:29:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.274902, avg_loss=0.660989, seen=480, correct=290, accuracy=0.604167
2025-10-10 06:29:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:29:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:29:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2070MB allocated=1929MB
2025-10-10 06:29:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.8337065577507, 'train_avg_loss': 0.6486142213145892, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:29:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.27490234375, 'train_avg_loss': 0.6609893798828125, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:29:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 317.27490234375, 'train_avg_loss': 0.6609893798828125, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:29:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:29:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:29:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 06:29:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:30:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:30:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.153168, avg_loss=0.623236, seen=480, correct=316, accuracy=0.658333
2025-10-10 06:30:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:30:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:30:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:30:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2102MB allocated=1929MB
2025-10-10 06:30:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.25287294387817, 'train_avg_loss': 0.6437739411989848, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:30:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.1531677246094, 'train_avg_loss': 0.6232357660929362, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 06:30:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 299.1531677246094, 'train_avg_loss': 0.6232357660929362, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 06:30:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:30:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:30:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:31:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:31:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.992096, avg_loss=0.674984, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:31:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:31:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:31:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:31:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2068MB allocated=1929MB
2025-10-10 06:31:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.80467963218689, 'train_avg_loss': 0.6650389969348908, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:31:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.9920959472656, 'train_avg_loss': 0.67498353322347, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:31:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 323.9920959472656, 'train_avg_loss': 0.67498353322347, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:31:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:31:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:31:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-10 06:31:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:31:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:31:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:31:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:31:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:31:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:32:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:32:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.752411, avg_loss=0.686984, seen=480, correct=264, accuracy=0.550000
2025-10-10 06:32:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:32:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:32:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2064MB allocated=1929MB
2025-10-10 06:32:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.39605367183685, 'train_avg_loss': 0.6866337805986404, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:32:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7524108886719, 'train_avg_loss': 0.6869841893513997, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:32:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 329.7524108886719, 'train_avg_loss': 0.6869841893513997, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:32:08 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #44) -------------
2025-10-10 06:32:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=44 aidx=1 | s=5 (candidates=16)
2025-10-10 06:32:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 15, 20, 48, 28] (from 16)
2025-10-10 06:32:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:32:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:32:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-10 06:32:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 06:32:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:32:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:32:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:32:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:32:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:32:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.488190, avg_loss=0.648934, seen=480, correct=302, accuracy=0.629167
2025-10-10 06:32:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:32:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:32:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2110MB allocated=1929MB
2025-10-10 06:32:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5902087688446, 'train_avg_loss': 0.6799184064070384, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:32:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.4881896972656, 'train_avg_loss': 0.6489337285359701, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:32:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 311.4881896972656, 'train_avg_loss': 0.6489337285359701, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 06:32:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:32:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:32:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-10 06:32:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:32:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:32:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:32:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:32:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:33:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:33:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.433411, avg_loss=0.657153, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:33:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:33:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:33:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:33:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2064MB allocated=1929MB
2025-10-10 06:33:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.33253663778305, 'train_avg_loss': 0.6861044719815255, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:33:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.43341064453125, 'train_avg_loss': 0.6571529388427735, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:33:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 315.43341064453125, 'train_avg_loss': 0.6571529388427735, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:33:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:33:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:33:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-10 06:33:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 06:33:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:33:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:33:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:33:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:33:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:34:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:34:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.863281, avg_loss=0.626799, seen=480, correct=310, accuracy=0.645833
2025-10-10 06:34:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:34:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:34:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:34:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2102MB allocated=1929MB
2025-10-10 06:34:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.28979980945587, 'train_avg_loss': 0.6440816650787989, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:34:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.86328125, 'train_avg_loss': 0.6267985026041667, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:34:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 300.86328125, 'train_avg_loss': 0.6267985026041667, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:34:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:34:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:34:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:34:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:34:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.145813, avg_loss=0.673220, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:34:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:34:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:35:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2086MB allocated=1929MB
2025-10-10 06:35:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.91074568033218, 'train_avg_loss': 0.7075895473361016, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 06:35:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.14581298828125, 'train_avg_loss': 0.673220443725586, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:35:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 323.14581298828125, 'train_avg_loss': 0.673220443725586, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:35:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:35:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:35:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:35:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:35:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.155670, avg_loss=0.652408, seen=480, correct=299, accuracy=0.622917
2025-10-10 06:35:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:35:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:35:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2064MB allocated=1929MB
2025-10-10 06:35:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.41749995946884, 'train_avg_loss': 0.653479166328907, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:35:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.1556701660156, 'train_avg_loss': 0.6524076461791992, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 06:35:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 313.1556701660156, 'train_avg_loss': 0.6524076461791992, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 06:35:42 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #45) -------------
2025-10-10 06:35:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=45 aidx=1 | s=5 (candidates=16)
2025-10-10 06:35:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 22, 43, 1, 45] (from 16)
2025-10-10 06:35:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 06:35:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:35:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:36:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:36:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.647278, avg_loss=0.682598, seen=480, correct=277, accuracy=0.577083
2025-10-10 06:36:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:36:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:36:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2064MB allocated=1929MB
2025-10-10 06:36:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.06466102600098, 'train_avg_loss': 0.7088721752166748, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:36:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.64727783203125, 'train_avg_loss': 0.6825984954833985, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 06:36:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 327.64727783203125, 'train_avg_loss': 0.6825984954833985, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 06:36:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:36:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:36:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:37:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:37:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.273376, avg_loss=0.646403, seen=480, correct=303, accuracy=0.631250
2025-10-10 06:37:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:37:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:37:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2104MB allocated=1929MB
2025-10-10 06:37:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.11326360702515, 'train_avg_loss': 0.6509438633918763, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:37:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.27337646484375, 'train_avg_loss': 0.6464028676350911, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 06:37:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 310.27337646484375, 'train_avg_loss': 0.6464028676350911, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 06:37:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 06:37:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:37:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:37:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:37:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.566681, avg_loss=0.630347, seen=480, correct=309, accuracy=0.643750
2025-10-10 06:37:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:37:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:37:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2124MB allocated=1929MB
2025-10-10 06:37:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.37385058403015, 'train_avg_loss': 0.6531154215335846, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:37:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.5666809082031, 'train_avg_loss': 0.6303472518920898, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 06:37:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 302.5666809082031, 'train_avg_loss': 0.6303472518920898, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 06:37:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:37:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:37:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:38:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:38:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.493958, avg_loss=0.682279, seen=480, correct=267, accuracy=0.556250
2025-10-10 06:38:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:38:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:38:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:38:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2064MB allocated=1929MB
2025-10-10 06:38:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98644196987152, 'train_avg_loss': 0.6832203497489293, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:38:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.49395751953125, 'train_avg_loss': 0.6822790781656901, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:38:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 327.49395751953125, 'train_avg_loss': 0.6822790781656901, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 06:38:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:38:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:38:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:39:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:39:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.536499, avg_loss=0.674034, seen=480, correct=282, accuracy=0.587500
2025-10-10 06:39:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:39:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:39:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2068MB allocated=1929MB
2025-10-10 06:39:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.02347111701965, 'train_avg_loss': 0.6668622593084971, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:39:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.5364990234375, 'train_avg_loss': 0.6740343729654948, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 06:39:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 323.5364990234375, 'train_avg_loss': 0.6740343729654948, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 06:39:18 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #46) -------------
2025-10-10 06:39:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=46 aidx=1 | s=5 (candidates=16)
2025-10-10 06:39:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 15, 51, 16, 22] (from 16)
2025-10-10 06:39:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:39:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:39:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:39:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.760620, avg_loss=0.676585, seen=480, correct=277, accuracy=0.577083
2025-10-10 06:39:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:39:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:40:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2064MB allocated=1929MB
2025-10-10 06:40:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.99809110164642, 'train_avg_loss': 0.6749840925137202, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:40:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7606201171875, 'train_avg_loss': 0.6765846252441406, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 06:40:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 324.7606201171875, 'train_avg_loss': 0.6765846252441406, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 06:40:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:40:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:40:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:40:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:40:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.210327, avg_loss=0.656688, seen=480, correct=296, accuracy=0.616667
2025-10-10 06:40:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:40:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:40:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2064MB allocated=1929MB
2025-10-10 06:40:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.7064278125763, 'train_avg_loss': 0.6808868984381358, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:40:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.2103271484375, 'train_avg_loss': 0.6566881815592448, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:40:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 315.2103271484375, 'train_avg_loss': 0.6566881815592448, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:40:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 06:40:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:40:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:41:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:41:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.257629, avg_loss=0.648453, seen=480, correct=297, accuracy=0.618750
2025-10-10 06:41:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:41:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:41:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2110MB allocated=1929MB
2025-10-10 06:41:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.92801368236542, 'train_avg_loss': 0.6827334473530452, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 06:41:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.25762939453125, 'train_avg_loss': 0.6484533945719401, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 06:41:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 311.25762939453125, 'train_avg_loss': 0.6484533945719401, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 06:41:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 06:41:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:41:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:42:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:42:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.555634, avg_loss=0.653241, seen=480, correct=296, accuracy=0.616667
2025-10-10 06:42:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:42:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:42:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2104MB allocated=1929MB
2025-10-10 06:42:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.90222430229187, 'train_avg_loss': 0.6158518691857656, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 06:42:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.5556335449219, 'train_avg_loss': 0.6532409032185872, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:42:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 313.5556335449219, 'train_avg_loss': 0.6532409032185872, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:42:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:42:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:42:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:42:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:42:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.987732, avg_loss=0.647891, seen=480, correct=301, accuracy=0.627083
2025-10-10 06:42:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:42:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:42:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2104MB allocated=1929MB
2025-10-10 06:42:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.15736347436905, 'train_avg_loss': 0.6513113622864087, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:42:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.98773193359375, 'train_avg_loss': 0.647891108194987, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 06:42:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 310.98773193359375, 'train_avg_loss': 0.647891108194987, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 06:42:49 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #47) -------------
2025-10-10 06:42:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=47 aidx=1 | s=5 (candidates=16)
2025-10-10 06:42:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 34, 20, 48, 45] (from 16)
2025-10-10 06:42:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:42:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:42:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:43:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:43:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.729584, avg_loss=0.657770, seen=480, correct=295, accuracy=0.614583
2025-10-10 06:43:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:43:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:43:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:43:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2064MB allocated=1929MB
2025-10-10 06:43:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.86050927639008, 'train_avg_loss': 0.682170910636584, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:43:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.7295837402344, 'train_avg_loss': 0.6577699661254883, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 06:43:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 315.7295837402344, 'train_avg_loss': 0.6577699661254883, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 06:43:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:43:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:43:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-10 06:43:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:43:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:43:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:43:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:43:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:43:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:44:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:44:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.418945, avg_loss=0.675873, seen=480, correct=280, accuracy=0.583333
2025-10-10 06:44:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:44:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:44:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2082MB allocated=1929MB
2025-10-10 06:44:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.03246939182281, 'train_avg_loss': 0.6919372449318568, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:44:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.4189453125, 'train_avg_loss': 0.675872802734375, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:44:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 324.4189453125, 'train_avg_loss': 0.675872802734375, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:44:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 06:44:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:44:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:44:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:44:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.481201, avg_loss=0.626003, seen=480, correct=305, accuracy=0.635417
2025-10-10 06:44:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:44:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:44:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2102MB allocated=1929MB
2025-10-10 06:44:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.83475387096405, 'train_avg_loss': 0.6402896155913671, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:44:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.481201171875, 'train_avg_loss': 0.6260025024414062, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 06:44:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 300.481201171875, 'train_avg_loss': 0.6260025024414062, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 06:44:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:44:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:44:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-10 06:44:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:44:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:44:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:44:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:44:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:45:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:45:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.029388, avg_loss=0.668811, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:45:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:45:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:45:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2086MB allocated=1929MB
2025-10-10 06:45:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.3524666428566, 'train_avg_loss': 0.7112705553571383, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 06:45:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.0293884277344, 'train_avg_loss': 0.6688112258911133, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:45:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 321.0293884277344, 'train_avg_loss': 0.6688112258911133, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:45:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:45:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:45:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:46:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:46:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.795593, avg_loss=0.664157, seen=480, correct=282, accuracy=0.587500
2025-10-10 06:46:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:46:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:46:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:46:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2068MB allocated=1929MB
2025-10-10 06:46:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.44924515485764, 'train_avg_loss': 0.662077042957147, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:46:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.79559326171875, 'train_avg_loss': 0.664157485961914, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 06:46:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 318.79559326171875, 'train_avg_loss': 0.664157485961914, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 06:46:24 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #48) -------------
2025-10-10 06:46:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=48 aidx=1 | s=5 (candidates=16)
2025-10-10 06:46:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 28, 48, 43, 15] (from 16)
2025-10-10 06:46:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:46:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:46:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:47:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:47:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.008759, avg_loss=0.656268, seen=480, correct=287, accuracy=0.597917
2025-10-10 06:47:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:47:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:47:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2068MB allocated=1929MB
2025-10-10 06:47:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.40414214134216, 'train_avg_loss': 0.6533678511778513, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:47:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.0087585449219, 'train_avg_loss': 0.6562682469685872, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 06:47:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 315.0087585449219, 'train_avg_loss': 0.6562682469685872, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 06:47:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:47:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:47:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:47:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:47:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.545288, avg_loss=0.642803, seen=480, correct=310, accuracy=0.645833
2025-10-10 06:47:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:47:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:47:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2064MB allocated=1929MB
2025-10-10 06:47:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.60635185241699, 'train_avg_loss': 0.6383862654368083, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 06:47:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.5452880859375, 'train_avg_loss': 0.6428026835123698, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:47:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 308.5452880859375, 'train_avg_loss': 0.6428026835123698, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 06:47:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:47:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:47:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:48:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:48:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.578949, avg_loss=0.663706, seen=480, correct=281, accuracy=0.585417
2025-10-10 06:48:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:48:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:48:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2086MB allocated=1929MB
2025-10-10 06:48:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.88503289222717, 'train_avg_loss': 0.7073752741018932, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 06:48:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.5789489746094, 'train_avg_loss': 0.6637061436971029, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:48:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 318.5789489746094, 'train_avg_loss': 0.6637061436971029, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 06:48:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 06:48:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:48:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:49:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:49:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.868652, avg_loss=0.630976, seen=480, correct=321, accuracy=0.668750
2025-10-10 06:49:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:49:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:49:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:49:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2124MB allocated=1929MB
2025-10-10 06:49:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.10650742053986, 'train_avg_loss': 0.6592208951711654, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:49:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.86865234375, 'train_avg_loss': 0.6309763590494791, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 06:49:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 302.86865234375, 'train_avg_loss': 0.6309763590494791, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 06:49:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:49:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:49:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-10 06:49:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:49:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:49:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:49:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:49:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:49:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:49:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:49:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.352722, avg_loss=0.656985, seen=480, correct=301, accuracy=0.627083
2025-10-10 06:49:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:49:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:50:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2064MB allocated=1929MB
2025-10-10 06:50:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.85708206892014, 'train_avg_loss': 0.6821423505743345, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:50:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.35272216796875, 'train_avg_loss': 0.6569848378499349, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 06:50:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 315.35272216796875, 'train_avg_loss': 0.6569848378499349, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 06:50:01 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #49) -------------
2025-10-10 06:50:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=49 aidx=1 | s=5 (candidates=16)
2025-10-10 06:50:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 22, 1, 48, 28] (from 16)
2025-10-10 06:50:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:50:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:50:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-10 06:50:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:50:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:50:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:50:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:50:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:50:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:50:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.540649, avg_loss=0.657376, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:50:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:50:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:50:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2070MB allocated=1929MB
2025-10-10 06:50:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77541363239288, 'train_avg_loss': 0.6481284469366073, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 06:50:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.5406494140625, 'train_avg_loss': 0.6573763529459635, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:50:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 315.5406494140625, 'train_avg_loss': 0.6573763529459635, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:50:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 06:50:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:50:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:51:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:51:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.625183, avg_loss=0.615886, seen=480, correct=325, accuracy=0.677083
2025-10-10 06:51:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:51:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:51:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:51:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2104MB allocated=1929MB
2025-10-10 06:51:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.90042620897293, 'train_avg_loss': 0.6158368850747744, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 06:51:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.62518310546875, 'train_avg_loss': 0.6158857981363932, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 06:51:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 295.62518310546875, 'train_avg_loss': 0.6158857981363932, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 06:51:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:51:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:51:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:52:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:52:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.247040, avg_loss=0.675515, seen=480, correct=273, accuracy=0.568750
2025-10-10 06:52:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:52:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:52:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2064MB allocated=1929MB
2025-10-10 06:52:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.66989207267761, 'train_avg_loss': 0.6722491006056468, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:52:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.2470397949219, 'train_avg_loss': 0.6755146662394206, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 06:52:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 324.2470397949219, 'train_avg_loss': 0.6755146662394206, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 06:52:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 06:52:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:52:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:52:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:52:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.668610, avg_loss=0.665976, seen=480, correct=280, accuracy=0.583333
2025-10-10 06:52:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:52:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:52:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2086MB allocated=1929MB
2025-10-10 06:52:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.13063710927963, 'train_avg_loss': 0.7094219759106636, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 06:52:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.6686096191406, 'train_avg_loss': 0.6659762700398763, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:52:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 319.6686096191406, 'train_avg_loss': 0.6659762700398763, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:52:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:52:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:52:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-10 06:52:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 06:52:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:52:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:52:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:52:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:53:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:53:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.591583, avg_loss=0.636649, seen=480, correct=312, accuracy=0.650000
2025-10-10 06:53:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:53:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:53:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:53:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2064MB allocated=1929MB
2025-10-10 06:53:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.23833513259888, 'train_avg_loss': 0.635319459438324, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:53:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.5915832519531, 'train_avg_loss': 0.6366491317749023, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 06:53:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 305.5915832519531, 'train_avg_loss': 0.6366491317749023, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 06:53:35 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #50) -------------
2025-10-10 06:53:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=50 aidx=1 | s=5 (candidates=16)
2025-10-10 06:53:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[43, 34, 45, 47, 15] (from 16)
2025-10-10 06:53:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 06:53:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:53:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:54:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:54:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.145996, avg_loss=0.627387, seen=480, correct=308, accuracy=0.641667
2025-10-10 06:54:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:54:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:54:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:54:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2124MB allocated=1929MB
2025-10-10 06:54:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.92147636413574, 'train_avg_loss': 0.6493456363677979, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 06:54:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.14599609375, 'train_avg_loss': 0.6273874918619792, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 06:54:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 301.14599609375, 'train_avg_loss': 0.6273874918619792, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 06:54:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:54:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:54:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:55:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:55:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.315521, avg_loss=0.677741, seen=480, correct=289, accuracy=0.602083
2025-10-10 06:55:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:55:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:55:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2082MB allocated=1929MB
2025-10-10 06:55:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.42250889539719, 'train_avg_loss': 0.6951875741283099, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:55:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.3155212402344, 'train_avg_loss': 0.6777406692504883, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 06:55:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 325.3155212402344, 'train_avg_loss': 0.6777406692504883, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 06:55:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:55:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:55:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:55:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:55:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.653778, avg_loss=0.653445, seen=480, correct=298, accuracy=0.620833
2025-10-10 06:55:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:55:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:55:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2068MB allocated=1929MB
2025-10-10 06:55:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.18006139993668, 'train_avg_loss': 0.6431671783328057, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:55:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.6537780761719, 'train_avg_loss': 0.6534453709920247, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 06:55:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 313.6537780761719, 'train_avg_loss': 0.6534453709920247, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 06:55:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:55:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:55:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-10 06:55:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:55:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:55:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:55:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:55:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:56:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:56:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.275696, avg_loss=0.658908, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:56:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:56:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:56:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:56:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2072MB allocated=1929MB
2025-10-10 06:56:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.59978157281876, 'train_avg_loss': 0.638331513106823, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:56:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.27569580078125, 'train_avg_loss': 0.658907699584961, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:56:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 316.27569580078125, 'train_avg_loss': 0.658907699584961, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:56:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:56:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:56:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-10 06:56:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:56:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:56:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:56:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:56:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:56:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:57:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:57:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.939758, avg_loss=0.643624, seen=480, correct=308, accuracy=0.641667
2025-10-10 06:57:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:57:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:57:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2064MB allocated=1929MB
2025-10-10 06:57:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.86402899026871, 'train_avg_loss': 0.6738669082522393, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:57:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.93975830078125, 'train_avg_loss': 0.6436244964599609, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 06:57:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 308.93975830078125, 'train_avg_loss': 0.6436244964599609, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 06:57:14 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #51) -------------
2025-10-10 06:57:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=51 aidx=1 | s=5 (candidates=16)
2025-10-10 06:57:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 26, 47, 15, 43] (from 16)
2025-10-10 06:57:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:57:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:57:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:57:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:57:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.472870, avg_loss=0.673902, seen=480, correct=284, accuracy=0.591667
2025-10-10 06:57:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:57:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:57:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2082MB allocated=1929MB
2025-10-10 06:57:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.58861118555069, 'train_avg_loss': 0.6965717598795891, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:57:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4728698730469, 'train_avg_loss': 0.6739018122355144, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 06:57:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 323.4728698730469, 'train_avg_loss': 0.6739018122355144, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 06:57:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:58:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:58:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:58:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:58:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.390930, avg_loss=0.675814, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:58:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:58:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:58:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:58:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2064MB allocated=1929MB
2025-10-10 06:58:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.83967706561089, 'train_avg_loss': 0.6569973088800907, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:58:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.39093017578125, 'train_avg_loss': 0.675814437866211, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:58:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 324.39093017578125, 'train_avg_loss': 0.675814437866211, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:58:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:58:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:58:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:59:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:59:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.414795, avg_loss=0.657114, seen=480, correct=294, accuracy=0.612500
2025-10-10 06:59:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:59:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:59:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:59:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2070MB allocated=1929MB
2025-10-10 06:59:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.30811876058578, 'train_avg_loss': 0.6442343230048816, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 06:59:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.414794921875, 'train_avg_loss': 0.6571141560872396, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 06:59:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 315.414794921875, 'train_avg_loss': 0.6571141560872396, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 06:59:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 06:59:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:59:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:00:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:00:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.923340, avg_loss=0.637340, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:00:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:00:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2064MB allocated=1929MB
2025-10-10 07:00:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.57017236948013, 'train_avg_loss': 0.6714181030790011, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:00:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.92333984375, 'train_avg_loss': 0.6373402913411458, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:00:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 305.92333984375, 'train_avg_loss': 0.6373402913411458, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:00:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:00:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:00:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:00:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:00:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.689941, avg_loss=0.626437, seen=480, correct=312, accuracy=0.650000
2025-10-10 07:00:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:00:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:00:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2124MB allocated=1929MB
2025-10-10 07:00:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.26269894838333, 'train_avg_loss': 0.6521891579031944, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 07:00:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.68994140625, 'train_avg_loss': 0.6264373779296875, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:00:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 300.68994140625, 'train_avg_loss': 0.6264373779296875, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:00:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #52) -------------
2025-10-10 07:00:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=52 aidx=1 | s=5 (candidates=16)
2025-10-10 07:00:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 6, 15, 34, 29] (from 16)
2025-10-10 07:00:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 07:00:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:00:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:01:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:01:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.294556, avg_loss=0.686030, seen=480, correct=276, accuracy=0.575000
2025-10-10 07:01:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:01:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:01:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:01:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2064MB allocated=1929MB
2025-10-10 07:01:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.366226375103, 'train_avg_loss': 0.711385219792525, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:01:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2945556640625, 'train_avg_loss': 0.6860303243001302, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:01:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 329.2945556640625, 'train_avg_loss': 0.6860303243001302, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:01:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:01:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:01:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 07:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:02:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:02:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.037506, avg_loss=0.654245, seen=480, correct=291, accuracy=0.606250
2025-10-10 07:02:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:02:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:02:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:02:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2074MB allocated=1929MB
2025-10-10 07:02:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.395223736763, 'train_avg_loss': 0.636626864473025, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:02:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.0375061035156, 'train_avg_loss': 0.6542448043823242, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 07:02:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 314.0375061035156, 'train_avg_loss': 0.6542448043823242, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 07:02:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 07:02:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:03:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:03:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.245331, avg_loss=0.635928, seen=480, correct=303, accuracy=0.631250
2025-10-10 07:03:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:03:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:03:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2064MB allocated=1929MB
2025-10-10 07:03:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.22361344099045, 'train_avg_loss': 0.676863445341587, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:03:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.2453308105469, 'train_avg_loss': 0.6359277725219726, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:03:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 305.2453308105469, 'train_avg_loss': 0.6359277725219726, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:03:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:03:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:03:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:03:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:03:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.537048, avg_loss=0.674036, seen=480, correct=288, accuracy=0.600000
2025-10-10 07:03:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:03:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:03:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2082MB allocated=1929MB
2025-10-10 07:03:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.4208373427391, 'train_avg_loss': 0.7118403111894925, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 07:03:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.53704833984375, 'train_avg_loss': 0.6740355173746745, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:03:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 323.53704833984375, 'train_avg_loss': 0.6740355173746745, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:03:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:03:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:03:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:04:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:04:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.808960, avg_loss=0.662102, seen=480, correct=284, accuracy=0.591667
2025-10-10 07:04:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:04:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:04:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:04:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2096MB allocated=1929MB
2025-10-10 07:04:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.71047461032867, 'train_avg_loss': 0.6559206217527389, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:04:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8089599609375, 'train_avg_loss': 0.6621019999186198, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 07:04:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 317.8089599609375, 'train_avg_loss': 0.6621019999186198, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 07:04:29 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #53) -------------
2025-10-10 07:04:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=53 aidx=1 | s=5 (candidates=16)
2025-10-10 07:04:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 48, 40, 45, 34] (from 16)
2025-10-10 07:04:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 07:04:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:04:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:05:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:05:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.506042, avg_loss=0.613554, seen=480, correct=313, accuracy=0.652083
2025-10-10 07:05:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:05:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:05:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2102MB allocated=1929MB
2025-10-10 07:05:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.15360641479492, 'train_avg_loss': 0.6346133867899577, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 07:05:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.50604248046875, 'train_avg_loss': 0.6135542551676433, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 07:05:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 294.50604248046875, 'train_avg_loss': 0.6135542551676433, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 07:05:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 07:05:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:05:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:05:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:05:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.441925, avg_loss=0.667587, seen=480, correct=279, accuracy=0.581250
2025-10-10 07:05:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:05:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:05:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2086MB allocated=1929MB
2025-10-10 07:05:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.57118827104568, 'train_avg_loss': 0.729759902258714, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 07:05:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.4419250488281, 'train_avg_loss': 0.6675873438517252, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 07:05:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 320.4419250488281, 'train_avg_loss': 0.6675873438517252, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 07:05:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:05:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:05:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 07:05:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 07:05:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:05:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:05:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:05:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:06:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:06:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.659393, avg_loss=0.682624, seen=480, correct=276, accuracy=0.575000
2025-10-10 07:06:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:06:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:06:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2064MB allocated=1929MB
2025-10-10 07:06:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.25936138629913, 'train_avg_loss': 0.7104946782191595, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 07:06:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6593933105469, 'train_avg_loss': 0.6826237360636394, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:06:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 327.6593933105469, 'train_avg_loss': 0.6826237360636394, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:06:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:06:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:06:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 07:06:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:06:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:06:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:06:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:06:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:07:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:07:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.129486, avg_loss=0.650270, seen=480, correct=292, accuracy=0.608333
2025-10-10 07:07:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:07:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:07:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:07:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2068MB allocated=1929MB
2025-10-10 07:07:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.36590707302094, 'train_avg_loss': 0.6447158922751745, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:07:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.1294860839844, 'train_avg_loss': 0.6502697626749675, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:07:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 312.1294860839844, 'train_avg_loss': 0.6502697626749675, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:07:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:07:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:07:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:08:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:08:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.729004, avg_loss=0.670269, seen=480, correct=292, accuracy=0.608333
2025-10-10 07:08:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:08:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:08:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2082MB allocated=1929MB
2025-10-10 07:08:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.31523156166077, 'train_avg_loss': 0.7026269296805064, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:08:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.72900390625, 'train_avg_loss': 0.6702687581380208, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:08:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 321.72900390625, 'train_avg_loss': 0.6702687581380208, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:08:03 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #54) -------------
2025-10-10 07:08:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=54 aidx=1 | s=5 (candidates=16)
2025-10-10 07:08:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 29, 45, 28, 43] (from 16)
2025-10-10 07:08:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 07:08:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:08:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:08:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:08:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.487518, avg_loss=0.655182, seen=480, correct=290, accuracy=0.604167
2025-10-10 07:08:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:08:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:08:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2070MB allocated=1929MB
2025-10-10 07:08:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.925756752491, 'train_avg_loss': 0.6243813062707583, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:08:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.4875183105469, 'train_avg_loss': 0.6551823298136393, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 07:08:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 314.4875183105469, 'train_avg_loss': 0.6551823298136393, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 07:08:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:08:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:08:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:09:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:09:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.659821, avg_loss=0.640958, seen=480, correct=293, accuracy=0.610417
2025-10-10 07:09:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:09:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:09:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2096MB allocated=1929MB
2025-10-10 07:09:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.51079893112183, 'train_avg_loss': 0.6459233244260152, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:09:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.6598205566406, 'train_avg_loss': 0.6409579594930013, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:09:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 307.6598205566406, 'train_avg_loss': 0.6409579594930013, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:09:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:09:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:09:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 07:09:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:09:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:09:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:09:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:09:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:10:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:10:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.466980, avg_loss=0.650973, seen=480, correct=299, accuracy=0.622917
2025-10-10 07:10:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:10:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:10:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2068MB allocated=1929MB
2025-10-10 07:10:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.83402752876282, 'train_avg_loss': 0.6402835627396901, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:10:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.46697998046875, 'train_avg_loss': 0.6509728749593099, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:10:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 312.46697998046875, 'train_avg_loss': 0.6509728749593099, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:10:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:10:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:10:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:10:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:10:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.120209, avg_loss=0.629417, seen=480, correct=318, accuracy=0.662500
2025-10-10 07:10:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:10:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:10:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2064MB allocated=1929MB
2025-10-10 07:10:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.2225347161293, 'train_avg_loss': 0.6268544559677441, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:10:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.1202087402344, 'train_avg_loss': 0.6294171015421549, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 07:10:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 302.1202087402344, 'train_avg_loss': 0.6294171015421549, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 07:10:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:10:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:10:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 07:10:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:10:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:10:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:10:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:10:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:11:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:11:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.527588, avg_loss=0.613599, seen=480, correct=313, accuracy=0.652083
2025-10-10 07:11:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:11:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:11:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:11:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2124MB allocated=1929MB
2025-10-10 07:11:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.99830034375191, 'train_avg_loss': 0.6333191695312659, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:11:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.527587890625, 'train_avg_loss': 0.6135991414388021, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 07:11:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 294.527587890625, 'train_avg_loss': 0.6135991414388021, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 07:11:40 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #55) -------------
2025-10-10 07:11:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=55 aidx=1 | s=5 (candidates=16)
2025-10-10 07:11:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 1, 43, 16, 26] (from 16)
2025-10-10 07:11:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:11:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:11:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:12:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:12:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.091553, avg_loss=0.648107, seen=480, correct=292, accuracy=0.608333
2025-10-10 07:12:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:12:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:12:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2096MB allocated=1929MB
2025-10-10 07:12:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.24581786990166, 'train_avg_loss': 0.6437151489158471, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:12:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.091552734375, 'train_avg_loss': 0.648107401529948, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:12:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 311.091552734375, 'train_avg_loss': 0.648107401529948, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:12:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 07:12:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:12:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:12:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:12:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.699921, avg_loss=0.684792, seen=480, correct=274, accuracy=0.570833
2025-10-10 07:12:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:12:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:13:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2064MB allocated=1929MB
2025-10-10 07:13:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.69680440425873, 'train_avg_loss': 0.6891400367021561, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:13:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6999206542969, 'train_avg_loss': 0.6847915013631185, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:13:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 328.6999206542969, 'train_avg_loss': 0.6847915013631185, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:13:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:13:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:13:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 07:13:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:13:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:13:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:13:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:13:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:13:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:13:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.744751, avg_loss=0.593218, seen=480, correct=328, accuracy=0.683333
2025-10-10 07:13:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:13:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:13:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2124MB allocated=1929MB
2025-10-10 07:13:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.83513313531876, 'train_avg_loss': 0.6152927761276563, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 07:13:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.7447509765625, 'train_avg_loss': 0.5932182312011719, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 07:13:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 284.7447509765625, 'train_avg_loss': 0.5932182312011719, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 07:13:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 07:13:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:13:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:14:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:14:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.908722, avg_loss=0.651893, seen=480, correct=302, accuracy=0.629167
2025-10-10 07:14:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:14:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:14:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:14:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2104MB allocated=1929MB
2025-10-10 07:14:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.03796625137329, 'train_avg_loss': 0.5919830520947774, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 07:14:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.9087219238281, 'train_avg_loss': 0.6518931706746419, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 07:14:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 312.9087219238281, 'train_avg_loss': 0.6518931706746419, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 07:14:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:14:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:14:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:15:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:15:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.863708, avg_loss=0.678883, seen=480, correct=280, accuracy=0.583333
2025-10-10 07:15:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:15:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:15:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2064MB allocated=1929MB
2025-10-10 07:15:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.30678117275238, 'train_avg_loss': 0.6608898431062699, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:15:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.86370849609375, 'train_avg_loss': 0.6788827260335286, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 07:15:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 325.86370849609375, 'train_avg_loss': 0.6788827260335286, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 07:15:12 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #56) -------------
2025-10-10 07:15:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=56 aidx=1 | s=5 (candidates=16)
2025-10-10 07:15:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 51, 43, 34, 20] (from 16)
2025-10-10 07:15:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 07:15:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:15:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:15:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:15:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.262115, avg_loss=0.652629, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:15:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:15:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:15:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2074MB allocated=1929MB
2025-10-10 07:15:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.54508459568024, 'train_avg_loss': 0.6378757049640019, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:15:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.2621154785156, 'train_avg_loss': 0.6526294072469075, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:15:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 313.2621154785156, 'train_avg_loss': 0.6526294072469075, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:15:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:15:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:15:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:16:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:16:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.899231, avg_loss=0.645623, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:16:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:16:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:16:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:16:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2110MB allocated=1929MB
2025-10-10 07:16:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5658129453659, 'train_avg_loss': 0.6880484412113825, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:16:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.89923095703125, 'train_avg_loss': 0.6456233978271484, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:16:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 309.89923095703125, 'train_avg_loss': 0.6456233978271484, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:16:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:16:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:16:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:17:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.049683, avg_loss=0.595937, seen=480, correct=333, accuracy=0.693750
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:17:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:17:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:17:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2124MB allocated=1929MB
2025-10-10 07:17:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.31519803404808, 'train_avg_loss': 0.6109599836170674, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 07:17:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.0496826171875, 'train_avg_loss': 0.5959368387858073, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 07:17:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 286.0496826171875, 'train_avg_loss': 0.5959368387858073, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 07:17:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:17:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:17:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 07:17:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:17:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:17:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:17:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:17:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:17:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:18:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:18:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.717590, avg_loss=0.657745, seen=480, correct=299, accuracy=0.622917
2025-10-10 07:18:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:18:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:18:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2084MB allocated=1929MB
2025-10-10 07:18:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.45724493265152, 'train_avg_loss': 0.687143707772096, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:18:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.71759033203125, 'train_avg_loss': 0.6577449798583984, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:18:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 315.71759033203125, 'train_avg_loss': 0.6577449798583984, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:18:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 07:18:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:18:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:18:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:18:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.367432, avg_loss=0.607015, seen=480, correct=315, accuracy=0.656250
2025-10-10 07:18:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:18:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:18:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2102MB allocated=1929MB
2025-10-10 07:18:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.88234949111938, 'train_avg_loss': 0.6406862457593282, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:18:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.367431640625, 'train_avg_loss': 0.6070154825846354, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:18:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 291.367431640625, 'train_avg_loss': 0.6070154825846354, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:18:48 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #57) -------------
2025-10-10 07:18:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=57 aidx=1 | s=5 (candidates=16)
2025-10-10 07:18:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 51, 29, 6, 20] (from 16)
2025-10-10 07:18:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:18:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:18:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:19:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:19:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.147644, avg_loss=0.650308, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:19:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:19:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:19:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:19:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2068MB allocated=1929MB
2025-10-10 07:19:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.8214420080185, 'train_avg_loss': 0.6318453500668207, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:19:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.14764404296875, 'train_avg_loss': 0.6503075917561849, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:19:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 312.14764404296875, 'train_avg_loss': 0.6503075917561849, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:19:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:19:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:19:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:20:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:20:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.775879, avg_loss=0.647450, seen=480, correct=301, accuracy=0.627083
2025-10-10 07:20:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:20:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:20:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2110MB allocated=1929MB
2025-10-10 07:20:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.1198422908783, 'train_avg_loss': 0.7009986857573192, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:20:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.77587890625, 'train_avg_loss': 0.6474497477213542, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:20:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 310.77587890625, 'train_avg_loss': 0.6474497477213542, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:20:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:20:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:20:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:20:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.696594, avg_loss=0.645201, seen=480, correct=292, accuracy=0.608333
2025-10-10 07:20:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:20:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:20:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2096MB allocated=1929MB
2025-10-10 07:20:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.25746348500252, 'train_avg_loss': 0.6354788623750209, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:20:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.69659423828125, 'train_avg_loss': 0.6452012379964193, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:20:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 309.69659423828125, 'train_avg_loss': 0.6452012379964193, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:20:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 07:20:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:20:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:21:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:21:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.595215, avg_loss=0.657490, seen=480, correct=302, accuracy=0.629167
2025-10-10 07:21:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:21:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:21:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:21:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2074MB allocated=1929MB
2025-10-10 07:21:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.14811772108078, 'train_avg_loss': 0.6429009810090065, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:21:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.59521484375, 'train_avg_loss': 0.6574900309244792, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 07:21:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 315.59521484375, 'train_avg_loss': 0.6574900309244792, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 07:21:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 07:21:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:22:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:22:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.568634, avg_loss=0.588685, seen=480, correct=332, accuracy=0.691667
2025-10-10 07:22:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:22:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:22:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:22:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2102MB allocated=1929MB
2025-10-10 07:22:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.37059932947159, 'train_avg_loss': 0.6197549944122632, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 07:22:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.5686340332031, 'train_avg_loss': 0.5886846542358398, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-10 07:22:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 282.5686340332031, 'train_avg_loss': 0.5886846542358398, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-10 07:22:25 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #58) -------------
2025-10-10 07:22:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=58 aidx=1 | s=5 (candidates=16)
2025-10-10 07:22:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 29, 47, 28] (from 16)
2025-10-10 07:22:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 07:22:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:23:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:23:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.471161, avg_loss=0.678065, seen=480, correct=281, accuracy=0.585417
2025-10-10 07:23:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:23:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:23:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2086MB allocated=1929MB
2025-10-10 07:23:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.75151774287224, 'train_avg_loss': 0.7562626478572686, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 07:23:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4711608886719, 'train_avg_loss': 0.6780649185180664, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:23:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 325.4711608886719, 'train_avg_loss': 0.6780649185180664, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:23:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:23:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:23:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 07:23:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 07:23:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:23:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:23:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:23:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:23:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:23:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.627441, avg_loss=0.653391, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:23:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:23:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:23:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2104MB allocated=1929MB
2025-10-10 07:23:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.03576090931892, 'train_avg_loss': 0.583631340910991, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-10 07:23:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.62744140625, 'train_avg_loss': 0.6533905029296875, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:23:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 313.62744140625, 'train_avg_loss': 0.6533905029296875, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:23:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:23:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:23:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 07:23:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:23:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:23:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:23:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:23:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:24:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:24:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.045868, avg_loss=0.648012, seen=480, correct=295, accuracy=0.614583
2025-10-10 07:24:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:24:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:24:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:24:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2096MB allocated=1929MB
2025-10-10 07:24:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.53533953428268, 'train_avg_loss': 0.6294611627856891, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:24:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.0458679199219, 'train_avg_loss': 0.6480122248331706, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:24:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 311.0458679199219, 'train_avg_loss': 0.6480122248331706, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:24:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:24:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:24:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 07:24:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 07:24:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:24:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:24:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:24:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:24:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:25:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:25:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.716736, avg_loss=0.661910, seen=480, correct=296, accuracy=0.616667
2025-10-10 07:25:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:25:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:25:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2070MB allocated=1929MB
2025-10-10 07:25:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.45447504520416, 'train_avg_loss': 0.6204539587100347, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:25:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.71673583984375, 'train_avg_loss': 0.6619098663330079, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:25:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 317.71673583984375, 'train_avg_loss': 0.6619098663330079, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:25:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:25:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:25:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:25:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:25:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.438660, avg_loss=0.625914, seen=480, correct=310, accuracy=0.645833
2025-10-10 07:25:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:25:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:25:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2064MB allocated=1929MB
2025-10-10 07:25:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.68406772613525, 'train_avg_loss': 0.6223672310511271, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:25:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.43865966796875, 'train_avg_loss': 0.6259138743082683, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 07:25:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 300.43865966796875, 'train_avg_loss': 0.6259138743082683, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 07:25:55 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #59) -------------
2025-10-10 07:25:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=59 aidx=1 | s=5 (candidates=16)
2025-10-10 07:25:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 20, 26, 51, 15] (from 16)
2025-10-10 07:25:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:25:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:25:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:26:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:26:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.318512, avg_loss=0.661080, seen=480, correct=299, accuracy=0.622917
2025-10-10 07:26:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:26:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:26:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:26:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2084MB allocated=1929MB
2025-10-10 07:26:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.52935761213303, 'train_avg_loss': 0.6960779801011086, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:26:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.3185119628906, 'train_avg_loss': 0.6610802332560222, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:26:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 317.3185119628906, 'train_avg_loss': 0.6610802332560222, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:26:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 07:26:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:26:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:27:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:27:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=275.425842, avg_loss=0.573804, seen=480, correct=345, accuracy=0.718750
2025-10-10 07:27:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:27:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:27:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:27:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2102MB allocated=1929MB
2025-10-10 07:27:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.10340493917465, 'train_avg_loss': 0.6091950411597887, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 07:27:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 275.42584228515625, 'train_avg_loss': 0.5738038380940755, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 07:27:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 275.42584228515625, 'train_avg_loss': 0.5738038380940755, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 07:27:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:27:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:27:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:28:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:28:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.781128, avg_loss=0.668294, seen=480, correct=293, accuracy=0.610417
2025-10-10 07:28:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:28:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:28:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2064MB allocated=1929MB
2025-10-10 07:28:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.0533740222454, 'train_avg_loss': 0.6421114501853784, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:28:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.7811279296875, 'train_avg_loss': 0.6682940165201823, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:28:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 320.7811279296875, 'train_avg_loss': 0.6682940165201823, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:28:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:28:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:28:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:28:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:28:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.891632, avg_loss=0.651858, seen=480, correct=304, accuracy=0.633333
2025-10-10 07:28:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:28:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:28:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2110MB allocated=1929MB
2025-10-10 07:28:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.99082010984421, 'train_avg_loss': 0.6999235009153684, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:28:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.8916320800781, 'train_avg_loss': 0.651857566833496, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:28:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 312.8916320800781, 'train_avg_loss': 0.651857566833496, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:28:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 07:28:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:28:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:29:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:29:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.773834, avg_loss=0.639112, seen=480, correct=301, accuracy=0.627083
2025-10-10 07:29:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:29:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:29:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2064MB allocated=1929MB
2025-10-10 07:29:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61593025922775, 'train_avg_loss': 0.6884660854935646, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:29:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.7738342285156, 'train_avg_loss': 0.6391121546427408, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:29:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 306.7738342285156, 'train_avg_loss': 0.6391121546427408, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:29:33 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #60) -------------
2025-10-10 07:29:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=60 aidx=1 | s=5 (candidates=16)
2025-10-10 07:29:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 45, 6, 28, 51] (from 16)
2025-10-10 07:29:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 07:29:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:29:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:30:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:30:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.465515, avg_loss=0.675970, seen=480, correct=285, accuracy=0.593750
2025-10-10 07:30:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:30:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:30:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:30:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2064MB allocated=1929MB
2025-10-10 07:30:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.04475969076157, 'train_avg_loss': 0.675372997423013, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:30:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.46551513671875, 'train_avg_loss': 0.6759698232014973, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 07:30:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 324.46551513671875, 'train_avg_loss': 0.6759698232014973, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 07:30:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:30:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:30:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 07:30:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:30:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:30:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:30:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:30:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:30:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:30:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:30:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.748047, avg_loss=0.645308, seen=480, correct=303, accuracy=0.631250
2025-10-10 07:30:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:30:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:30:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:30:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2068MB allocated=1929MB
2025-10-10 07:30:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.9320478439331, 'train_avg_loss': 0.6327670653661092, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:30:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.748046875, 'train_avg_loss': 0.6453084309895833, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:30:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 309.748046875, 'train_avg_loss': 0.6453084309895833, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:30:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 07:31:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:31:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:31:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:31:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.911407, avg_loss=0.656065, seen=480, correct=295, accuracy=0.614583
2025-10-10 07:31:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:31:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:31:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:31:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2074MB allocated=1929MB
2025-10-10 07:31:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.44473522901535, 'train_avg_loss': 0.6453727935751279, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:31:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9114074707031, 'train_avg_loss': 0.6560654322306315, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:31:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 314.9114074707031, 'train_avg_loss': 0.6560654322306315, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:31:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:31:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:31:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:32:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:32:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.140564, avg_loss=0.612793, seen=480, correct=319, accuracy=0.664583
2025-10-10 07:32:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:32:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:32:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:32:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2064MB allocated=1929MB
2025-10-10 07:32:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.24231669306755, 'train_avg_loss': 0.602019305775563, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:32:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.14056396484375, 'train_avg_loss': 0.6127928415934245, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 07:32:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 294.14056396484375, 'train_avg_loss': 0.6127928415934245, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 07:32:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:32:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:32:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:33:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.679321, avg_loss=0.645165, seen=480, correct=305, accuracy=0.635417
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:33:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:33:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2110MB allocated=1929MB
2025-10-10 07:33:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.76000642776489, 'train_avg_loss': 0.6896667202313741, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:33:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.6793212890625, 'train_avg_loss': 0.6451652526855469, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:33:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 309.6793212890625, 'train_avg_loss': 0.6451652526855469, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:33:05 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #61) -------------
2025-10-10 07:33:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=61 aidx=1 | s=5 (candidates=16)
2025-10-10 07:33:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 43, 48, 28, 1] (from 16)
2025-10-10 07:33:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:33:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:33:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:33:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:33:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.970703, avg_loss=0.643689, seen=480, correct=305, accuracy=0.635417
2025-10-10 07:33:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:33:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:33:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2068MB allocated=1929MB
2025-10-10 07:33:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.8239935040474, 'train_avg_loss': 0.6318666125337283, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:33:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.970703125, 'train_avg_loss': 0.64368896484375, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:33:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 308.970703125, 'train_avg_loss': 0.64368896484375, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:33:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:33:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:33:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:34:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:34:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.986786, avg_loss=0.591639, seen=480, correct=329, accuracy=0.685417
2025-10-10 07:34:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:34:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:34:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:34:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2124MB allocated=1929MB
2025-10-10 07:34:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.94136732816696, 'train_avg_loss': 0.6078447277347246, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:34:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.9867858886719, 'train_avg_loss': 0.5916391372680664, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 07:34:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 283.9867858886719, 'train_avg_loss': 0.5916391372680664, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 07:34:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 07:34:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:34:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:35:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:35:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.256348, avg_loss=0.658867, seen=480, correct=293, accuracy=0.610417
2025-10-10 07:35:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:35:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2086MB allocated=1929MB
2025-10-10 07:35:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.19566833972931, 'train_avg_loss': 0.7182972361644109, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 07:35:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.25634765625, 'train_avg_loss': 0.6588673909505208, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:35:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 316.25634765625, 'train_avg_loss': 0.6588673909505208, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:35:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:35:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:35:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:35:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.313141, avg_loss=0.613152, seen=480, correct=321, accuracy=0.668750
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:35:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:36:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2064MB allocated=1929MB
2025-10-10 07:36:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.13561061024666, 'train_avg_loss': 0.6094634217520555, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:36:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.3131408691406, 'train_avg_loss': 0.6131523768107097, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 07:36:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 294.3131408691406, 'train_avg_loss': 0.6131523768107097, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 07:36:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 07:36:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:36:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:36:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:36:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.576843, avg_loss=0.672035, seen=480, correct=286, accuracy=0.595833
2025-10-10 07:36:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:36:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2064MB allocated=1929MB
2025-10-10 07:36:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.56936287879944, 'train_avg_loss': 0.6714113573233287, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:36:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.57684326171875, 'train_avg_loss': 0.6720350901285808, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 07:36:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 322.57684326171875, 'train_avg_loss': 0.6720350901285808, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 07:36:43 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #62) -------------
2025-10-10 07:36:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=62 aidx=1 | s=5 (candidates=16)
2025-10-10 07:36:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 16, 40, 15] (from 16)
2025-10-10 07:36:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:36:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:36:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 07:36:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:36:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:36:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:36:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:36:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:37:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:37:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.951477, avg_loss=0.643649, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:37:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:37:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2096MB allocated=1929MB
2025-10-10 07:37:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.65800374746323, 'train_avg_loss': 0.6388166978955269, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:37:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.95147705078125, 'train_avg_loss': 0.643648910522461, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:37:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 308.95147705078125, 'train_avg_loss': 0.643648910522461, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:37:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:37:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:37:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:38:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:38:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.072479, avg_loss=0.643901, seen=480, correct=303, accuracy=0.631250
2025-10-10 07:38:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:38:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:38:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2068MB allocated=1929MB
2025-10-10 07:38:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.83366960287094, 'train_avg_loss': 0.6319472466905912, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 07:38:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.0724792480469, 'train_avg_loss': 0.643900998433431, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:38:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 309.0724792480469, 'train_avg_loss': 0.643900998433431, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:38:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 07:38:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:38:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:38:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:38:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.476379, avg_loss=0.644742, seen=480, correct=305, accuracy=0.635417
2025-10-10 07:38:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:38:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:38:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2104MB allocated=1929MB
2025-10-10 07:38:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.32975506782532, 'train_avg_loss': 0.594414625565211, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 07:38:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.47637939453125, 'train_avg_loss': 0.6447424570719401, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:38:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 309.47637939453125, 'train_avg_loss': 0.6447424570719401, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:38:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 07:38:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:39:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:39:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.751343, avg_loss=0.672399, seen=480, correct=278, accuracy=0.579167
2025-10-10 07:39:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:39:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:39:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:39:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2064MB allocated=1929MB
2025-10-10 07:39:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54561769962311, 'train_avg_loss': 0.6878801474968592, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:39:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.7513427734375, 'train_avg_loss': 0.6723986307779948, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 07:39:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 322.7513427734375, 'train_avg_loss': 0.6723986307779948, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 07:39:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 07:39:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:40:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:40:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.917450, avg_loss=0.626911, seen=480, correct=312, accuracy=0.650000
2025-10-10 07:40:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:40:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:40:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:40:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2064MB allocated=1929MB
2025-10-10 07:40:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.20754116773605, 'train_avg_loss': 0.6683961763978005, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:40:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.9174499511719, 'train_avg_loss': 0.6269113540649414, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:40:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 300.9174499511719, 'train_avg_loss': 0.6269113540649414, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:40:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #63) -------------
2025-10-10 07:40:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=63 aidx=1 | s=5 (candidates=16)
2025-10-10 07:40:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 1, 51, 45, 26] (from 16)
2025-10-10 07:40:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 07:40:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:40:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:40:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:40:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=277.863373, avg_loss=0.578882, seen=480, correct=341, accuracy=0.710417
2025-10-10 07:40:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:40:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:41:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2102MB allocated=1929MB
2025-10-10 07:41:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.23666495084763, 'train_avg_loss': 0.6103055412570636, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 07:41:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 277.8633728027344, 'train_avg_loss': 0.5788820266723633, 'train_seen': 480, 'train_correct': 341, 'train_acc': 0.7104166666666667}}
2025-10-10 07:41:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 277.8633728027344, 'train_avg_loss': 0.5788820266723633, 'train_seen': 480, 'train_correct': 341, 'train_acc': 0.7104166666666667}}
2025-10-10 07:41:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 07:41:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:41:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:41:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:41:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.964661, avg_loss=0.660343, seen=480, correct=291, accuracy=0.606250
2025-10-10 07:41:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:41:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:41:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2064MB allocated=1929MB
2025-10-10 07:41:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.78341126441956, 'train_avg_loss': 0.6565284272034962, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:41:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.96466064453125, 'train_avg_loss': 0.6603430430094401, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 07:41:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 316.96466064453125, 'train_avg_loss': 0.6603430430094401, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 07:41:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:41:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:41:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:42:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:42:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.082123, avg_loss=0.633504, seen=480, correct=305, accuracy=0.635417
2025-10-10 07:42:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:42:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:42:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:42:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2110MB allocated=1929MB
2025-10-10 07:42:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6196391582489, 'train_avg_loss': 0.6801636596520741, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:42:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.0821228027344, 'train_avg_loss': 0.6335044225056966, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:42:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 304.0821228027344, 'train_avg_loss': 0.6335044225056966, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 07:42:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:42:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:42:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:43:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:43:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.332520, avg_loss=0.642359, seen=480, correct=299, accuracy=0.622917
2025-10-10 07:43:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:43:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:43:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2068MB allocated=1929MB
2025-10-10 07:43:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.06395483016968, 'train_avg_loss': 0.6338662902514139, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 07:43:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.33251953125, 'train_avg_loss': 0.6423594156901041, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:43:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 308.33251953125, 'train_avg_loss': 0.6423594156901041, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:43:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:43:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:43:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:43:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:43:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.998901, avg_loss=0.660414, seen=480, correct=298, accuracy=0.620833
2025-10-10 07:43:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:43:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:43:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2064MB allocated=1929MB
2025-10-10 07:43:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.23693120479584, 'train_avg_loss': 0.6353077600399654, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:43:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.9989013671875, 'train_avg_loss': 0.6604143778483073, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 07:43:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 316.9989013671875, 'train_avg_loss': 0.6604143778483073, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 07:43:53 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #64) -------------
2025-10-10 07:43:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=64 aidx=1 | s=5 (candidates=16)
2025-10-10 07:43:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 26, 28, 34, 45] (from 16)
2025-10-10 07:43:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 07:43:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:43:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:44:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:44:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.304749, avg_loss=0.656885, seen=480, correct=288, accuracy=0.600000
2025-10-10 07:44:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:44:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:44:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2086MB allocated=1929MB
2025-10-10 07:44:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.43249422311783, 'train_avg_loss': 0.7119374518593152, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 07:44:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.30474853515625, 'train_avg_loss': 0.6568848927815755, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:44:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 315.30474853515625, 'train_avg_loss': 0.6568848927815755, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:44:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:44:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:44:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 07:44:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:44:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:44:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:44:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:44:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:45:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:45:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.273224, avg_loss=0.644319, seen=480, correct=296, accuracy=0.616667
2025-10-10 07:45:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:45:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:45:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:45:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2064MB allocated=1929MB
2025-10-10 07:45:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.80567359924316, 'train_avg_loss': 0.615047279993693, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 07:45:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.2732238769531, 'train_avg_loss': 0.644319216410319, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:45:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 309.2732238769531, 'train_avg_loss': 0.644319216410319, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:45:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:45:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:45:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:46:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:46:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.190033, avg_loss=0.617063, seen=480, correct=318, accuracy=0.662500
2025-10-10 07:46:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:46:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:46:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2064MB allocated=1929MB
2025-10-10 07:46:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.66861426830292, 'train_avg_loss': 0.6139051189025243, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 07:46:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.1900329589844, 'train_avg_loss': 0.6170625686645508, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 07:46:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 296.1900329589844, 'train_avg_loss': 0.6170625686645508, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 07:46:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:46:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:46:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:46:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:46:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.355347, avg_loss=0.659074, seen=480, correct=295, accuracy=0.614583
2025-10-10 07:46:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:46:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:46:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2082MB allocated=1929MB
2025-10-10 07:46:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.509202927351, 'train_avg_loss': 0.6875766910612583, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:46:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.3553466796875, 'train_avg_loss': 0.6590736389160157, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:46:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 316.3553466796875, 'train_avg_loss': 0.6590736389160157, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:46:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:46:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:46:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:47:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:47:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.841187, avg_loss=0.645502, seen=480, correct=299, accuracy=0.622917
2025-10-10 07:47:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:47:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:47:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2068MB allocated=1929MB
2025-10-10 07:47:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.63059103488922, 'train_avg_loss': 0.6385882586240769, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 07:47:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.8411865234375, 'train_avg_loss': 0.6455024719238281, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:47:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 309.8411865234375, 'train_avg_loss': 0.6455024719238281, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 07:47:31 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #65) -------------
2025-10-10 07:47:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=65 aidx=1 | s=5 (candidates=16)
2025-10-10 07:47:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 45, 26, 51, 40] (from 16)
2025-10-10 07:47:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:47:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:47:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 07:47:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 07:47:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:47:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:47:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:47:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:48:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:48:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.719971, avg_loss=0.643167, seen=480, correct=304, accuracy=0.633333
2025-10-10 07:48:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:48:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:48:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:48:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2104MB allocated=1929MB
2025-10-10 07:48:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.22557413578033, 'train_avg_loss': 0.5935464511315028, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 07:48:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.719970703125, 'train_avg_loss': 0.6431666056315104, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:48:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 308.719970703125, 'train_avg_loss': 0.6431666056315104, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:48:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 07:48:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:48:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:49:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:49:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.107178, avg_loss=0.629390, seen=480, correct=315, accuracy=0.656250
2025-10-10 07:49:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:49:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:49:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2068MB allocated=1929MB
2025-10-10 07:49:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.87551927566528, 'train_avg_loss': 0.6239626606305441, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:49:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.107177734375, 'train_avg_loss': 0.6293899536132812, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:49:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 302.107177734375, 'train_avg_loss': 0.6293899536132812, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:49:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:49:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:49:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:49:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:49:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.941620, avg_loss=0.645712, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:49:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:49:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:49:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2064MB allocated=1929MB
2025-10-10 07:49:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.34664642810822, 'train_avg_loss': 0.6112220535675684, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:49:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.9416198730469, 'train_avg_loss': 0.6457117080688477, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:49:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 309.9416198730469, 'train_avg_loss': 0.6457117080688477, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:49:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:49:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:49:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:50:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:50:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.014374, avg_loss=0.637530, seen=480, correct=301, accuracy=0.627083
2025-10-10 07:50:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:50:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:50:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2110MB allocated=1929MB
2025-10-10 07:50:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.4256597161293, 'train_avg_loss': 0.6868804976344108, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 07:50:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.0143737792969, 'train_avg_loss': 0.6375299453735351, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:50:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 306.0143737792969, 'train_avg_loss': 0.6375299453735351, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 07:50:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 07:50:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:50:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:51:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:51:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.346130, avg_loss=0.675721, seen=480, correct=277, accuracy=0.577083
2025-10-10 07:51:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:51:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:51:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2064MB allocated=1929MB
2025-10-10 07:51:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.38298118114471, 'train_avg_loss': 0.6948581765095393, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 07:51:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.34613037109375, 'train_avg_loss': 0.6757211049397787, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 07:51:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 324.34613037109375, 'train_avg_loss': 0.6757211049397787, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 07:51:13 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #66) -------------
2025-10-10 07:51:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=66 aidx=1 | s=5 (candidates=16)
2025-10-10 07:51:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 47, 22, 6, 28] (from 16)
2025-10-10 07:51:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:51:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:51:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 07:51:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:51:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:51:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:51:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:51:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:51:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:51:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.961243, avg_loss=0.641586, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:51:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:51:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:51:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2096MB allocated=1929MB
2025-10-10 07:51:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.82584583759308, 'train_avg_loss': 0.631882048646609, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:51:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.96124267578125, 'train_avg_loss': 0.6415859222412109, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:51:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 307.96124267578125, 'train_avg_loss': 0.6415859222412109, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:51:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:51:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:51:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 07:51:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 07:51:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:51:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:51:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:51:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:52:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:52:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.375977, avg_loss=0.642450, seen=480, correct=304, accuracy=0.633333
2025-10-10 07:52:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:52:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:52:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:52:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2070MB allocated=1929MB
2025-10-10 07:52:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.79367727041245, 'train_avg_loss': 0.6149473105867703, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:52:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.3759765625, 'train_avg_loss': 0.642449951171875, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:52:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 308.3759765625, 'train_avg_loss': 0.642449951171875, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 07:52:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 07:52:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:52:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:53:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:53:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.480652, avg_loss=0.621835, seen=480, correct=309, accuracy=0.643750
2025-10-10 07:53:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:53:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:53:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2104MB allocated=1929MB
2025-10-10 07:53:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.99164128303528, 'train_avg_loss': 0.624930344025294, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:53:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.48065185546875, 'train_avg_loss': 0.6218346913655599, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 07:53:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 298.48065185546875, 'train_avg_loss': 0.6218346913655599, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 07:53:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:53:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:53:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 07:53:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 07:53:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:53:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:53:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:53:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:54:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:54:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.652466, avg_loss=0.651359, seen=480, correct=294, accuracy=0.612500
2025-10-10 07:54:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:54:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:54:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2074MB allocated=1929MB
2025-10-10 07:54:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.6904339492321, 'train_avg_loss': 0.6390869495769341, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:54:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6524658203125, 'train_avg_loss': 0.6513593037923177, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 07:54:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 312.6524658203125, 'train_avg_loss': 0.6513593037923177, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 07:54:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 07:54:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:54:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:54:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:54:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.801117, avg_loss=0.614169, seen=480, correct=322, accuracy=0.670833
2025-10-10 07:54:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:54:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:54:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2064MB allocated=1929MB
2025-10-10 07:54:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.13588654994965, 'train_avg_loss': 0.6094657212495804, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 07:54:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.8011169433594, 'train_avg_loss': 0.6141689936319987, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 07:54:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 294.8011169433594, 'train_avg_loss': 0.6141689936319987, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 07:54:46 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #67) -------------
2025-10-10 07:54:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=67 aidx=1 | s=5 (candidates=16)
2025-10-10 07:54:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 22, 51, 29, 34] (from 16)
2025-10-10 07:54:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 07:54:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:54:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:55:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:55:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.739746, avg_loss=0.645291, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:55:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:55:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:55:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2064MB allocated=1929MB
2025-10-10 07:55:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.46760195493698, 'train_avg_loss': 0.6122300162911415, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:55:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.73974609375, 'train_avg_loss': 0.6452911376953125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:55:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 309.73974609375, 'train_avg_loss': 0.6452911376953125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:55:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 07:55:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:55:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:56:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:56:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.225861, avg_loss=0.619221, seen=480, correct=317, accuracy=0.660417
2025-10-10 07:56:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:56:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:56:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2104MB allocated=1929MB
2025-10-10 07:56:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.31176519393921, 'train_avg_loss': 0.6275980432828268, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 07:56:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.2258605957031, 'train_avg_loss': 0.6192205429077149, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 07:56:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 297.2258605957031, 'train_avg_loss': 0.6192205429077149, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 07:56:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 07:56:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:56:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:56:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:56:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.736938, avg_loss=0.639035, seen=480, correct=307, accuracy=0.639583
2025-10-10 07:56:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:56:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:56:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2110MB allocated=1929MB
2025-10-10 07:56:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.70500373840332, 'train_avg_loss': 0.680875031153361, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:56:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.7369384765625, 'train_avg_loss': 0.6390352884928385, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 07:56:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 306.7369384765625, 'train_avg_loss': 0.6390352884928385, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 07:56:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 07:56:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:56:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:57:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:57:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.362885, avg_loss=0.636173, seen=480, correct=306, accuracy=0.637500
2025-10-10 07:57:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:57:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:57:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:57:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2096MB allocated=1929MB
2025-10-10 07:57:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.63528800010681, 'train_avg_loss': 0.6219607333342234, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:57:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.3628845214844, 'train_avg_loss': 0.6361726760864258, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:57:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 305.3628845214844, 'train_avg_loss': 0.6361726760864258, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 07:57:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 07:57:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:57:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:58:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:58:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.614624, avg_loss=0.659614, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:58:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:58:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:58:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:58:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2082MB allocated=1929MB
2025-10-10 07:58:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.99767872691154, 'train_avg_loss': 0.6916473227242629, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:58:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6146240234375, 'train_avg_loss': 0.6596138000488281, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:58:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 316.6146240234375, 'train_avg_loss': 0.6596138000488281, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:58:21 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #68) -------------
2025-10-10 07:58:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=68 aidx=1 | s=5 (candidates=16)
2025-10-10 07:58:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 22, 43, 34, 47] (from 16)
2025-10-10 07:58:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 07:58:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:58:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:59:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:59:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.060364, avg_loss=0.645959, seen=480, correct=303, accuracy=0.631250
2025-10-10 07:59:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:59:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:59:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2104MB allocated=1929MB
2025-10-10 07:59:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.32272893190384, 'train_avg_loss': 0.5860227410991986, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 07:59:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.06036376953125, 'train_avg_loss': 0.6459590911865234, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:59:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 310.06036376953125, 'train_avg_loss': 0.6459590911865234, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 07:59:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 07:59:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:59:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:59:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:59:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.759064, avg_loss=0.622415, seen=480, correct=319, accuracy=0.664583
2025-10-10 07:59:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:59:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2104MB allocated=1929MB
2025-10-10 07:59:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.79178458452225, 'train_avg_loss': 0.6315982048710187, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:59:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.7590637207031, 'train_avg_loss': 0.6224147160847981, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 07:59:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 298.7590637207031, 'train_avg_loss': 0.6224147160847981, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 07:59:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 07:59:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:59:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:00:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:00:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.582855, avg_loss=0.592881, seen=480, correct=337, accuracy=0.702083
2025-10-10 08:00:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:00:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:00:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:00:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2124MB allocated=1929MB
2025-10-10 08:00:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.07348355650902, 'train_avg_loss': 0.6006123629709085, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 08:00:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.5828552246094, 'train_avg_loss': 0.5928809483846028, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 08:00:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 284.5828552246094, 'train_avg_loss': 0.5928809483846028, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 08:00:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:00:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:00:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 08:00:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:01:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:01:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.551178, avg_loss=0.644898, seen=480, correct=304, accuracy=0.633333
2025-10-10 08:01:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:01:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:01:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2082MB allocated=1929MB
2025-10-10 08:01:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.76613509654999, 'train_avg_loss': 0.6730511258045833, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:01:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.5511779785156, 'train_avg_loss': 0.6448982874552409, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:01:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 309.5511779785156, 'train_avg_loss': 0.6448982874552409, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:01:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:01:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:01:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:01:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.419983, avg_loss=0.644625, seen=480, correct=297, accuracy=0.618750
2025-10-10 08:01:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:01:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:01:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2070MB allocated=1929MB
2025-10-10 08:01:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.2605208158493, 'train_avg_loss': 0.6021710067987442, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 08:01:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.41998291015625, 'train_avg_loss': 0.6446249643961589, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:01:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 309.41998291015625, 'train_avg_loss': 0.6446249643961589, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:01:59 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #69) -------------
2025-10-10 08:02:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=69 aidx=1 | s=5 (candidates=16)
2025-10-10 08:02:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 26, 43, 28, 51] (from 16)
2025-10-10 08:02:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 08:02:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:02:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:02:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.307556, avg_loss=0.640224, seen=480, correct=311, accuracy=0.647917
2025-10-10 08:02:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:02:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:02:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2104MB allocated=1929MB
2025-10-10 08:02:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.34520277380943, 'train_avg_loss': 0.5862100231150786, 'train_seen': 120, 'train_correct': 89, 'train_acc': 0.7416666666666667}}
2025-10-10 08:02:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.30755615234375, 'train_avg_loss': 0.6402240753173828, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 08:02:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 307.30755615234375, 'train_avg_loss': 0.6402240753173828, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 08:02:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 08:02:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:03:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:03:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.361755, avg_loss=0.646587, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:03:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:03:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:03:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:03:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2064MB allocated=1929MB
2025-10-10 08:03:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.35694706439972, 'train_avg_loss': 0.611307892203331, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:03:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.36175537109375, 'train_avg_loss': 0.6465869903564453, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:03:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 310.36175537109375, 'train_avg_loss': 0.6465869903564453, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:03:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:03:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:03:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 08:03:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:03:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:04:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:04:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.436310, avg_loss=0.590492, seen=480, correct=339, accuracy=0.706250
2025-10-10 08:04:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:04:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:04:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2124MB allocated=1929MB
2025-10-10 08:04:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.71996337175369, 'train_avg_loss': 0.6059996947646141, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:04:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.4363098144531, 'train_avg_loss': 0.590492312113444, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:04:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 283.4363098144531, 'train_avg_loss': 0.590492312113444, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:04:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 08:04:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:04:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:04:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:04:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=285.031738, avg_loss=0.593816, seen=480, correct=330, accuracy=0.687500
2025-10-10 08:04:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:04:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:04:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2064MB allocated=1929MB
2025-10-10 08:04:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.38163805007935, 'train_avg_loss': 0.5865136504173278, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 08:04:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 285.03173828125, 'train_avg_loss': 0.5938161214192709, 'train_seen': 480, 'train_correct': 330, 'train_acc': 0.6875}}
2025-10-10 08:04:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 285.03173828125, 'train_avg_loss': 0.5938161214192709, 'train_seen': 480, 'train_correct': 330, 'train_acc': 0.6875}}
2025-10-10 08:04:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 08:04:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:04:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:05:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:05:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.838348, avg_loss=0.635080, seen=480, correct=299, accuracy=0.622917
2025-10-10 08:05:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:05:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:05:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:05:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2110MB allocated=1929MB
2025-10-10 08:05:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.1598904132843, 'train_avg_loss': 0.6846657534440358, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:05:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.8383483886719, 'train_avg_loss': 0.6350798924763997, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:05:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 304.8383483886719, 'train_avg_loss': 0.6350798924763997, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:05:32 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #70) -------------
2025-10-10 08:05:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=70 aidx=1 | s=5 (candidates=16)
2025-10-10 08:05:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 6, 26, 1, 47] (from 16)
2025-10-10 08:05:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 08:05:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:05:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:06:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:06:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.381653, avg_loss=0.613295, seen=480, correct=320, accuracy=0.666667
2025-10-10 08:06:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:06:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:06:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2104MB allocated=1929MB
2025-10-10 08:06:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.56238943338394, 'train_avg_loss': 0.6130199119448662, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:06:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.38165283203125, 'train_avg_loss': 0.6132951100667318, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:06:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 294.38165283203125, 'train_avg_loss': 0.6132951100667318, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:06:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:06:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:06:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 08:06:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 08:06:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:06:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:06:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:06:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:06:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:06:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.197449, avg_loss=0.654578, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:06:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:06:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:06:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2074MB allocated=1929MB
2025-10-10 08:06:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.16875353455544, 'train_avg_loss': 0.6514062794546286, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:06:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.19744873046875, 'train_avg_loss': 0.6545780181884766, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:06:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 314.19744873046875, 'train_avg_loss': 0.6545780181884766, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:06:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 08:06:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:06:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:07:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:07:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.238708, avg_loss=0.650497, seen=480, correct=297, accuracy=0.618750
2025-10-10 08:07:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:07:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:07:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:07:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2064MB allocated=1929MB
2025-10-10 08:07:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.30217334628105, 'train_avg_loss': 0.6191847778856754, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:07:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.23870849609375, 'train_avg_loss': 0.650497309366862, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:07:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 312.23870849609375, 'train_avg_loss': 0.650497309366862, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:07:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 08:07:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:07:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:08:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:08:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.792023, avg_loss=0.657900, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:08:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:08:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:08:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2064MB allocated=1929MB
2025-10-10 08:08:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.33941739797592, 'train_avg_loss': 0.6528284783164661, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:08:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.7920227050781, 'train_avg_loss': 0.657900047302246, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:08:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 315.7920227050781, 'train_avg_loss': 0.657900047302246, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:08:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:08:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:08:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:09:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:09:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.215546, avg_loss=0.631699, seen=480, correct=307, accuracy=0.639583
2025-10-10 08:09:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:09:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:09:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2070MB allocated=1929MB
2025-10-10 08:09:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.66662967205048, 'train_avg_loss': 0.5888885806004206, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:09:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.2155456542969, 'train_avg_loss': 0.6316990534464518, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:09:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 303.2155456542969, 'train_avg_loss': 0.6316990534464518, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:09:09 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #71) -------------
2025-10-10 08:09:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=71 aidx=1 | s=5 (candidates=16)
2025-10-10 08:09:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 43, 20, 15, 29] (from 16)
2025-10-10 08:09:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:09:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:09:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 08:09:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 08:09:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:09:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:09:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:09:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:09:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:09:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.840942, avg_loss=0.618419, seen=480, correct=314, accuracy=0.654167
2025-10-10 08:09:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:09:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:09:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2104MB allocated=1929MB
2025-10-10 08:09:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.81860160827637, 'train_avg_loss': 0.615155013402303, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:09:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.8409423828125, 'train_avg_loss': 0.6184186299641927, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:09:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 296.8409423828125, 'train_avg_loss': 0.6184186299641927, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:09:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:09:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:09:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:10:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:10:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.576477, avg_loss=0.590784, seen=480, correct=328, accuracy=0.683333
2025-10-10 08:10:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:10:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:10:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:10:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2124MB allocated=1929MB
2025-10-10 08:10:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.96661323308945, 'train_avg_loss': 0.6080551102757454, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:10:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.57647705078125, 'train_avg_loss': 0.5907843271891277, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 08:10:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 283.57647705078125, 'train_avg_loss': 0.5907843271891277, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 08:10:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 08:10:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:10:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:11:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:11:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=273.227142, avg_loss=0.569223, seen=480, correct=337, accuracy=0.702083
2025-10-10 08:11:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:11:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:11:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2102MB allocated=1929MB
2025-10-10 08:11:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.94115763902664, 'train_avg_loss': 0.6245096469918887, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:11:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 273.2271423339844, 'train_avg_loss': 0.5692232131958008, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 08:11:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 273.2271423339844, 'train_avg_loss': 0.5692232131958008, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 08:11:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 08:11:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:11:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:11:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:11:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.817810, avg_loss=0.610037, seen=480, correct=320, accuracy=0.666667
2025-10-10 08:11:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:11:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:11:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2064MB allocated=1929MB
2025-10-10 08:11:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.5024881362915, 'train_avg_loss': 0.6625207344690959, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:11:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.81781005859375, 'train_avg_loss': 0.610037104288737, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:11:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 292.81781005859375, 'train_avg_loss': 0.610037104288737, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:11:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 08:12:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:12:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:12:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:12:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.538513, avg_loss=0.646955, seen=480, correct=304, accuracy=0.633333
2025-10-10 08:12:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:12:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:12:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:12:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2096MB allocated=1929MB
2025-10-10 08:12:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.73223724961281, 'train_avg_loss': 0.6311019770801067, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:12:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.53851318359375, 'train_avg_loss': 0.6469552357991536, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:12:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 310.53851318359375, 'train_avg_loss': 0.6469552357991536, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:12:44 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #72) -------------
2025-10-10 08:12:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=72 aidx=1 | s=5 (candidates=16)
2025-10-10 08:12:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 16, 29, 22, 45] (from 16)
2025-10-10 08:12:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:12:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:12:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 08:12:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:12:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:12:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:12:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:12:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:12:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:13:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:13:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.730042, avg_loss=0.618188, seen=480, correct=315, accuracy=0.656250
2025-10-10 08:13:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:13:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:13:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:13:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2070MB allocated=1929MB
2025-10-10 08:13:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.80176049470901, 'train_avg_loss': 0.5733480041225751, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 08:13:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.73004150390625, 'train_avg_loss': 0.6181875864664713, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 08:13:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 296.73004150390625, 'train_avg_loss': 0.6181875864664713, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 08:13:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:13:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:13:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 08:13:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 08:13:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:13:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:13:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:13:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:13:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:14:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:14:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.062866, avg_loss=0.635548, seen=480, correct=306, accuracy=0.637500
2025-10-10 08:14:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:14:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:14:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2104MB allocated=1929MB
2025-10-10 08:14:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.30708456039429, 'train_avg_loss': 0.5775590380032857, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 08:14:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.0628662109375, 'train_avg_loss': 0.6355476379394531, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:14:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 305.0628662109375, 'train_avg_loss': 0.6355476379394531, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:14:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 08:14:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:14:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:14:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:14:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.941711, avg_loss=0.633212, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:14:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:14:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:14:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2096MB allocated=1929MB
2025-10-10 08:14:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.10579669475555, 'train_avg_loss': 0.6175483057896296, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:14:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.94171142578125, 'train_avg_loss': 0.633211898803711, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:14:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 303.94171142578125, 'train_avg_loss': 0.633211898803711, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:14:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:14:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:14:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 08:14:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 08:14:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:14:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:14:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:14:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:15:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:15:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.264343, avg_loss=0.621384, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:15:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:15:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:15:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:15:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2104MB allocated=1929MB
2025-10-10 08:15:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.827596783638, 'train_avg_loss': 0.6235633065303167, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:15:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.26434326171875, 'train_avg_loss': 0.6213840484619141, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:15:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 298.26434326171875, 'train_avg_loss': 0.6213840484619141, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:15:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:15:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:15:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 08:15:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 08:15:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:15:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:15:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:15:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:15:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:16:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:16:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.125732, avg_loss=0.627345, seen=480, correct=319, accuracy=0.664583
2025-10-10 08:16:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:16:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:16:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:16:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2068MB allocated=1929MB
2025-10-10 08:16:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.02678668498993, 'train_avg_loss': 0.6168898890415827, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 08:16:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.125732421875, 'train_avg_loss': 0.6273452758789062, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 08:16:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 301.125732421875, 'train_avg_loss': 0.6273452758789062, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 08:16:21 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #73) -------------
2025-10-10 08:16:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=73 aidx=1 | s=5 (candidates=16)
2025-10-10 08:16:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 6, 1, 29, 16] (from 16)
2025-10-10 08:16:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 08:16:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:16:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:17:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=274.885376, avg_loss=0.572678, seen=480, correct=344, accuracy=0.716667
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:17:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:17:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2102MB allocated=1929MB
2025-10-10 08:17:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.2516756951809, 'train_avg_loss': 0.6187639641265075, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:17:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 274.8853759765625, 'train_avg_loss': 0.5726778666178386, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-10 08:17:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 274.8853759765625, 'train_avg_loss': 0.5726778666178386, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-10 08:17:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 08:17:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:17:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:17:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:17:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.825378, avg_loss=0.649636, seen=480, correct=300, accuracy=0.625000
2025-10-10 08:17:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:17:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:17:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2074MB allocated=1929MB
2025-10-10 08:17:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.09928005933762, 'train_avg_loss': 0.6424940004944801, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 08:17:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.82537841796875, 'train_avg_loss': 0.6496362050374349, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 08:17:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 311.82537841796875, 'train_avg_loss': 0.6496362050374349, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 08:17:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 08:17:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:17:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:18:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.955750, avg_loss=0.658241, seen=480, correct=296, accuracy=0.616667
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:18:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:18:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:18:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2064MB allocated=1929MB
2025-10-10 08:18:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.43575251102448, 'train_avg_loss': 0.653631270925204, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:18:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.95574951171875, 'train_avg_loss': 0.6582411448160808, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:18:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 315.95574951171875, 'train_avg_loss': 0.6582411448160808, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:18:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:18:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:18:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 08:18:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 08:18:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:18:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:18:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:18:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:18:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:19:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:19:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.039795, avg_loss=0.633416, seen=480, correct=307, accuracy=0.639583
2025-10-10 08:19:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:19:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:19:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2096MB allocated=1929MB
2025-10-10 08:19:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.2626322209835, 'train_avg_loss': 0.6188552685081958, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:19:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.039794921875, 'train_avg_loss': 0.6334162394205729, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:19:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 304.039794921875, 'train_avg_loss': 0.6334162394205729, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:19:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 08:19:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:19:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:19:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:19:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:19:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:19:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.005493, avg_loss=0.639595, seen=480, correct=306, accuracy=0.637500
2025-10-10 08:19:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:19:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2104MB allocated=1929MB
2025-10-10 08:19:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.21652328968048, 'train_avg_loss': 0.5851376940806706, 'train_seen': 120, 'train_correct': 89, 'train_acc': 0.7416666666666667}}
2025-10-10 08:19:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.0054931640625, 'train_avg_loss': 0.6395947774251302, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:19:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 307.0054931640625, 'train_avg_loss': 0.6395947774251302, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:19:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #74) -------------
2025-10-10 08:19:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=74 aidx=1 | s=5 (candidates=16)
2025-10-10 08:19:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 26, 47, 28, 43] (from 16)
2025-10-10 08:19:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 08:19:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:19:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:20:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:20:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.580414, avg_loss=0.649126, seen=480, correct=289, accuracy=0.602083
2025-10-10 08:20:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:20:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:20:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:20:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2086MB allocated=1929MB
2025-10-10 08:20:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.19936442375183, 'train_avg_loss': 0.7099947035312653, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:20:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.5804138183594, 'train_avg_loss': 0.6491258621215821, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:20:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 311.5804138183594, 'train_avg_loss': 0.6491258621215821, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:20:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:20:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:20:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 08:20:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 08:20:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:21:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:21:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.232239, avg_loss=0.648400, seen=480, correct=292, accuracy=0.608333
2025-10-10 08:21:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:21:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:21:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:21:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2064MB allocated=1929MB
2025-10-10 08:21:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.17629438638687, 'train_avg_loss': 0.6098024532198906, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:21:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.23223876953125, 'train_avg_loss': 0.6484004974365234, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 08:21:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 311.23223876953125, 'train_avg_loss': 0.6484004974365234, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 08:21:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:21:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:21:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 08:21:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:21:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:22:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:22:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.175476, avg_loss=0.619116, seen=480, correct=307, accuracy=0.639583
2025-10-10 08:22:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:22:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:22:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2070MB allocated=1929MB
2025-10-10 08:22:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.2339531481266, 'train_avg_loss': 0.5769496095677217, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 08:22:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.17547607421875, 'train_avg_loss': 0.6191155751546223, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:22:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 297.17547607421875, 'train_avg_loss': 0.6191155751546223, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:22:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 08:22:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:22:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:22:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:22:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.011475, avg_loss=0.604191, seen=480, correct=327, accuracy=0.681250
2025-10-10 08:22:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:22:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:22:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2064MB allocated=1929MB
2025-10-10 08:22:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.9997450709343, 'train_avg_loss': 0.6083312089244525, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:22:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.011474609375, 'train_avg_loss': 0.6041905721028645, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 08:22:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 290.011474609375, 'train_avg_loss': 0.6041905721028645, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 08:22:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:22:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:22:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:23:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:23:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.104614, avg_loss=0.598135, seen=480, correct=326, accuracy=0.679167
2025-10-10 08:23:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:23:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:23:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:23:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2124MB allocated=1929MB
2025-10-10 08:23:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.33666282892227, 'train_avg_loss': 0.6111388569076855, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 08:23:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.1046142578125, 'train_avg_loss': 0.5981346130371094, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:23:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 287.1046142578125, 'train_avg_loss': 0.5981346130371094, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:23:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #75) -------------
2025-10-10 08:23:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=75 aidx=1 | s=5 (candidates=16)
2025-10-10 08:23:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 15, 28, 48, 45] (from 16)
2025-10-10 08:23:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 08:23:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:23:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:24:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:24:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.148254, avg_loss=0.625309, seen=480, correct=305, accuracy=0.635417
2025-10-10 08:24:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:24:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:24:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2110MB allocated=1929MB
2025-10-10 08:24:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62691897153854, 'train_avg_loss': 0.6802243247628212, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:24:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.14825439453125, 'train_avg_loss': 0.6253088633219401, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 08:24:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 300.14825439453125, 'train_avg_loss': 0.6253088633219401, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 08:24:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 08:24:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:24:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:24:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:24:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.752594, avg_loss=0.607818, seen=480, correct=317, accuracy=0.660417
2025-10-10 08:24:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:24:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:24:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2064MB allocated=1929MB
2025-10-10 08:24:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.81412491202354, 'train_avg_loss': 0.6651177076001962, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 08:24:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.7525939941406, 'train_avg_loss': 0.6078179041544597, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:24:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 291.7525939941406, 'train_avg_loss': 0.6078179041544597, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:24:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 08:24:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:24:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:25:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:25:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.451965, avg_loss=0.598858, seen=480, correct=325, accuracy=0.677083
2025-10-10 08:25:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:25:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:25:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2064MB allocated=1929MB
2025-10-10 08:25:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.60422387719154, 'train_avg_loss': 0.5967018656432629, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:25:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.45196533203125, 'train_avg_loss': 0.5988582611083985, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:25:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 287.45196533203125, 'train_avg_loss': 0.5988582611083985, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:25:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:25:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:25:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 08:25:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 08:25:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:25:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:25:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:25:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:26:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:26:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.880310, avg_loss=0.658084, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:26:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:26:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:26:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:26:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2086MB allocated=1929MB
2025-10-10 08:26:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.90920668840408, 'train_avg_loss': 0.7325767224033674, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:26:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.88031005859375, 'train_avg_loss': 0.658083979288737, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:26:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 315.88031005859375, 'train_avg_loss': 0.658083979288737, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:26:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 08:26:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:26:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:27:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:27:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.679077, avg_loss=0.611831, seen=480, correct=326, accuracy=0.679167
2025-10-10 08:27:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:27:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:27:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2068MB allocated=1929MB
2025-10-10 08:27:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.74134784936905, 'train_avg_loss': 0.5978445654114087, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:27:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.6790771484375, 'train_avg_loss': 0.6118314107259114, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:27:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 293.6790771484375, 'train_avg_loss': 0.6118314107259114, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:27:03 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #76) -------------
2025-10-10 08:27:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=76 aidx=1 | s=5 (candidates=16)
2025-10-10 08:27:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[43, 15, 48, 6, 34] (from 16)
2025-10-10 08:27:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:27:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:27:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:27:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:27:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=275.719879, avg_loss=0.574416, seen=480, correct=339, accuracy=0.706250
2025-10-10 08:27:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:27:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:27:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2124MB allocated=1929MB
2025-10-10 08:27:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.74736806750298, 'train_avg_loss': 0.5895614005625248, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 08:27:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 275.7198791503906, 'train_avg_loss': 0.5744164148966472, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:27:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 275.7198791503906, 'train_avg_loss': 0.5744164148966472, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:27:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:27:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:27:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 08:27:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 08:27:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:27:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:27:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:27:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:28:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:28:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.523132, avg_loss=0.611507, seen=480, correct=321, accuracy=0.668750
2025-10-10 08:28:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:28:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:28:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2064MB allocated=1929MB
2025-10-10 08:28:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.48787704110146, 'train_avg_loss': 0.6623989753425121, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:28:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.52313232421875, 'train_avg_loss': 0.6115065256754557, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:28:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 293.52313232421875, 'train_avg_loss': 0.6115065256754557, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:28:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:28:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:28:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 08:28:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 08:28:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:28:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:28:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:28:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:29:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:29:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.424316, avg_loss=0.655051, seen=480, correct=287, accuracy=0.597917
2025-10-10 08:29:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:29:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:29:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2086MB allocated=1929MB
2025-10-10 08:29:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.51285871863365, 'train_avg_loss': 0.7292738226552804, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:29:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.42431640625, 'train_avg_loss': 0.6550506591796875, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 08:29:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 314.42431640625, 'train_avg_loss': 0.6550506591796875, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 08:29:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 08:29:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:29:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:29:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:29:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.616974, avg_loss=0.653369, seen=480, correct=304, accuracy=0.633333
2025-10-10 08:29:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:29:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:29:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2074MB allocated=1929MB
2025-10-10 08:29:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.2241798043251, 'train_avg_loss': 0.6352014983693759, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 08:29:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.6169738769531, 'train_avg_loss': 0.6533686955769856, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:29:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 313.6169738769531, 'train_avg_loss': 0.6533686955769856, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 08:29:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:29:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:29:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 08:29:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 08:29:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:29:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:29:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:29:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:30:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:30:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.480743, avg_loss=0.638502, seen=480, correct=298, accuracy=0.620833
2025-10-10 08:30:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:30:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:30:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:30:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2082MB allocated=1929MB
2025-10-10 08:30:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.49782025814056, 'train_avg_loss': 0.6791485021511714, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 08:30:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.4807434082031, 'train_avg_loss': 0.6385015487670899, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 08:30:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 306.4807434082031, 'train_avg_loss': 0.6385015487670899, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 08:30:37 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #77) -------------
2025-10-10 08:30:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=77 aidx=1 | s=5 (candidates=16)
2025-10-10 08:30:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[43, 51, 48, 47, 34] (from 16)
2025-10-10 08:30:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:30:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:30:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 08:30:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:30:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:30:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:30:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:30:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:30:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:31:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:31:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=277.166931, avg_loss=0.577431, seen=480, correct=338, accuracy=0.704167
2025-10-10 08:31:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:31:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:31:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2124MB allocated=1929MB
2025-10-10 08:31:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.12789088487625, 'train_avg_loss': 0.5843990907073021, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:31:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 277.16693115234375, 'train_avg_loss': 0.5774311065673828, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 08:31:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 277.16693115234375, 'train_avg_loss': 0.5774311065673828, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 08:31:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:31:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:31:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 08:31:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 08:31:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:31:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:31:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:31:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:32:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:32:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.490234, avg_loss=0.630188, seen=480, correct=306, accuracy=0.637500
2025-10-10 08:32:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:32:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:32:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2110MB allocated=1929MB
2025-10-10 08:32:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72889655828476, 'train_avg_loss': 0.6894074713190397, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:32:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.490234375, 'train_avg_loss': 0.63018798828125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:32:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 302.490234375, 'train_avg_loss': 0.63018798828125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:32:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 08:32:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:32:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:32:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:32:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.632385, avg_loss=0.655484, seen=480, correct=294, accuracy=0.612500
2025-10-10 08:32:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:32:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:32:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2086MB allocated=1929MB
2025-10-10 08:32:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.01591631770134, 'train_avg_loss': 0.7167993026475111, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:32:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.63238525390625, 'train_avg_loss': 0.655484135945638, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 08:32:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 314.63238525390625, 'train_avg_loss': 0.655484135945638, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 08:32:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:32:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:32:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 08:32:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:32:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:32:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:32:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:32:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:33:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:33:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.396881, avg_loss=0.619577, seen=480, correct=312, accuracy=0.650000
2025-10-10 08:33:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:33:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:33:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:33:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2070MB allocated=1929MB
2025-10-10 08:33:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.65547993779182, 'train_avg_loss': 0.5721289994815986, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:33:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.3968811035156, 'train_avg_loss': 0.6195768356323242, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 08:33:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 297.3968811035156, 'train_avg_loss': 0.6195768356323242, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 08:33:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:33:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:33:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 08:33:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 08:33:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:33:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:33:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:33:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:33:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:34:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:34:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.792267, avg_loss=0.628734, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:34:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:34:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:34:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2082MB allocated=1929MB
2025-10-10 08:34:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.8191431760788, 'train_avg_loss': 0.6568261931339899, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:34:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.7922668457031, 'train_avg_loss': 0.6287338892618816, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:34:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 301.7922668457031, 'train_avg_loss': 0.6287338892618816, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:34:21 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #78) -------------
2025-10-10 08:34:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=78 aidx=1 | s=5 (candidates=16)
2025-10-10 08:34:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 15, 28, 43, 26] (from 16)
2025-10-10 08:34:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:34:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:34:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 08:34:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 08:34:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:34:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:34:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:34:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:35:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:35:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.235382, avg_loss=0.631740, seen=480, correct=308, accuracy=0.641667
2025-10-10 08:35:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:35:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:35:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2104MB allocated=1929MB
2025-10-10 08:35:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.22700941562653, 'train_avg_loss': 0.576891745130221, 'train_seen': 120, 'train_correct': 88, 'train_acc': 0.7333333333333333}}
2025-10-10 08:35:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.2353820800781, 'train_avg_loss': 0.6317403793334961, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 08:35:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 303.2353820800781, 'train_avg_loss': 0.6317403793334961, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 08:35:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:35:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:35:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 08:35:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 08:35:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:35:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:35:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:35:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:35:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:35:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.967590, avg_loss=0.608266, seen=480, correct=328, accuracy=0.683333
2025-10-10 08:35:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:35:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:35:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2064MB allocated=1929MB
2025-10-10 08:35:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.56101071834564, 'train_avg_loss': 0.6630084226528804, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:35:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.96759033203125, 'train_avg_loss': 0.6082658131917318, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 08:35:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 291.96759033203125, 'train_avg_loss': 0.6082658131917318, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 08:35:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:35:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:35:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 08:35:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 08:35:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:35:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:35:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:35:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:36:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:36:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.661102, avg_loss=0.597211, seen=480, correct=326, accuracy=0.679167
2025-10-10 08:36:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:36:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2064MB allocated=1929MB
2025-10-10 08:36:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.61406776309013, 'train_avg_loss': 0.6051172313590845, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:36:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.6611022949219, 'train_avg_loss': 0.5972106297810872, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:36:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 286.6611022949219, 'train_avg_loss': 0.5972106297810872, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:36:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:36:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:36:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 08:36:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:36:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:36:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:36:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:36:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:36:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:37:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:37:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=278.951172, avg_loss=0.581148, seen=480, correct=339, accuracy=0.706250
2025-10-10 08:37:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:37:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:37:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2124MB allocated=1929MB
2025-10-10 08:37:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.17730730772018, 'train_avg_loss': 0.5848108942310015, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 08:37:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 278.951171875, 'train_avg_loss': 0.5811482747395833, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:37:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 278.951171875, 'train_avg_loss': 0.5811482747395833, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 08:37:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 08:37:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:37:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:37:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.728821, avg_loss=0.651518, seen=480, correct=297, accuracy=0.618750
2025-10-10 08:37:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:37:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:37:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2064MB allocated=1929MB
2025-10-10 08:37:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.1441478729248, 'train_avg_loss': 0.6012012322743734, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:37:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.72882080078125, 'train_avg_loss': 0.6515183766682943, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:37:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 312.72882080078125, 'train_avg_loss': 0.6515183766682943, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 08:37:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #79) -------------
2025-10-10 08:37:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=79 aidx=1 | s=5 (candidates=16)
2025-10-10 08:37:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 43, 29, 40, 15] (from 16)
2025-10-10 08:37:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 08:37:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:37:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:38:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:38:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.721741, avg_loss=0.622337, seen=480, correct=308, accuracy=0.641667
2025-10-10 08:38:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:38:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:38:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:38:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2070MB allocated=1929MB
2025-10-10 08:38:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.08034810423851, 'train_avg_loss': 0.575669567535321, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:38:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.72174072265625, 'train_avg_loss': 0.6223369598388672, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 08:38:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 298.72174072265625, 'train_avg_loss': 0.6223369598388672, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 08:38:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 08:38:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:39:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:39:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=276.856812, avg_loss=0.576785, seen=480, correct=342, accuracy=0.712500
2025-10-10 08:39:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:39:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:39:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:39:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2124MB allocated=1929MB
2025-10-10 08:39:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.71221727132797, 'train_avg_loss': 0.5726018105943997, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:39:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 276.8568115234375, 'train_avg_loss': 0.5767850240071615, 'train_seen': 480, 'train_correct': 342, 'train_acc': 0.7125}}
2025-10-10 08:39:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 276.8568115234375, 'train_avg_loss': 0.5767850240071615, 'train_seen': 480, 'train_correct': 342, 'train_acc': 0.7125}}
2025-10-10 08:39:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 08:39:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:40:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:40:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.612579, avg_loss=0.626276, seen=480, correct=314, accuracy=0.654167
2025-10-10 08:40:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:40:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:40:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2096MB allocated=1929MB
2025-10-10 08:40:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.6785663664341, 'train_avg_loss': 0.6139880530536175, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 08:40:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.6125793457031, 'train_avg_loss': 0.6262762069702148, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:40:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 300.6125793457031, 'train_avg_loss': 0.6262762069702148, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:40:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 08:40:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:40:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:40:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.495361, avg_loss=0.663532, seen=480, correct=288, accuracy=0.600000
2025-10-10 08:40:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:40:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:40:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2064MB allocated=1929MB
2025-10-10 08:40:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.38457715511322, 'train_avg_loss': 0.6698714762926101, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 08:40:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.495361328125, 'train_avg_loss': 0.663532002766927, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:40:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 318.495361328125, 'train_avg_loss': 0.663532002766927, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:40:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:40:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:40:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 08:40:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 08:40:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:40:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:40:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:40:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:41:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:41:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.063293, avg_loss=0.606382, seen=480, correct=325, accuracy=0.677083
2025-10-10 08:41:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:41:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:41:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:41:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2064MB allocated=1929MB
2025-10-10 08:41:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.38110238313675, 'train_avg_loss': 0.6531758531928062, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:41:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.06329345703125, 'train_avg_loss': 0.6063818613688151, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:41:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 291.06329345703125, 'train_avg_loss': 0.6063818613688151, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:41:32 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #80) -------------
2025-10-10 08:41:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=80 aidx=2 | s=5 (candidates=9)
2025-10-10 08:41:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 41, 5, 32, 36] (from 9)
2025-10-10 08:41:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 08:41:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:42:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:42:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.475464, avg_loss=0.715574, seen=480, correct=241, accuracy=0.502083
2025-10-10 08:42:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:42:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:42:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2136MB allocated=1980MB
2025-10-10 08:42:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.18757778406143, 'train_avg_loss': 0.7098964815338452, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 08:42:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.4754638671875, 'train_avg_loss': 0.7155738830566406, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 08:42:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 343.4754638671875, 'train_avg_loss': 0.7155738830566406, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 08:42:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 08:42:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:42:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:42:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:42:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=350.256317, avg_loss=0.729701, seen=480, correct=227, accuracy=0.472917
2025-10-10 08:42:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:42:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:42:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2090MB allocated=1988MB
2025-10-10 08:42:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.44358223676682, 'train_avg_loss': 0.7120298519730568, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 08:42:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 350.2563171386719, 'train_avg_loss': 0.7297006607055664, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 08:42:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 350.2563171386719, 'train_avg_loss': 0.7297006607055664, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 08:42:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:42:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:42:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 08:42:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 08:42:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:42:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:42:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:42:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:43:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:43:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=352.306519, avg_loss=0.733972, seen=480, correct=236, accuracy=0.491667
2025-10-10 08:43:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:43:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:43:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2158MB allocated=1997MB
2025-10-10 08:43:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.17080253362656, 'train_avg_loss': 0.7180900211135547, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 08:43:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 352.3065185546875, 'train_avg_loss': 0.733971913655599, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 08:43:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 352.3065185546875, 'train_avg_loss': 0.733971913655599, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 08:43:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:43:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:43:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 08:43:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 08:43:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:43:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:43:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:43:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:44:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:44:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.534912, avg_loss=0.711531, seen=480, correct=257, accuracy=0.535417
2025-10-10 08:44:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:44:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:44:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:44:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2092MB allocated=2005MB
2025-10-10 08:44:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.49267810583115, 'train_avg_loss': 0.7124389842152595, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 08:44:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.534912109375, 'train_avg_loss': 0.7115310668945313, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 08:44:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 341.534912109375, 'train_avg_loss': 0.7115310668945313, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 08:44:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:44:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:44:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 08:44:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 08:44:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:44:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:44:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:44:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:44:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:44:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:44:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.949829, avg_loss=0.712395, seen=480, correct=242, accuracy=0.504167
2025-10-10 08:44:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:44:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:44:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:45:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2110MB allocated=2014MB
2025-10-10 08:45:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.09959757328033, 'train_avg_loss': 0.7258299797773361, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 08:45:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.9498291015625, 'train_avg_loss': 0.7123954772949219, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 08:45:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 341.9498291015625, 'train_avg_loss': 0.7123954772949219, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 08:45:01 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #81) -------------
2025-10-10 08:45:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=81 aidx=2 | s=5 (candidates=9)
2025-10-10 08:45:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 21, 37, 5, 32] (from 9)
2025-10-10 08:45:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:45:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:45:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 08:45:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 08:45:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:45:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:45:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:45:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:45:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:45:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:45:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.623901, avg_loss=0.703383, seen=480, correct=253, accuracy=0.527083
2025-10-10 08:45:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:45:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:45:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:45:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2134MB allocated=2064MB
2025-10-10 08:45:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.89910399913788, 'train_avg_loss': 0.7241591999928156, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 08:45:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.6239013671875, 'train_avg_loss': 0.7033831278483073, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 08:45:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 337.6239013671875, 'train_avg_loss': 0.7033831278483073, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 08:45:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:45:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:45:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 08:45:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 08:45:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:45:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:45:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:45:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:45:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:46:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:46:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.286407, avg_loss=0.696430, seen=480, correct=257, accuracy=0.535417
2025-10-10 08:46:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:46:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:46:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2166MB allocated=2072MB
2025-10-10 08:46:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.68604844808578, 'train_avg_loss': 0.7140504037340482, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 08:46:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2864074707031, 'train_avg_loss': 0.6964300155639649, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 08:46:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 334.2864074707031, 'train_avg_loss': 0.6964300155639649, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 08:46:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:46:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:46:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 08:46:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 08:46:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:46:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:46:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:46:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:47:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:47:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.689270, avg_loss=0.705603, seen=480, correct=252, accuracy=0.525000
2025-10-10 08:47:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:47:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:47:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2134MB allocated=2081MB
2025-10-10 08:47:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.95168054103851, 'train_avg_loss': 0.757930671175321, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 08:47:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.68927001953125, 'train_avg_loss': 0.7056026458740234, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 08:47:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 338.68927001953125, 'train_avg_loss': 0.7056026458740234, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 08:47:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:47:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:47:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 08:47:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 08:47:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:47:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:47:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:47:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:47:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:47:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.661926, avg_loss=0.722212, seen=480, correct=256, accuracy=0.533333
2025-10-10 08:47:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:47:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:47:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2152MB allocated=2039MB
2025-10-10 08:47:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.62232881784439, 'train_avg_loss': 0.7051860734820365, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:47:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.66192626953125, 'train_avg_loss': 0.7222123463948568, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 08:47:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 346.66192626953125, 'train_avg_loss': 0.7222123463948568, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 08:47:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:47:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:47:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 08:47:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 08:47:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:47:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:47:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:47:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:48:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:48:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.057922, avg_loss=0.708454, seen=480, correct=246, accuracy=0.512500
2025-10-10 08:48:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:48:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:48:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:48:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2108MB allocated=2039MB
2025-10-10 08:48:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.09740209579468, 'train_avg_loss': 0.692478350798289, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 08:48:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.05792236328125, 'train_avg_loss': 0.7084540049235026, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 08:48:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 340.05792236328125, 'train_avg_loss': 0.7084540049235026, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 08:48:38 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #82) -------------
2025-10-10 08:48:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=82 aidx=2 | s=5 (candidates=9)
2025-10-10 08:48:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 21, 36, 32, 5] (from 9)
2025-10-10 08:48:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 08:48:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:48:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:49:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:49:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.429810, avg_loss=0.707145, seen=480, correct=235, accuracy=0.489583
2025-10-10 08:49:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:49:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:49:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2064MB allocated=1997MB
2025-10-10 08:49:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75690001249313, 'train_avg_loss': 0.6896408334374428, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 08:49:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.4298095703125, 'train_avg_loss': 0.7071454366048177, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 08:49:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 339.4298095703125, 'train_avg_loss': 0.7071454366048177, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 08:49:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 08:49:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:49:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:50:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:50:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.474884, avg_loss=0.694739, seen=480, correct=251, accuracy=0.522917
2025-10-10 08:50:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:50:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:50:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2100MB allocated=1997MB
2025-10-10 08:50:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.29381430149078, 'train_avg_loss': 0.7107817858457566, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 08:50:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4748840332031, 'train_avg_loss': 0.6947393417358398, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 08:50:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 333.4748840332031, 'train_avg_loss': 0.6947393417358398, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 08:50:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 08:50:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:50:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:50:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:50:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.711853, avg_loss=0.680650, seen=480, correct=266, accuracy=0.554167
2025-10-10 08:50:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:50:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:50:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2080MB allocated=1997MB
2025-10-10 08:50:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.44704610109329, 'train_avg_loss': 0.6787253841757774, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:50:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.71185302734375, 'train_avg_loss': 0.6806496938069662, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 08:50:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 326.71185302734375, 'train_avg_loss': 0.6806496938069662, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 08:50:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 08:50:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:50:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:51:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:51:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.709290, avg_loss=0.697311, seen=480, correct=254, accuracy=0.529167
2025-10-10 08:51:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:51:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:51:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:51:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2064MB allocated=1997MB
2025-10-10 08:51:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.21185159683228, 'train_avg_loss': 0.6850987633069356, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 08:51:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.70928955078125, 'train_avg_loss': 0.6973110198974609, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 08:51:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 334.70928955078125, 'train_avg_loss': 0.6973110198974609, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 08:51:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 08:51:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:51:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:52:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.509949, avg_loss=0.717729, seen=480, correct=258, accuracy=0.537500
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:52:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:52:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2116MB allocated=1997MB
2025-10-10 08:52:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.16725301742554, 'train_avg_loss': 0.7097271084785461, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 08:52:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.50994873046875, 'train_avg_loss': 0.7177290598551432, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:52:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 344.50994873046875, 'train_avg_loss': 0.7177290598551432, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:52:13 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #83) -------------
2025-10-10 08:52:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=83 aidx=2 | s=5 (candidates=9)
2025-10-10 08:52:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 31, 32, 21, 3] (from 9)
2025-10-10 08:52:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:52:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:52:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 08:52:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 08:52:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:52:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:52:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:52:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:52:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.542786, avg_loss=0.696964, seen=480, correct=249, accuracy=0.518750
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:52:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:52:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2064MB allocated=1997MB
2025-10-10 08:52:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.12956470251083, 'train_avg_loss': 0.7094130391875902, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 08:52:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.54278564453125, 'train_avg_loss': 0.6969641367594401, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 08:52:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 334.54278564453125, 'train_avg_loss': 0.6969641367594401, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 08:52:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:52:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:52:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 08:52:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 08:52:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:52:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:52:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:52:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:53:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.706512, avg_loss=0.707722, seen=480, correct=230, accuracy=0.479167
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:53:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:53:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:53:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2106MB allocated=2047MB
2025-10-10 08:53:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.30863463878632, 'train_avg_loss': 0.7025719553232193, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 08:53:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.7065124511719, 'train_avg_loss': 0.7077219009399414, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 08:53:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 339.7065124511719, 'train_avg_loss': 0.7077219009399414, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 08:53:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 08:53:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:53:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:54:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:54:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.378326, avg_loss=0.696622, seen=480, correct=252, accuracy=0.525000
2025-10-10 08:54:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:54:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2064MB allocated=2006MB
2025-10-10 08:54:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.18759644031525, 'train_avg_loss': 0.6932299703359603, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:54:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.3783264160156, 'train_avg_loss': 0.6966215133666992, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 08:54:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 334.3783264160156, 'train_avg_loss': 0.6966215133666992, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 08:54:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 08:54:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:54:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:55:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:55:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.556641, avg_loss=0.692826, seen=480, correct=260, accuracy=0.541667
2025-10-10 08:55:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:55:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:55:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2104MB allocated=2006MB
2025-10-10 08:55:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.45971846580505, 'train_avg_loss': 0.7038309872150421, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 08:55:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.556640625, 'train_avg_loss': 0.6928263346354167, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 08:55:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 332.556640625, 'train_avg_loss': 0.6928263346354167, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 08:55:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:55:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:55:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 08:55:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:55:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:55:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.232697, avg_loss=0.700485, seen=480, correct=245, accuracy=0.510417
2025-10-10 08:55:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:55:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:55:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2118MB allocated=2006MB
2025-10-10 08:55:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.67354500293732, 'train_avg_loss': 0.6972795416911443, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:55:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.2326965332031, 'train_avg_loss': 0.7004847844441732, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 08:55:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 336.2326965332031, 'train_avg_loss': 0.7004847844441732, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 08:55:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #84) -------------
2025-10-10 08:55:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=84 aidx=2 | s=5 (candidates=9)
2025-10-10 08:55:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 5, 41, 21, 36] (from 9)
2025-10-10 08:55:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 08:55:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:55:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:56:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:56:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.785675, avg_loss=0.695387, seen=480, correct=251, accuracy=0.522917
2025-10-10 08:56:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:56:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:56:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:56:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2114MB allocated=2006MB
2025-10-10 08:56:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.08291840553284, 'train_avg_loss': 0.6923576533794403, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 08:56:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.7856750488281, 'train_avg_loss': 0.6953868230183919, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 08:56:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 333.7856750488281, 'train_avg_loss': 0.6953868230183919, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 08:56:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 08:56:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:57:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:57:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.980072, avg_loss=0.702042, seen=480, correct=256, accuracy=0.533333
2025-10-10 08:57:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:57:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:57:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2116MB allocated=2006MB
2025-10-10 08:57:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.70108842849731, 'train_avg_loss': 0.6975090702374777, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 08:57:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9800720214844, 'train_avg_loss': 0.7020418167114257, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 08:57:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 336.9800720214844, 'train_avg_loss': 0.7020418167114257, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 08:57:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 08:57:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:57:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:57:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.170288, avg_loss=0.704521, seen=480, correct=238, accuracy=0.495833
2025-10-10 08:57:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:57:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:57:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2064MB allocated=2006MB
2025-10-10 08:57:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.91476619243622, 'train_avg_loss': 0.6909563849369685, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 08:57:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.1702880859375, 'train_avg_loss': 0.7045214335123698, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 08:57:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 338.1702880859375, 'train_avg_loss': 0.7045214335123698, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 08:57:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:57:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:57:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 08:57:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 08:57:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:57:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:57:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:57:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:58:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:58:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.249481, avg_loss=0.692186, seen=480, correct=258, accuracy=0.537500
2025-10-10 08:58:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:58:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:58:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2104MB allocated=2006MB
2025-10-10 08:58:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.90297901630402, 'train_avg_loss': 0.7075248251358668, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 08:58:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.2494812011719, 'train_avg_loss': 0.6921864191691081, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:58:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 332.2494812011719, 'train_avg_loss': 0.6921864191691081, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:58:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 08:58:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:58:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:59:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:59:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.250854, avg_loss=0.683856, seen=480, correct=258, accuracy=0.537500
2025-10-10 08:59:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:59:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:59:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:59:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2076MB allocated=2006MB
2025-10-10 08:59:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00917392969131, 'train_avg_loss': 0.6834097827474276, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 08:59:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2508544921875, 'train_avg_loss': 0.683855946858724, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:59:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 328.2508544921875, 'train_avg_loss': 0.683855946858724, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 08:59:22 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #85) -------------
2025-10-10 08:59:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=85 aidx=2 | s=5 (candidates=9)
2025-10-10 08:59:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 3, 50, 5, 21] (from 9)
2025-10-10 08:59:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 08:59:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:59:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 08:59:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 08:59:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:59:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:59:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:59:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:59:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:00:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:00:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.412872, avg_loss=0.702943, seen=480, correct=237, accuracy=0.493750
2025-10-10 09:00:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:00:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:00:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2064MB allocated=2006MB
2025-10-10 09:00:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.79638230800629, 'train_avg_loss': 0.689969852566719, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:00:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4128723144531, 'train_avg_loss': 0.702943483988444, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 09:00:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 337.4128723144531, 'train_avg_loss': 0.702943483988444, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 09:00:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:00:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:00:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:00:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:00:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.572754, avg_loss=0.694943, seen=480, correct=255, accuracy=0.531250
2025-10-10 09:00:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:00:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:00:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2120MB allocated=2006MB
2025-10-10 09:00:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.82714378833771, 'train_avg_loss': 0.6902261982361476, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:00:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.57275390625, 'train_avg_loss': 0.6949432373046875, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 09:00:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 333.57275390625, 'train_avg_loss': 0.6949432373046875, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 09:00:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:00:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:00:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:01:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:01:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.890472, avg_loss=0.693522, seen=480, correct=256, accuracy=0.533333
2025-10-10 09:01:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:01:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:01:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:01:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2064MB allocated=2006MB
2025-10-10 09:01:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.17420244216919, 'train_avg_loss': 0.7097850203514099, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 09:01:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8904724121094, 'train_avg_loss': 0.6935218175252279, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:01:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 332.8904724121094, 'train_avg_loss': 0.6935218175252279, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:01:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:01:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:01:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:02:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:02:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.575684, avg_loss=0.703283, seen=480, correct=267, accuracy=0.556250
2025-10-10 09:02:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:02:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:02:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2116MB allocated=2006MB
2025-10-10 09:02:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91395646333694, 'train_avg_loss': 0.6992829705278079, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 09:02:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.57568359375, 'train_avg_loss': 0.7032826741536459, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 09:02:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 337.57568359375, 'train_avg_loss': 0.7032826741536459, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 09:02:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:02:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:02:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:02:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:02:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.772552, avg_loss=0.691193, seen=480, correct=258, accuracy=0.537500
2025-10-10 09:02:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:02:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:02:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2104MB allocated=2006MB
2025-10-10 09:02:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.64687198400497, 'train_avg_loss': 0.7053905998667082, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 09:02:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7725524902344, 'train_avg_loss': 0.6911928176879882, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:02:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 331.7725524902344, 'train_avg_loss': 0.6911928176879882, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:02:55 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #86) -------------
2025-10-10 09:02:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=86 aidx=2 | s=5 (candidates=9)
2025-10-10 09:02:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 36, 50, 32, 21] (from 9)
2025-10-10 09:02:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:02:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:02:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:03:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:03:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.345093, avg_loss=0.694469, seen=480, correct=264, accuracy=0.550000
2025-10-10 09:03:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:03:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:03:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2064MB allocated=2006MB
2025-10-10 09:03:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.01188921928406, 'train_avg_loss': 0.7334324101607005, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 09:03:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3450927734375, 'train_avg_loss': 0.6944689432779948, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:03:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 333.3450927734375, 'train_avg_loss': 0.6944689432779948, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:03:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:03:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:03:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 09:03:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:03:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:03:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:03:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:03:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:04:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:04:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.166016, avg_loss=0.679513, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:04:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:04:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:04:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:04:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2080MB allocated=2006MB
2025-10-10 09:04:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.44611585140228, 'train_avg_loss': 0.678717632095019, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 09:04:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.166015625, 'train_avg_loss': 0.6795125325520833, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:04:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 326.166015625, 'train_avg_loss': 0.6795125325520833, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:04:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:04:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:04:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 09:04:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:04:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:04:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:04:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:04:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:04:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:04:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:04:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.216339, avg_loss=0.694201, seen=480, correct=253, accuracy=0.527083
2025-10-10 09:04:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:04:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:05:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2064MB allocated=2006MB
2025-10-10 09:05:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.32032197713852, 'train_avg_loss': 0.711002683142821, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:05:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2163391113281, 'train_avg_loss': 0.6942007064819335, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:05:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 333.2163391113281, 'train_avg_loss': 0.6942007064819335, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:05:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:05:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:05:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:05:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:05:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.740479, avg_loss=0.693209, seen=480, correct=256, accuracy=0.533333
2025-10-10 09:05:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:05:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:05:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2064MB allocated=2006MB
2025-10-10 09:05:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.73270726203918, 'train_avg_loss': 0.6894392271836599, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:05:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.740478515625, 'train_avg_loss': 0.6932093302408854, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:05:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 332.740478515625, 'train_avg_loss': 0.6932093302408854, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:05:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:05:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:05:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:06:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:06:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.881531, avg_loss=0.687253, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:06:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:06:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:06:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2104MB allocated=2006MB
2025-10-10 09:06:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.96035528182983, 'train_avg_loss': 0.699669627348582, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 09:06:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.88153076171875, 'train_avg_loss': 0.687253189086914, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:06:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 329.88153076171875, 'train_avg_loss': 0.687253189086914, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:06:29 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #87) -------------
2025-10-10 09:06:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=87 aidx=2 | s=5 (candidates=9)
2025-10-10 09:06:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 50, 5, 32, 31] (from 9)
2025-10-10 09:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:06:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:06:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:07:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:07:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.476410, avg_loss=0.684326, seen=480, correct=268, accuracy=0.558333
2025-10-10 09:07:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:07:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:07:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2104MB allocated=2006MB
2025-10-10 09:07:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.42610740661621, 'train_avg_loss': 0.6952175617218017, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:07:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4764099121094, 'train_avg_loss': 0.6843258539835612, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:07:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 328.4764099121094, 'train_avg_loss': 0.6843258539835612, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:07:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:07:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:07:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 09:07:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:07:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:07:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:07:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:07:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:07:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:07:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.828278, avg_loss=0.695476, seen=480, correct=245, accuracy=0.510417
2025-10-10 09:07:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:07:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:07:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2064MB allocated=2006MB
2025-10-10 09:07:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.93230545520782, 'train_avg_loss': 0.7077692121267318, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:07:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8282775878906, 'train_avg_loss': 0.6954755783081055, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 09:07:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 333.8282775878906, 'train_avg_loss': 0.6954755783081055, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 09:07:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:07:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:07:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:08:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:08:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.609711, avg_loss=0.699187, seen=480, correct=264, accuracy=0.550000
2025-10-10 09:08:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:08:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:08:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:08:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2116MB allocated=2006MB
2025-10-10 09:08:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.38912725448608, 'train_avg_loss': 0.694909393787384, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 09:08:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.6097106933594, 'train_avg_loss': 0.699186897277832, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:08:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 335.6097106933594, 'train_avg_loss': 0.699186897277832, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:08:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:08:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:08:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 09:08:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:08:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:08:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:08:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:08:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:08:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:09:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:09:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.192139, avg_loss=0.692067, seen=480, correct=257, accuracy=0.535417
2025-10-10 09:09:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:09:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:09:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2064MB allocated=2006MB
2025-10-10 09:09:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60486483573914, 'train_avg_loss': 0.6883738736311594, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:09:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.192138671875, 'train_avg_loss': 0.6920669555664063, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 09:09:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 332.192138671875, 'train_avg_loss': 0.6920669555664063, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 09:09:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:09:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:09:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:10:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:10:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.866760, avg_loss=0.703889, seen=480, correct=237, accuracy=0.493750
2025-10-10 09:10:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:10:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:10:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2076MB allocated=2006MB
2025-10-10 09:10:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26916718482971, 'train_avg_loss': 0.7022430598735809, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:10:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.86676025390625, 'train_avg_loss': 0.7038890838623046, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 09:10:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 337.86676025390625, 'train_avg_loss': 0.7038890838623046, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 09:10:08 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #88) -------------
2025-10-10 09:10:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=88 aidx=2 | s=5 (candidates=9)
2025-10-10 09:10:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 36, 31, 50, 21] (from 9)
2025-10-10 09:10:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:10:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:10:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:10:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:10:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.406555, avg_loss=0.690430, seen=480, correct=258, accuracy=0.537500
2025-10-10 09:10:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:10:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:10:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2064MB allocated=2006MB
2025-10-10 09:10:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64903223514557, 'train_avg_loss': 0.6887419352928797, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 09:10:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.40655517578125, 'train_avg_loss': 0.6904303232828776, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:10:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 331.40655517578125, 'train_avg_loss': 0.6904303232828776, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:10:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:10:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:10:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:11:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:11:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.945862, avg_loss=0.676971, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:11:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:11:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:11:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:11:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2080MB allocated=2006MB
2025-10-10 09:11:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.19470131397247, 'train_avg_loss': 0.6766225109497707, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 09:11:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.94586181640625, 'train_avg_loss': 0.6769705454508463, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:11:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 324.94586181640625, 'train_avg_loss': 0.6769705454508463, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:11:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:11:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:11:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:12:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:12:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.233612, avg_loss=0.696320, seen=480, correct=252, accuracy=0.525000
2025-10-10 09:12:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:12:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:12:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2076MB allocated=2006MB
2025-10-10 09:12:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.591881275177, 'train_avg_loss': 0.696599010626475, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 09:12:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2336120605469, 'train_avg_loss': 0.6963200251261393, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 09:12:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 334.2336120605469, 'train_avg_loss': 0.6963200251261393, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 09:12:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:12:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:12:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 09:12:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:12:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:12:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:12:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:12:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:12:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:12:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.501068, avg_loss=0.694794, seen=480, correct=240, accuracy=0.500000
2025-10-10 09:12:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:12:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:12:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2064MB allocated=2006MB
2025-10-10 09:12:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.64888656139374, 'train_avg_loss': 0.7054073880116145, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 09:12:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5010681152344, 'train_avg_loss': 0.6947938919067382, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 09:12:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 333.5010681152344, 'train_avg_loss': 0.6947938919067382, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 09:12:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:12:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:12:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:13:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:13:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.037354, avg_loss=0.681328, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:13:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:13:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:13:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2102MB allocated=2006MB
2025-10-10 09:13:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.85637032985687, 'train_avg_loss': 0.6904697527488073, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:13:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.037353515625, 'train_avg_loss': 0.6813278198242188, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:13:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 327.037353515625, 'train_avg_loss': 0.6813278198242188, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:13:41 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #89) -------------
2025-10-10 09:13:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=89 aidx=2 | s=5 (candidates=9)
2025-10-10 09:13:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 32, 31, 3, 37] (from 9)
2025-10-10 09:13:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:13:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:13:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:14:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:14:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.388611, avg_loss=0.677893, seen=480, correct=273, accuracy=0.568750
2025-10-10 09:14:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:14:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:14:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:14:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2102MB allocated=2006MB
2025-10-10 09:14:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5833899974823, 'train_avg_loss': 0.6881949166456859, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:14:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.38861083984375, 'train_avg_loss': 0.6778929392496745, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 09:14:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 325.38861083984375, 'train_avg_loss': 0.6778929392496745, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 09:14:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:14:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:15:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:15:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.932190, avg_loss=0.691525, seen=480, correct=263, accuracy=0.547917
2025-10-10 09:15:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:15:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:15:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2064MB allocated=2006MB
2025-10-10 09:15:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.33014178276062, 'train_avg_loss': 0.6860845148563385, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:15:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.93218994140625, 'train_avg_loss': 0.691525395711263, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 09:15:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 331.93218994140625, 'train_avg_loss': 0.691525395711263, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 09:15:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:15:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:15:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:15:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:15:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:15:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.825317, avg_loss=0.699636, seen=480, correct=245, accuracy=0.510417
2025-10-10 09:15:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:15:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2076MB allocated=2006MB
2025-10-10 09:15:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.85697364807129, 'train_avg_loss': 0.6988081137339274, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:15:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.8253173828125, 'train_avg_loss': 0.6996360778808594, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 09:15:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 335.8253173828125, 'train_avg_loss': 0.6996360778808594, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 09:15:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:15:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:15:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 09:15:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:15:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:15:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:15:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:15:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:16:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:16:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.458771, avg_loss=0.694706, seen=480, correct=251, accuracy=0.522917
2025-10-10 09:16:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:16:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:16:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:16:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2118MB allocated=2006MB
2025-10-10 09:16:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.56596887111664, 'train_avg_loss': 0.696383073925972, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 09:16:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4587707519531, 'train_avg_loss': 0.6947057723999024, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 09:16:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 333.4587707519531, 'train_avg_loss': 0.6947057723999024, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 09:16:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:16:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:16:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:16:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:17:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:17:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.578247, avg_loss=0.692871, seen=480, correct=266, accuracy=0.554167
2025-10-10 09:17:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:17:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:17:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2064MB allocated=2006MB
2025-10-10 09:17:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.22447592020035, 'train_avg_loss': 0.7268706326683362, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 09:17:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5782470703125, 'train_avg_loss': 0.6928713480631511, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:17:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 332.5782470703125, 'train_avg_loss': 0.6928713480631511, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:17:13 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #90) -------------
2025-10-10 09:17:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=90 aidx=2 | s=5 (candidates=9)
2025-10-10 09:17:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 21, 5, 32, 41] (from 9)
2025-10-10 09:17:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:17:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:17:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:17:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.292786, avg_loss=0.694360, seen=480, correct=258, accuracy=0.537500
2025-10-10 09:17:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:17:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:17:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2120MB allocated=2006MB
2025-10-10 09:17:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6668496131897, 'train_avg_loss': 0.6972237467765808, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 09:17:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.29278564453125, 'train_avg_loss': 0.6943599700927734, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:17:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 333.29278564453125, 'train_avg_loss': 0.6943599700927734, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:17:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:17:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:17:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 09:17:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:17:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:18:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:18:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.081848, avg_loss=0.679337, seen=480, correct=278, accuracy=0.579167
2025-10-10 09:18:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:18:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:18:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2102MB allocated=2006MB
2025-10-10 09:18:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1086095571518, 'train_avg_loss': 0.6925717463095983, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 09:18:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.08184814453125, 'train_avg_loss': 0.6793371836344401, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 09:18:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 326.08184814453125, 'train_avg_loss': 0.6793371836344401, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 09:18:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:18:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:18:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:19:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:19:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.421021, avg_loss=0.700877, seen=480, correct=266, accuracy=0.554167
2025-10-10 09:19:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:19:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:19:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:19:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2116MB allocated=2006MB
2025-10-10 09:19:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.14956420660019, 'train_avg_loss': 0.6929130350550016, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:19:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4210205078125, 'train_avg_loss': 0.7008771260579427, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:19:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 336.4210205078125, 'train_avg_loss': 0.7008771260579427, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:19:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:19:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:19:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:20:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:20:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.019501, avg_loss=0.693791, seen=480, correct=240, accuracy=0.500000
2025-10-10 09:20:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:20:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:20:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:20:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2064MB allocated=2006MB
2025-10-10 09:20:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.35638701915741, 'train_avg_loss': 0.686303225159645, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 09:20:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0195007324219, 'train_avg_loss': 0.6937906265258789, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 09:20:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 333.0195007324219, 'train_avg_loss': 0.6937906265258789, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 09:20:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:20:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 09:20:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:20:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:20:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:20:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:20:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:20:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:20:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:20:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.533142, avg_loss=0.696944, seen=480, correct=250, accuracy=0.520833
2025-10-10 09:20:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:20:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:20:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:20:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2064MB allocated=2006MB
2025-10-10 09:20:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.23004949092865, 'train_avg_loss': 0.6852504124244054, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 09:20:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.53314208984375, 'train_avg_loss': 0.6969440460205079, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 09:20:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 334.53314208984375, 'train_avg_loss': 0.6969440460205079, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 09:20:45 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #91) -------------
2025-10-10 09:20:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=91 aidx=2 | s=5 (candidates=9)
2025-10-10 09:20:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[31, 36, 5, 50, 32] (from 9)
2025-10-10 09:20:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:20:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:20:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:21:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:21:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.031433, avg_loss=0.693815, seen=480, correct=246, accuracy=0.512500
2025-10-10 09:21:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:21:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:21:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:21:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2076MB allocated=2006MB
2025-10-10 09:21:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.96545743942261, 'train_avg_loss': 0.6913788119951884, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:21:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.03143310546875, 'train_avg_loss': 0.6938154856363933, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:21:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 333.03143310546875, 'train_avg_loss': 0.6938154856363933, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:21:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:21:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:21:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:22:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:22:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.175354, avg_loss=0.681615, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:22:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:22:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:22:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:22:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2080MB allocated=2006MB
2025-10-10 09:22:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.34631890058517, 'train_avg_loss': 0.6778859908382098, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 09:22:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.17535400390625, 'train_avg_loss': 0.6816153208414714, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:22:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 327.17535400390625, 'train_avg_loss': 0.6816153208414714, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:22:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:22:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:22:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:22:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:22:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.446960, avg_loss=0.698848, seen=480, correct=253, accuracy=0.527083
2025-10-10 09:22:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:22:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:22:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:22:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2116MB allocated=2006MB
2025-10-10 09:22:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.84512639045715, 'train_avg_loss': 0.698709386587143, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 09:22:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.44696044921875, 'train_avg_loss': 0.6988478342692057, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:22:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 335.44696044921875, 'train_avg_loss': 0.6988478342692057, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:22:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:22:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:22:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:23:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:23:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.286560, avg_loss=0.692264, seen=480, correct=241, accuracy=0.502083
2025-10-10 09:23:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:23:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:23:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:23:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2064MB allocated=2006MB
2025-10-10 09:23:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5889042019844, 'train_avg_loss': 0.6965742016832034, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 09:23:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.28656005859375, 'train_avg_loss': 0.692263666788737, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 09:23:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 332.28656005859375, 'train_avg_loss': 0.692263666788737, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 09:23:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:23:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:23:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:24:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:24:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.340698, avg_loss=0.686126, seen=480, correct=275, accuracy=0.572917
2025-10-10 09:24:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:24:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:24:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:24:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2064MB allocated=2006MB
2025-10-10 09:24:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.89881992340088, 'train_avg_loss': 0.690823499361674, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:24:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3406982421875, 'train_avg_loss': 0.6861264546712239, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 09:24:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 329.3406982421875, 'train_avg_loss': 0.6861264546712239, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 09:24:08 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #92) -------------
2025-10-10 09:24:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=92 aidx=2 | s=5 (candidates=9)
2025-10-10 09:24:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 37, 31, 5, 32] (from 9)
2025-10-10 09:24:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:24:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:24:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:24:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:24:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.580139, avg_loss=0.692875, seen=480, correct=256, accuracy=0.533333
2025-10-10 09:24:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:24:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:24:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:24:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2064MB allocated=2006MB
2025-10-10 09:24:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09882134199142, 'train_avg_loss': 0.6841568445165952, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:24:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.58013916015625, 'train_avg_loss': 0.6928752899169922, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:24:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 332.58013916015625, 'train_avg_loss': 0.6928752899169922, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:24:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:24:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:24:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:25:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:25:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.313599, avg_loss=0.688153, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:25:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:25:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:25:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:25:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2064MB allocated=2006MB
2025-10-10 09:25:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.43388092517853, 'train_avg_loss': 0.7202823410431544, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:25:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3135986328125, 'train_avg_loss': 0.688153330485026, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:25:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 330.3135986328125, 'train_avg_loss': 0.688153330485026, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:25:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:25:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:25:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:26:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:26:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.779846, avg_loss=0.697458, seen=480, correct=241, accuracy=0.502083
2025-10-10 09:26:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:26:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:26:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:26:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2076MB allocated=2006MB
2025-10-10 09:26:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.13773918151855, 'train_avg_loss': 0.7011478265126546, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:26:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.77984619140625, 'train_avg_loss': 0.697458012898763, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 09:26:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 334.77984619140625, 'train_avg_loss': 0.697458012898763, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 09:26:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:26:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:26:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:26:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:26:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.106262, avg_loss=0.700221, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:26:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:26:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:26:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:26:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2116MB allocated=2006MB
2025-10-10 09:26:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.90568900108337, 'train_avg_loss': 0.6908807416756948, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 09:26:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.10626220703125, 'train_avg_loss': 0.7002213795979818, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:26:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 336.10626220703125, 'train_avg_loss': 0.7002213795979818, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:26:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:26:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:26:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 09:26:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:26:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:26:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:26:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:26:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:26:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:27:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:27:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.802032, avg_loss=0.685004, seen=480, correct=272, accuracy=0.566667
2025-10-10 09:27:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:27:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:27:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:27:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2064MB allocated=2006MB
2025-10-10 09:27:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.87741661071777, 'train_avg_loss': 0.6823118050893148, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:27:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.8020324707031, 'train_avg_loss': 0.6850042343139648, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 09:27:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 328.8020324707031, 'train_avg_loss': 0.6850042343139648, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 09:27:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #93) -------------
2025-10-10 09:27:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=93 aidx=2 | s=5 (candidates=9)
2025-10-10 09:27:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 21, 50, 5, 3] (from 9)
2025-10-10 09:27:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:27:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:27:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:28:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:28:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.078491, avg_loss=0.689747, seen=480, correct=266, accuracy=0.554167
2025-10-10 09:28:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:28:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:28:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:28:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2064MB allocated=2006MB
2025-10-10 09:28:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.12173306941986, 'train_avg_loss': 0.7176811089118321, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 09:28:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.0784912109375, 'train_avg_loss': 0.6897468566894531, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:28:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 331.0784912109375, 'train_avg_loss': 0.6897468566894531, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 09:28:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:28:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:28:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:28:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:28:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.350525, avg_loss=0.679897, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:28:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:28:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:28:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:28:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2102MB allocated=2006MB
2025-10-10 09:28:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.69987523555756, 'train_avg_loss': 0.6891656269629797, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 09:28:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.35052490234375, 'train_avg_loss': 0.6798969268798828, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:28:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 326.35052490234375, 'train_avg_loss': 0.6798969268798828, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:28:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:28:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:28:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:29:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:29:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.877289, avg_loss=0.691411, seen=480, correct=249, accuracy=0.518750
2025-10-10 09:29:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:29:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:29:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:29:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2064MB allocated=2006MB
2025-10-10 09:29:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.30864727497101, 'train_avg_loss': 0.7025720606247584, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 09:29:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8772888183594, 'train_avg_loss': 0.691411018371582, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 09:29:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 331.8772888183594, 'train_avg_loss': 0.691411018371582, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 09:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:29:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:29:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:30:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:30:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.914490, avg_loss=0.701905, seen=480, correct=258, accuracy=0.537500
2025-10-10 09:30:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:30:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:30:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:30:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2116MB allocated=2006MB
2025-10-10 09:30:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.55621027946472, 'train_avg_loss': 0.6963017523288727, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:30:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.91448974609375, 'train_avg_loss': 0.7019051869710287, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:30:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 336.91448974609375, 'train_avg_loss': 0.7019051869710287, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:30:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:30:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:30:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 09:30:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:30:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:30:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:30:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:30:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:30:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:30:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:30:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.418030, avg_loss=0.694621, seen=480, correct=249, accuracy=0.518750
2025-10-10 09:30:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:30:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:30:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:30:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2118MB allocated=2006MB
2025-10-10 09:30:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.52732539176941, 'train_avg_loss': 0.6960610449314117, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 09:30:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.41802978515625, 'train_avg_loss': 0.6946208953857422, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 09:30:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 333.41802978515625, 'train_avg_loss': 0.6946208953857422, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 09:30:43 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #94) -------------
2025-10-10 09:30:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=94 aidx=2 | s=5 (candidates=9)
2025-10-10 09:30:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 50, 37, 31, 21] (from 9)
2025-10-10 09:30:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:30:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:30:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:31:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:31:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.661224, avg_loss=0.676378, seen=480, correct=276, accuracy=0.575000
2025-10-10 09:31:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:31:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:31:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:31:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2080MB allocated=2006MB
2025-10-10 09:31:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.50221961736679, 'train_avg_loss': 0.6708518301447233, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 09:31:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6612243652344, 'train_avg_loss': 0.676377550760905, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:31:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 324.6612243652344, 'train_avg_loss': 0.676377550760905, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:31:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:31:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:31:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:32:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:32:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.752960, avg_loss=0.691152, seen=480, correct=244, accuracy=0.508333
2025-10-10 09:32:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:32:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:32:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:32:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2064MB allocated=2006MB
2025-10-10 09:32:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.95276534557343, 'train_avg_loss': 0.6996063778797785, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 09:32:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7529602050781, 'train_avg_loss': 0.6911520004272461, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 09:32:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 331.7529602050781, 'train_avg_loss': 0.6911520004272461, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 09:32:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:32:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:32:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:32:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:32:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.114471, avg_loss=0.685655, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:32:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:32:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:32:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:32:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2064MB allocated=2006MB
2025-10-10 09:32:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.91788619756699, 'train_avg_loss': 0.7159823849797249, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 09:32:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1144714355469, 'train_avg_loss': 0.685655148824056, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:32:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 329.1144714355469, 'train_avg_loss': 0.685655148824056, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:32:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:32:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:32:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:33:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:33:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.853271, avg_loss=0.693444, seen=480, correct=244, accuracy=0.508333
2025-10-10 09:33:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:33:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:33:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:33:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2076MB allocated=2006MB
2025-10-10 09:33:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.07784640789032, 'train_avg_loss': 0.6923153867324193, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 09:33:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.853271484375, 'train_avg_loss': 0.6934443155924479, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 09:33:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 332.853271484375, 'train_avg_loss': 0.6934443155924479, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 09:33:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:33:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:33:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:33:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:33:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.315002, avg_loss=0.677740, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:33:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:33:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:33:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:33:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2102MB allocated=2006MB
2025-10-10 09:33:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.29097807407379, 'train_avg_loss': 0.6857581506172816, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:33:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.31500244140625, 'train_avg_loss': 0.6777395884195964, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:33:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 325.31500244140625, 'train_avg_loss': 0.6777395884195964, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:34:00 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #95) -------------
2025-10-10 09:34:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=95 aidx=2 | s=5 (candidates=9)
2025-10-10 09:34:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 41, 31, 36, 50] (from 9)
2025-10-10 09:34:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:34:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:34:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:34:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:34:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.464478, avg_loss=0.688468, seen=480, correct=252, accuracy=0.525000
2025-10-10 09:34:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:34:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:34:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:34:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2120MB allocated=2006MB
2025-10-10 09:34:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.9552652835846, 'train_avg_loss': 0.6912938773632049, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:34:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4644775390625, 'train_avg_loss': 0.6884676615397135, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 09:34:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 330.4644775390625, 'train_avg_loss': 0.6884676615397135, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 09:34:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:34:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:34:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 09:34:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:34:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:34:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:34:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:34:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:34:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:35:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:35:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.867462, avg_loss=0.691391, seen=480, correct=259, accuracy=0.539583
2025-10-10 09:35:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:35:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:35:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:35:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2064MB allocated=2006MB
2025-10-10 09:35:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66268789768219, 'train_avg_loss': 0.6805223991473516, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 09:35:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8674621582031, 'train_avg_loss': 0.6913905461629232, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 09:35:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 331.8674621582031, 'train_avg_loss': 0.6913905461629232, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 09:35:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:35:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:35:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 09:35:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:35:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:35:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:35:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:35:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:35:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:35:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:35:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.532593, avg_loss=0.696943, seen=480, correct=247, accuracy=0.514583
2025-10-10 09:35:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:35:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:36:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:36:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2076MB allocated=2006MB
2025-10-10 09:36:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37786984443665, 'train_avg_loss': 0.694815582036972, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:36:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.5325927734375, 'train_avg_loss': 0.6969429016113281, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 09:36:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 334.5325927734375, 'train_avg_loss': 0.6969429016113281, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 09:36:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:36:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:36:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:36:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:36:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.999084, avg_loss=0.672915, seen=480, correct=282, accuracy=0.587500
2025-10-10 09:36:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:36:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:36:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:36:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2080MB allocated=2006MB
2025-10-10 09:36:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.74322009086609, 'train_avg_loss': 0.6645268340905507, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:36:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.99908447265625, 'train_avg_loss': 0.6729147593180339, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 09:36:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 322.99908447265625, 'train_avg_loss': 0.6729147593180339, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 09:36:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:36:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:36:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:37:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:37:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.477722, avg_loss=0.692662, seen=480, correct=246, accuracy=0.512500
2025-10-10 09:37:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:37:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:37:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:37:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2064MB allocated=2006MB
2025-10-10 09:37:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.70796203613281, 'train_avg_loss': 0.7058996836344401, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 09:37:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.47772216796875, 'train_avg_loss': 0.6926619211832682, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:37:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 332.47772216796875, 'train_avg_loss': 0.6926619211832682, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:37:20 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #96) -------------
2025-10-10 09:37:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=96 aidx=2 | s=5 (candidates=9)
2025-10-10 09:37:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[31, 37, 21, 3, 41] (from 9)
2025-10-10 09:37:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:37:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:37:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:37:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:37:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.774170, avg_loss=0.697446, seen=480, correct=246, accuracy=0.512500
2025-10-10 09:37:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:37:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:38:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:38:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2076MB allocated=2006MB
2025-10-10 09:38:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.24489557743073, 'train_avg_loss': 0.7020407964785894, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:38:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.774169921875, 'train_avg_loss': 0.6974461873372396, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:38:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 334.774169921875, 'train_avg_loss': 0.6974461873372396, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:38:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:38:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:38:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 09:38:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:38:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:38:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:38:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:38:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:38:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:38:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:38:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.178467, avg_loss=0.687872, seen=480, correct=269, accuracy=0.560417
2025-10-10 09:38:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:38:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:38:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:38:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2064MB allocated=2006MB
2025-10-10 09:38:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.04217195510864, 'train_avg_loss': 0.7170180996259053, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:38:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.178466796875, 'train_avg_loss': 0.687871805826823, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 09:38:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 330.178466796875, 'train_avg_loss': 0.687871805826823, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 09:38:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:38:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:38:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:39:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:39:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.626526, avg_loss=0.674222, seen=480, correct=278, accuracy=0.579167
2025-10-10 09:39:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:39:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:39:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:39:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2102MB allocated=2006MB
2025-10-10 09:39:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.86232101917267, 'train_avg_loss': 0.6821860084931056, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 09:39:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.62652587890625, 'train_avg_loss': 0.674221928914388, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 09:39:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 323.62652587890625, 'train_avg_loss': 0.674221928914388, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 09:39:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:39:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:39:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:39:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:39:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.934753, avg_loss=0.689447, seen=480, correct=253, accuracy=0.527083
2025-10-10 09:39:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:39:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:39:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:40:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2120MB allocated=2006MB
2025-10-10 09:40:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.78632992506027, 'train_avg_loss': 0.6898860827088356, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:40:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.93475341796875, 'train_avg_loss': 0.6894474029541016, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:40:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 330.93475341796875, 'train_avg_loss': 0.6894474029541016, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 09:40:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:40:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:40:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:40:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:40:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.670593, avg_loss=0.688897, seen=480, correct=264, accuracy=0.550000
2025-10-10 09:40:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:40:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:40:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:40:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2064MB allocated=2006MB
2025-10-10 09:40:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91109037399292, 'train_avg_loss': 0.6825924197832743, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:40:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.67059326171875, 'train_avg_loss': 0.6888970692952474, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:40:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 330.67059326171875, 'train_avg_loss': 0.6888970692952474, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 09:40:40 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #97) -------------
2025-10-10 09:40:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=97 aidx=2 | s=5 (candidates=9)
2025-10-10 09:40:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 50, 41, 36, 3] (from 9)
2025-10-10 09:40:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:40:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:40:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:41:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:41:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.544159, avg_loss=0.669884, seen=480, correct=292, accuracy=0.608333
2025-10-10 09:41:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:41:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:41:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:41:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2064MB allocated=2006MB
2025-10-10 09:41:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.04852640628815, 'train_avg_loss': 0.6754043867190679, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:41:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.5441589355469, 'train_avg_loss': 0.669883664449056, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 09:41:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 321.5441589355469, 'train_avg_loss': 0.669883664449056, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 09:41:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:41:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:41:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 09:41:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:41:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:41:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:41:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:41:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:41:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:41:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:41:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.585541, avg_loss=0.686637, seen=480, correct=246, accuracy=0.512500
2025-10-10 09:41:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:41:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:41:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:41:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2064MB allocated=2006MB
2025-10-10 09:41:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.02339804172516, 'train_avg_loss': 0.6918616503477096, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 09:41:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5855407714844, 'train_avg_loss': 0.6866365432739258, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:41:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 329.5855407714844, 'train_avg_loss': 0.6866365432739258, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 09:41:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:41:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:41:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 09:42:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:42:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:42:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:42:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:42:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:42:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:42:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:42:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.949554, avg_loss=0.689478, seen=480, correct=256, accuracy=0.533333
2025-10-10 09:42:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:42:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:42:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:42:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2064MB allocated=2006MB
2025-10-10 09:42:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88171344995499, 'train_avg_loss': 0.6823476120829582, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:42:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9495544433594, 'train_avg_loss': 0.6894782384236654, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:42:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 330.9495544433594, 'train_avg_loss': 0.6894782384236654, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 09:42:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:42:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:42:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 09:42:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:42:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:42:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:42:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:42:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:42:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:43:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:43:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.841003, avg_loss=0.678835, seen=480, correct=268, accuracy=0.558333
2025-10-10 09:43:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:43:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:43:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:43:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2080MB allocated=2006MB
2025-10-10 09:43:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5399022102356, 'train_avg_loss': 0.6711658517519633, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 09:43:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.84100341796875, 'train_avg_loss': 0.6788354237874349, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:43:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 325.84100341796875, 'train_avg_loss': 0.6788354237874349, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:43:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:43:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:43:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:43:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:43:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.661835, avg_loss=0.688879, seen=480, correct=257, accuracy=0.535417
2025-10-10 09:43:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:43:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:43:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:43:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2118MB allocated=2006MB
2025-10-10 09:43:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.57731032371521, 'train_avg_loss': 0.6964775860309601, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:43:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6618347167969, 'train_avg_loss': 0.6888788223266602, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 09:43:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 330.6618347167969, 'train_avg_loss': 0.6888788223266602, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 09:43:54 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #98) -------------
2025-10-10 09:43:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=98 aidx=2 | s=5 (candidates=9)
2025-10-10 09:43:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 31, 21, 37, 3] (from 9)
2025-10-10 09:43:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:43:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:43:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:44:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:44:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.184784, avg_loss=0.671218, seen=480, correct=299, accuracy=0.622917
2025-10-10 09:44:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:44:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:44:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:44:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2064MB allocated=2006MB
2025-10-10 09:44:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.47856771945953, 'train_avg_loss': 0.6706547309954961, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 09:44:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1847839355469, 'train_avg_loss': 0.6712182998657227, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 09:44:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 322.1847839355469, 'train_avg_loss': 0.6712182998657227, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 09:44:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 09:44:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:44:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:45:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:45:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.057495, avg_loss=0.693870, seen=480, correct=258, accuracy=0.537500
2025-10-10 09:45:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:45:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:45:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:45:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2076MB allocated=2006MB
2025-10-10 09:45:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.60293591022491, 'train_avg_loss': 0.6966911325852077, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 09:45:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0574951171875, 'train_avg_loss': 0.6938697814941406, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:45:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 333.0574951171875, 'train_avg_loss': 0.6938697814941406, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 09:45:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:45:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:45:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:45:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:45:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.740417, avg_loss=0.672376, seen=480, correct=276, accuracy=0.575000
2025-10-10 09:45:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:45:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:45:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:45:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2102MB allocated=2006MB
2025-10-10 09:45:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3977136015892, 'train_avg_loss': 0.6783142800132433, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 09:45:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.74041748046875, 'train_avg_loss': 0.6723758697509765, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:45:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 322.74041748046875, 'train_avg_loss': 0.6723758697509765, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:45:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:45:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:45:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:46:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:46:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.458801, avg_loss=0.688456, seen=480, correct=267, accuracy=0.556250
2025-10-10 09:46:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:46:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:46:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:46:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2064MB allocated=2006MB
2025-10-10 09:46:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.52353322505951, 'train_avg_loss': 0.7210294435421626, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 09:46:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.45880126953125, 'train_avg_loss': 0.6884558359781902, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 09:46:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 330.45880126953125, 'train_avg_loss': 0.6884558359781902, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 09:46:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:46:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:46:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:47:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:47:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.018036, avg_loss=0.681288, seen=480, correct=268, accuracy=0.558333
2025-10-10 09:47:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:47:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:47:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:47:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2120MB allocated=2006MB
2025-10-10 09:47:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.49322712421417, 'train_avg_loss': 0.6791102260351181, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:47:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0180358886719, 'train_avg_loss': 0.6812875747680665, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:47:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 327.0180358886719, 'train_avg_loss': 0.6812875747680665, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:47:16 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #99) -------------
2025-10-10 09:47:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=99 aidx=2 | s=5 (candidates=9)
2025-10-10 09:47:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 5, 36, 32, 37] (from 9)
2025-10-10 09:47:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:47:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:47:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:47:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:47:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.526978, avg_loss=0.686515, seen=480, correct=254, accuracy=0.529167
2025-10-10 09:47:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:47:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:47:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:47:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2064MB allocated=2006MB
2025-10-10 09:47:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00909531116486, 'train_avg_loss': 0.7000757942597071, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 09:47:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5269775390625, 'train_avg_loss': 0.6865145365397135, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 09:47:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 329.5269775390625, 'train_avg_loss': 0.6865145365397135, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 09:47:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:47:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:47:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:48:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:48:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.459534, avg_loss=0.694707, seen=480, correct=268, accuracy=0.558333
2025-10-10 09:48:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:48:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:48:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:48:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2116MB allocated=2006MB
2025-10-10 09:48:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.46335345506668, 'train_avg_loss': 0.6871946121255557, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 09:48:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.45953369140625, 'train_avg_loss': 0.6947073618570964, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:48:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 333.45953369140625, 'train_avg_loss': 0.6947073618570964, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 09:48:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:48:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:48:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:49:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:49:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.579468, avg_loss=0.676207, seen=480, correct=274, accuracy=0.570833
2025-10-10 09:49:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:49:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:49:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:49:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2080MB allocated=2006MB
2025-10-10 09:49:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.6762825846672, 'train_avg_loss': 0.6723023548722267, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:49:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.5794677734375, 'train_avg_loss': 0.6762072245279948, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:49:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 324.5794677734375, 'train_avg_loss': 0.6762072245279948, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:49:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:49:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:49:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:49:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:49:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.876801, avg_loss=0.676827, seen=480, correct=287, accuracy=0.597917
2025-10-10 09:49:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:49:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:49:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:49:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2064MB allocated=2006MB
2025-10-10 09:49:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.39233195781708, 'train_avg_loss': 0.678269432981809, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:49:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.8768005371094, 'train_avg_loss': 0.6768266677856445, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 09:49:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 324.8768005371094, 'train_avg_loss': 0.6768266677856445, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 09:49:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:49:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:49:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:50:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:50:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.428833, avg_loss=0.688393, seen=480, correct=270, accuracy=0.562500
2025-10-10 09:50:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:50:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:50:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:50:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2064MB allocated=2006MB
2025-10-10 09:50:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.2957484126091, 'train_avg_loss': 0.7274645701050758, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 09:50:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4288330078125, 'train_avg_loss': 0.6883934020996094, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 09:50:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 330.4288330078125, 'train_avg_loss': 0.6883934020996094, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 09:50:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #100) -------------
2025-10-10 09:50:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=100 aidx=2 | s=5 (candidates=9)
2025-10-10 09:50:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 37, 50, 41, 32] (from 9)
2025-10-10 09:50:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:50:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:50:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:51:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:51:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.497467, avg_loss=0.673953, seen=480, correct=274, accuracy=0.570833
2025-10-10 09:51:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:51:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:51:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:51:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2120MB allocated=2006MB
2025-10-10 09:51:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.45253813266754, 'train_avg_loss': 0.6704378177722295, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 09:51:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4974670410156, 'train_avg_loss': 0.6739530563354492, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:51:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 323.4974670410156, 'train_avg_loss': 0.6739530563354492, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:51:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:51:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:51:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:51:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:51:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.243134, avg_loss=0.683840, seen=480, correct=269, accuracy=0.560417
2025-10-10 09:51:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:51:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:51:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:51:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2064MB allocated=2006MB
2025-10-10 09:51:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.12866300344467, 'train_avg_loss': 0.7260721916953723, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 09:51:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2431335449219, 'train_avg_loss': 0.6838398615519206, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 09:51:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 328.2431335449219, 'train_avg_loss': 0.6838398615519206, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 09:51:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:51:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:51:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:52:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:52:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.575531, avg_loss=0.686616, seen=480, correct=271, accuracy=0.564583
2025-10-10 09:52:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:52:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:52:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:52:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2064MB allocated=2006MB
2025-10-10 09:52:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1380854845047, 'train_avg_loss': 0.7094840457042059, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 09:52:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5755310058594, 'train_avg_loss': 0.6866156895955403, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:52:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 329.5755310058594, 'train_avg_loss': 0.6866156895955403, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 09:52:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:52:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:52:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:53:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:53:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.602600, avg_loss=0.684589, seen=480, correct=272, accuracy=0.566667
2025-10-10 09:53:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:53:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:53:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:53:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2064MB allocated=2006MB
2025-10-10 09:53:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.18445527553558, 'train_avg_loss': 0.6765371272961299, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:53:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.60260009765625, 'train_avg_loss': 0.6845887502034506, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 09:53:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 328.60260009765625, 'train_avg_loss': 0.6845887502034506, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 09:53:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:53:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:53:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 09:53:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:53:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:53:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:53:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:53:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:53:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:53:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:53:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.467194, avg_loss=0.678057, seen=480, correct=280, accuracy=0.583333
2025-10-10 09:53:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:53:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:53:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:53:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2064MB allocated=2006MB
2025-10-10 09:53:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.12013691663742, 'train_avg_loss': 0.6676678076386452, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 09:53:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4671936035156, 'train_avg_loss': 0.6780566533406576, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 09:53:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 325.4671936035156, 'train_avg_loss': 0.6780566533406576, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 09:53:49 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #101) -------------
2025-10-10 09:53:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=101 aidx=2 | s=5 (candidates=9)
2025-10-10 09:53:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 3, 32, 36, 41] (from 9)
2025-10-10 09:53:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:53:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:53:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 09:53:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:53:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:53:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:53:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:53:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:53:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:54:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:54:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.596283, avg_loss=0.672076, seen=480, correct=281, accuracy=0.585417
2025-10-10 09:54:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:54:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:54:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:54:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2102MB allocated=2006MB
2025-10-10 09:54:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88721895217896, 'train_avg_loss': 0.682393491268158, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 09:54:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.5962829589844, 'train_avg_loss': 0.6720755894978842, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 09:54:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 322.5962829589844, 'train_avg_loss': 0.6720755894978842, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 09:54:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:54:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:54:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 09:54:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 09:54:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:54:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:54:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:54:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:54:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:55:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:55:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.469757, avg_loss=0.673895, seen=480, correct=276, accuracy=0.575000
2025-10-10 09:55:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:55:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:55:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:55:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2120MB allocated=2006MB
2025-10-10 09:55:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.81043481826782, 'train_avg_loss': 0.6734202901522318, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:55:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4697570800781, 'train_avg_loss': 0.6738953272501628, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:55:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 323.4697570800781, 'train_avg_loss': 0.6738953272501628, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:55:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 09:55:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:55:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:55:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:55:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.931030, avg_loss=0.666523, seen=480, correct=284, accuracy=0.591667
2025-10-10 09:55:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:55:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:55:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:55:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2064MB allocated=2006MB
2025-10-10 09:55:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.49744254350662, 'train_avg_loss': 0.6624786878625551, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 09:55:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.9310302734375, 'train_avg_loss': 0.6665229797363281, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 09:55:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 319.9310302734375, 'train_avg_loss': 0.6665229797363281, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 09:55:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:55:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:55:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:56:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:56:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.840027, avg_loss=0.672583, seen=480, correct=276, accuracy=0.575000
2025-10-10 09:56:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:56:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:56:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:56:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2080MB allocated=2006MB
2025-10-10 09:56:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.88424003124237, 'train_avg_loss': 0.6657020002603531, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:56:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.84002685546875, 'train_avg_loss': 0.6725833892822266, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:56:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 322.84002685546875, 'train_avg_loss': 0.6725833892822266, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 09:56:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 09:56:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:56:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:57:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:57:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.748291, avg_loss=0.682809, seen=480, correct=265, accuracy=0.552083
2025-10-10 09:57:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:57:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:57:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:57:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2064MB allocated=2006MB
2025-10-10 09:57:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.21137350797653, 'train_avg_loss': 0.6767614458998045, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 09:57:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.748291015625, 'train_avg_loss': 0.6828089396158854, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:57:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 327.748291015625, 'train_avg_loss': 0.6828089396158854, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 09:57:10 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #102) -------------
2025-10-10 09:57:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=102 aidx=2 | s=5 (candidates=9)
2025-10-10 09:57:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 21, 5, 36, 50] (from 9)
2025-10-10 09:57:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 09:57:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:57:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:57:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:57:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.601501, avg_loss=0.682503, seen=480, correct=270, accuracy=0.562500
2025-10-10 09:57:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:57:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:57:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:57:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2064MB allocated=2006MB
2025-10-10 09:57:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.67873674631119, 'train_avg_loss': 0.7139894728859265, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 09:57:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.60150146484375, 'train_avg_loss': 0.6825031280517578, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 09:57:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 327.60150146484375, 'train_avg_loss': 0.6825031280517578, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 09:57:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 09:57:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:57:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:58:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:58:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.535767, avg_loss=0.671950, seen=480, correct=274, accuracy=0.570833
2025-10-10 09:58:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:58:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:58:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:58:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2102MB allocated=2006MB
2025-10-10 09:58:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.53773909807205, 'train_avg_loss': 0.6794811591506005, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 09:58:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.5357666015625, 'train_avg_loss': 0.6719495137532552, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:58:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 322.5357666015625, 'train_avg_loss': 0.6719495137532552, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 09:58:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:58:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:58:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 09:58:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 09:58:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:58:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:58:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:58:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:58:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:59:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:59:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.751160, avg_loss=0.697398, seen=480, correct=261, accuracy=0.543750
2025-10-10 09:59:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:59:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:59:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:59:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2116MB allocated=2006MB
2025-10-10 09:59:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.48692411184311, 'train_avg_loss': 0.6873910342653592, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:59:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.75115966796875, 'train_avg_loss': 0.6973982493082682, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 09:59:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 334.75115966796875, 'train_avg_loss': 0.6973982493082682, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 09:59:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 09:59:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:59:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:59:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:59:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.239746, avg_loss=0.675499, seen=480, correct=275, accuracy=0.572917
2025-10-10 09:59:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:59:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:59:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:59:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2080MB allocated=2006MB
2025-10-10 09:59:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.05660259723663, 'train_avg_loss': 0.6671383549769719, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:59:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.23974609375, 'train_avg_loss': 0.6754994710286458, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 09:59:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 324.23974609375, 'train_avg_loss': 0.6754994710286458, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 09:59:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 09:59:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:59:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:00:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:00:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.985016, avg_loss=0.685385, seen=480, correct=251, accuracy=0.522917
2025-10-10 10:00:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:00:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:00:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:00:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2064MB allocated=2006MB
2025-10-10 10:00:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.57928019762039, 'train_avg_loss': 0.6964940016468366, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 10:00:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.9850158691406, 'train_avg_loss': 0.6853854497273763, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 10:00:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 328.9850158691406, 'train_avg_loss': 0.6853854497273763, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 10:00:31 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #103) -------------
2025-10-10 10:00:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=103 aidx=2 | s=5 (candidates=9)
2025-10-10 10:00:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 50, 3, 41, 21] (from 9)
2025-10-10 10:00:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:00:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:00:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 10:00:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:00:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:00:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:00:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:00:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:00:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:01:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:01:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.146790, avg_loss=0.664889, seen=480, correct=293, accuracy=0.610417
2025-10-10 10:01:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:01:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:01:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:01:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2064MB allocated=2006MB
2025-10-10 10:01:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.17506468296051, 'train_avg_loss': 0.6597922056913376, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 10:01:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.14678955078125, 'train_avg_loss': 0.664889144897461, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:01:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 319.14678955078125, 'train_avg_loss': 0.664889144897461, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:01:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:01:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:01:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 10:01:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:01:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:01:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:01:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:01:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:01:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:01:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:01:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.164032, avg_loss=0.681592, seen=480, correct=266, accuracy=0.554167
2025-10-10 10:01:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:01:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:01:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:01:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2064MB allocated=2006MB
2025-10-10 10:01:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.41431772708893, 'train_avg_loss': 0.7034526477257411, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:01:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1640319824219, 'train_avg_loss': 0.6815917332967122, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 10:01:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 327.1640319824219, 'train_avg_loss': 0.6815917332967122, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 10:01:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 10:01:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:01:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:02:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:02:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.798126, avg_loss=0.672496, seen=480, correct=278, accuracy=0.579167
2025-10-10 10:02:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:02:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:02:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:02:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2120MB allocated=2006MB
2025-10-10 10:02:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.00446331501007, 'train_avg_loss': 0.6750371942917506, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 10:02:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.7981262207031, 'train_avg_loss': 0.6724960962931316, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:02:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 322.7981262207031, 'train_avg_loss': 0.6724960962931316, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:02:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:02:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:02:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 10:02:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:02:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:02:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:02:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:02:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:02:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:03:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:03:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.064270, avg_loss=0.675134, seen=480, correct=273, accuracy=0.568750
2025-10-10 10:03:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:03:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:03:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:03:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2064MB allocated=2006MB
2025-10-10 10:03:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.2098223567009, 'train_avg_loss': 0.6684151863058408, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 10:03:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.06427001953125, 'train_avg_loss': 0.6751338958740234, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 10:03:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 324.06427001953125, 'train_avg_loss': 0.6751338958740234, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 10:03:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:03:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:03:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:03:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:03:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.691742, avg_loss=0.672274, seen=480, correct=275, accuracy=0.572917
2025-10-10 10:03:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:03:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:03:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:03:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2102MB allocated=2006MB
2025-10-10 10:03:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.56602901220322, 'train_avg_loss': 0.6797169084350269, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 10:03:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6917419433594, 'train_avg_loss': 0.6722744623819987, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 10:03:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 322.6917419433594, 'train_avg_loss': 0.6722744623819987, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 10:03:49 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #104) -------------
2025-10-10 10:03:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=104 aidx=2 | s=5 (candidates=9)
2025-10-10 10:03:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 21, 3, 37, 5] (from 9)
2025-10-10 10:03:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:03:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:03:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:04:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:04:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.969482, avg_loss=0.662436, seen=480, correct=296, accuracy=0.616667
2025-10-10 10:04:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:04:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:04:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:04:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2064MB allocated=2006MB
2025-10-10 10:04:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.83857554197311, 'train_avg_loss': 0.6569881295164426, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 10:04:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.969482421875, 'train_avg_loss': 0.6624364217122396, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:04:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 317.969482421875, 'train_avg_loss': 0.6624364217122396, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:04:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:04:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:04:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:05:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:05:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.975159, avg_loss=0.664532, seen=480, correct=293, accuracy=0.610417
2025-10-10 10:05:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:05:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:05:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:05:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2102MB allocated=2006MB
2025-10-10 10:05:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.68720757961273, 'train_avg_loss': 0.6723933964967728, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:05:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.97515869140625, 'train_avg_loss': 0.6645315806070964, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:05:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 318.97515869140625, 'train_avg_loss': 0.6645315806070964, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:05:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 10:05:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:05:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:05:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:05:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.915039, avg_loss=0.672740, seen=480, correct=273, accuracy=0.568750
2025-10-10 10:05:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:05:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:05:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:05:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2118MB allocated=2006MB
2025-10-10 10:05:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7550756931305, 'train_avg_loss': 0.6729589641094208, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 10:05:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.9150390625, 'train_avg_loss': 0.6727396647135416, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 10:05:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 322.9150390625, 'train_avg_loss': 0.6727396647135416, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 10:05:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 10:05:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:05:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:06:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:06:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.496246, avg_loss=0.684367, seen=480, correct=270, accuracy=0.562500
2025-10-10 10:06:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:06:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:06:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:06:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2064MB allocated=2006MB
2025-10-10 10:06:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.40517199039459, 'train_avg_loss': 0.720043099919955, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:06:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4962463378906, 'train_avg_loss': 0.6843671798706055, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 10:06:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 328.4962463378906, 'train_avg_loss': 0.6843671798706055, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 10:06:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 10:06:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:06:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:07:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:07:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.092590, avg_loss=0.698110, seen=480, correct=261, accuracy=0.543750
2025-10-10 10:07:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:07:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:07:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:07:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2116MB allocated=2006MB
2025-10-10 10:07:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90156489610672, 'train_avg_loss': 0.6825130408008894, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 10:07:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.09259033203125, 'train_avg_loss': 0.6981095631917318, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 10:07:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 335.09259033203125, 'train_avg_loss': 0.6981095631917318, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 10:07:06 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #105) -------------
2025-10-10 10:07:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=105 aidx=2 | s=5 (candidates=9)
2025-10-10 10:07:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 32, 3, 36, 21] (from 9)
2025-10-10 10:07:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 10:07:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:07:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:07:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:07:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.566956, avg_loss=0.682431, seen=480, correct=276, accuracy=0.575000
2025-10-10 10:07:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:07:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:07:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:07:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2064MB allocated=2006MB
2025-10-10 10:07:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.76786583662033, 'train_avg_loss': 0.7230655486385028, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 10:07:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.56695556640625, 'train_avg_loss': 0.682431157430013, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 10:07:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 327.56695556640625, 'train_avg_loss': 0.682431157430013, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 10:07:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:07:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:07:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 10:07:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:07:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:07:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:07:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:07:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:07:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:08:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:08:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.573059, avg_loss=0.663694, seen=480, correct=305, accuracy=0.635417
2025-10-10 10:08:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:08:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:08:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:08:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2064MB allocated=2006MB
2025-10-10 10:08:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.48815149068832, 'train_avg_loss': 0.6624012624224027, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 10:08:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.57305908203125, 'train_avg_loss': 0.6636938730875651, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 10:08:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 318.57305908203125, 'train_avg_loss': 0.6636938730875651, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 10:08:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 10:08:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:08:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:09:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:09:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.612366, avg_loss=0.672109, seen=480, correct=281, accuracy=0.585417
2025-10-10 10:09:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:09:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:09:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:09:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2118MB allocated=2006MB
2025-10-10 10:09:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.08245760202408, 'train_avg_loss': 0.675687146683534, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:09:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.61236572265625, 'train_avg_loss': 0.6721090952555339, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 10:09:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 322.61236572265625, 'train_avg_loss': 0.6721090952555339, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 10:09:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 10:09:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:09:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:09:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:09:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.347443, avg_loss=0.669474, seen=480, correct=289, accuracy=0.602083
2025-10-10 10:09:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:09:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:09:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:09:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2080MB allocated=2006MB
2025-10-10 10:09:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.82622516155243, 'train_avg_loss': 0.6652185430129369, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 10:09:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3474426269531, 'train_avg_loss': 0.6694738388061523, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 10:09:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 321.3474426269531, 'train_avg_loss': 0.6694738388061523, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 10:09:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:09:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:09:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 10:09:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:09:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:09:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:09:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:09:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:09:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:10:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:10:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.586670, avg_loss=0.665806, seen=480, correct=285, accuracy=0.593750
2025-10-10 10:10:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:10:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:10:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:10:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2102MB allocated=2006MB
2025-10-10 10:10:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.97062075138092, 'train_avg_loss': 0.6747551729281743, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 10:10:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.586669921875, 'train_avg_loss': 0.6658055623372395, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 10:10:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 319.586669921875, 'train_avg_loss': 0.6658055623372395, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 10:10:27 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #106) -------------
2025-10-10 10:10:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=106 aidx=2 | s=5 (candidates=9)
2025-10-10 10:10:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 37, 50, 31, 21] (from 9)
2025-10-10 10:10:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:10:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:10:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:11:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:11:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.563324, avg_loss=0.663674, seen=480, correct=293, accuracy=0.610417
2025-10-10 10:11:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:11:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:11:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:11:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2064MB allocated=2006MB
2025-10-10 10:11:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.93164157867432, 'train_avg_loss': 0.657763679822286, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:11:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.5633239746094, 'train_avg_loss': 0.6636735916137695, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:11:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 318.5633239746094, 'train_avg_loss': 0.6636735916137695, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:11:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 10:11:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:11:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:11:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:11:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.104614, avg_loss=0.683551, seen=480, correct=271, accuracy=0.564583
2025-10-10 10:11:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:11:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:11:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:11:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2064MB allocated=2006MB
2025-10-10 10:11:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.42504286766052, 'train_avg_loss': 0.7202086905638377, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 10:11:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1046142578125, 'train_avg_loss': 0.683551279703776, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 10:11:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 328.1046142578125, 'train_avg_loss': 0.683551279703776, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 10:11:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:11:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:11:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:12:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:12:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.841064, avg_loss=0.680919, seen=480, correct=264, accuracy=0.550000
2025-10-10 10:12:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:12:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:12:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:12:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2064MB allocated=2006MB
2025-10-10 10:12:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.65960121154785, 'train_avg_loss': 0.7054966767628987, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 10:12:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.841064453125, 'train_avg_loss': 0.6809188842773437, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 10:12:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 326.841064453125, 'train_avg_loss': 0.6809188842773437, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 10:12:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:12:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:12:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 10:12:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:12:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:12:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:12:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:12:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:12:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:13:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:13:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.795898, avg_loss=0.697491, seen=480, correct=259, accuracy=0.539583
2025-10-10 10:13:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:13:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:13:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:13:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2076MB allocated=2006MB
2025-10-10 10:13:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.40862780809402, 'train_avg_loss': 0.7034052317341168, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 10:13:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.7958984375, 'train_avg_loss': 0.697491455078125, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:13:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 334.7958984375, 'train_avg_loss': 0.697491455078125, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:13:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:13:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:13:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:13:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:13:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.235535, avg_loss=0.658824, seen=480, correct=296, accuracy=0.616667
2025-10-10 10:13:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:13:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:13:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:13:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2102MB allocated=2006MB
2025-10-10 10:13:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.9804772734642, 'train_avg_loss': 0.6665039772788683, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 10:13:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.23553466796875, 'train_avg_loss': 0.6588240305582682, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:13:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 316.23553466796875, 'train_avg_loss': 0.6588240305582682, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:13:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #107) -------------
2025-10-10 10:13:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=107 aidx=2 | s=5 (candidates=9)
2025-10-10 10:13:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 36, 32, 41, 3] (from 9)
2025-10-10 10:13:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 10:13:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:13:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:14:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:14:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.348480, avg_loss=0.681976, seen=480, correct=279, accuracy=0.581250
2025-10-10 10:14:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:14:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:14:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:14:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2064MB allocated=2006MB
2025-10-10 10:14:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.17427629232407, 'train_avg_loss': 0.7181189691027006, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 10:14:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3484802246094, 'train_avg_loss': 0.6819760004679362, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 10:14:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 327.3484802246094, 'train_avg_loss': 0.6819760004679362, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 10:14:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:14:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:14:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 10:14:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 10:14:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:14:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:14:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:14:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:14:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:15:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:15:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.036407, avg_loss=0.666743, seen=480, correct=296, accuracy=0.616667
2025-10-10 10:15:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:15:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:15:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:15:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2080MB allocated=2006MB
2025-10-10 10:15:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.8955609202385, 'train_avg_loss': 0.6574630076686542, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 10:15:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.0364074707031, 'train_avg_loss': 0.6667425155639648, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:15:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 320.0364074707031, 'train_avg_loss': 0.6667425155639648, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 10:15:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:15:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:15:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:15:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:15:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.147705, avg_loss=0.662808, seen=480, correct=290, accuracy=0.604167
2025-10-10 10:15:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:15:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:15:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:15:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2064MB allocated=2006MB
2025-10-10 10:15:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.89645713567734, 'train_avg_loss': 0.6574704761306445, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 10:15:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.147705078125, 'train_avg_loss': 0.6628077189127605, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 10:15:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 318.147705078125, 'train_avg_loss': 0.6628077189127605, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 10:15:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:15:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:15:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:16:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:16:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.252075, avg_loss=0.673442, seen=480, correct=287, accuracy=0.597917
2025-10-10 10:16:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:16:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:16:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:16:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2064MB allocated=2006MB
2025-10-10 10:16:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.03377687931061, 'train_avg_loss': 0.6669481406609218, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 10:16:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.2520751953125, 'train_avg_loss': 0.6734418233235677, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 10:16:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 323.2520751953125, 'train_avg_loss': 0.6734418233235677, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 10:16:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 10:16:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:16:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:16:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:16:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.361603, avg_loss=0.669503, seen=480, correct=278, accuracy=0.579167
2025-10-10 10:16:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:16:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:17:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:17:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2120MB allocated=2006MB
2025-10-10 10:17:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.94369900226593, 'train_avg_loss': 0.6745308250188827, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 10:17:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3616027832031, 'train_avg_loss': 0.6695033391316731, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:17:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 321.3616027832031, 'train_avg_loss': 0.6695033391316731, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:17:02 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #108) -------------
2025-10-10 10:17:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=108 aidx=2 | s=5 (candidates=9)
2025-10-10 10:17:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 50, 21, 41, 31] (from 9)
2025-10-10 10:17:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:17:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:17:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 10:17:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 10:17:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:17:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:17:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:17:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:17:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:17:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:17:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.919434, avg_loss=0.662332, seen=480, correct=293, accuracy=0.610417
2025-10-10 10:17:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:17:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:17:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:17:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2120MB allocated=2006MB
2025-10-10 10:17:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.02703338861465, 'train_avg_loss': 0.6668919449051222, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 10:17:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.91943359375, 'train_avg_loss': 0.6623321533203125, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:17:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 317.91943359375, 'train_avg_loss': 0.6623321533203125, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:17:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:17:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:17:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:18:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:18:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.605713, avg_loss=0.682512, seen=480, correct=265, accuracy=0.552083
2025-10-10 10:18:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:18:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:18:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:18:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2064MB allocated=2006MB
2025-10-10 10:18:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.93972104787827, 'train_avg_loss': 0.7078310087323189, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 10:18:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.605712890625, 'train_avg_loss': 0.6825119018554687, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 10:18:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 327.605712890625, 'train_avg_loss': 0.6825119018554687, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 10:18:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:18:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:18:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 10:18:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:18:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:18:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:18:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:18:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:18:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:18:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:18:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.552216, avg_loss=0.649067, seen=480, correct=306, accuracy=0.637500
2025-10-10 10:18:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:18:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:18:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:18:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2102MB allocated=2006MB
2025-10-10 10:18:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.43396157026291, 'train_avg_loss': 0.6619496797521909, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:18:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.5522155761719, 'train_avg_loss': 0.6490671157836914, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 10:18:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 311.5522155761719, 'train_avg_loss': 0.6490671157836914, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 10:18:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:19:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:19:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 10:19:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:19:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:19:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:19:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:19:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:19:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:19:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:19:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.800476, avg_loss=0.674584, seen=480, correct=291, accuracy=0.606250
2025-10-10 10:19:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:19:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:19:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:19:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2064MB allocated=2006MB
2025-10-10 10:19:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.03396236896515, 'train_avg_loss': 0.6669496864080429, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 10:19:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.80047607421875, 'train_avg_loss': 0.6745843251546224, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 10:19:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 323.80047607421875, 'train_avg_loss': 0.6745843251546224, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 10:19:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:19:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:19:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:20:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:20:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.749084, avg_loss=0.697394, seen=480, correct=263, accuracy=0.547917
2025-10-10 10:20:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:20:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:20:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:20:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2076MB allocated=2006MB
2025-10-10 10:20:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26602697372437, 'train_avg_loss': 0.702216891447703, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 10:20:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.74908447265625, 'train_avg_loss': 0.6973939259847005, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 10:20:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 334.74908447265625, 'train_avg_loss': 0.6973939259847005, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 10:20:20 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #109) -------------
2025-10-10 10:20:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=109 aidx=2 | s=5 (candidates=9)
2025-10-10 10:20:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[31, 50, 32, 36, 41] (from 9)
2025-10-10 10:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:20:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:20:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:20:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:20:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.511444, avg_loss=0.684399, seen=480, correct=262, accuracy=0.545833
2025-10-10 10:20:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:20:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:21:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:21:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2076MB allocated=2006MB
2025-10-10 10:21:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.73448699712753, 'train_avg_loss': 0.6894540583093961, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 10:21:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.5114440917969, 'train_avg_loss': 0.6843988418579101, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 10:21:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 328.5114440917969, 'train_avg_loss': 0.6843988418579101, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 10:21:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:21:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:21:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 10:21:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:21:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:21:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:21:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:21:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:21:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:21:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:21:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.829193, avg_loss=0.682977, seen=480, correct=264, accuracy=0.550000
2025-10-10 10:21:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:21:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:21:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:21:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2064MB allocated=2006MB
2025-10-10 10:21:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.67688149213791, 'train_avg_loss': 0.697307345767816, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 10:21:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8291931152344, 'train_avg_loss': 0.6829774856567383, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 10:21:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 327.8291931152344, 'train_avg_loss': 0.6829774856567383, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 10:21:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:21:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:21:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:22:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:22:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.093262, avg_loss=0.656444, seen=480, correct=299, accuracy=0.622917
2025-10-10 10:22:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:22:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:22:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:22:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2064MB allocated=2006MB
2025-10-10 10:22:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.856938123703, 'train_avg_loss': 0.648807817697525, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:22:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.09326171875, 'train_avg_loss': 0.6564442952473958, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 10:22:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 315.09326171875, 'train_avg_loss': 0.6564442952473958, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 10:22:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:22:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:22:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 10:22:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 10:22:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:22:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:22:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:22:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:22:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:22:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:22:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.429230, avg_loss=0.665478, seen=480, correct=280, accuracy=0.583333
2025-10-10 10:22:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:22:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:23:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:23:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2080MB allocated=2006MB
2025-10-10 10:23:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.80269873142242, 'train_avg_loss': 0.6566891560951869, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:23:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.4292297363281, 'train_avg_loss': 0.6654775619506836, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 10:23:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 319.4292297363281, 'train_avg_loss': 0.6654775619506836, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 10:23:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:23:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:23:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 10:23:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:23:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:23:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:23:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:23:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:23:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:23:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:23:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.327942, avg_loss=0.673600, seen=480, correct=284, accuracy=0.591667
2025-10-10 10:23:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:23:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:23:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:23:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2064MB allocated=2006MB
2025-10-10 10:23:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.08474558591843, 'train_avg_loss': 0.6673728798826536, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:23:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.32794189453125, 'train_avg_loss': 0.6735998789469401, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 10:23:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 323.32794189453125, 'train_avg_loss': 0.6735998789469401, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 10:23:45 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #110) -------------
2025-10-10 10:23:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=110 aidx=2 | s=5 (candidates=9)
2025-10-10 10:23:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5, 50, 32, 31, 21] (from 9)
2025-10-10 10:23:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:23:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:23:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 10:23:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 10:23:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:23:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:23:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:23:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:23:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:24:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:24:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.043030, avg_loss=0.681340, seen=480, correct=284, accuracy=0.591667
2025-10-10 10:24:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:24:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:24:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:24:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2116MB allocated=2006MB
2025-10-10 10:24:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.4136580824852, 'train_avg_loss': 0.66178048402071, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:24:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.04302978515625, 'train_avg_loss': 0.6813396453857422, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 10:24:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 327.04302978515625, 'train_avg_loss': 0.6813396453857422, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 10:24:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:24:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:24:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:25:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:25:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.351440, avg_loss=0.681982, seen=480, correct=268, accuracy=0.558333
2025-10-10 10:25:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:25:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:25:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:25:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2064MB allocated=2006MB
2025-10-10 10:25:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00361549854279, 'train_avg_loss': 0.7000301291545232, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 10:25:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3514404296875, 'train_avg_loss': 0.6819821675618489, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:25:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 327.3514404296875, 'train_avg_loss': 0.6819821675618489, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:25:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:25:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:25:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 10:25:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:25:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:25:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:25:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:25:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:25:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:25:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:25:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.827881, avg_loss=0.653808, seen=480, correct=302, accuracy=0.629167
2025-10-10 10:25:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:25:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:25:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:25:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2064MB allocated=2006MB
2025-10-10 10:25:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.98869091272354, 'train_avg_loss': 0.6499057576060295, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 10:25:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.827880859375, 'train_avg_loss': 0.6538080851236979, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 10:25:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 313.827880859375, 'train_avg_loss': 0.6538080851236979, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 10:25:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:25:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:25:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:26:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:26:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.463379, avg_loss=0.686382, seen=480, correct=269, accuracy=0.560417
2025-10-10 10:26:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:26:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:26:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:26:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2076MB allocated=2006MB
2025-10-10 10:26:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.92353105545044, 'train_avg_loss': 0.691029425462087, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 10:26:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.46337890625, 'train_avg_loss': 0.6863820393880208, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 10:26:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 329.46337890625, 'train_avg_loss': 0.6863820393880208, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 10:26:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:26:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:26:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 10:26:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:26:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:26:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:26:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:26:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:26:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:27:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:27:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.108093, avg_loss=0.650225, seen=480, correct=297, accuracy=0.618750
2025-10-10 10:27:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:27:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:27:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:27:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2102MB allocated=2006MB
2025-10-10 10:27:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.82625180482864, 'train_avg_loss': 0.6568854317069054, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 10:27:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.10809326171875, 'train_avg_loss': 0.6502251942952474, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 10:27:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 312.10809326171875, 'train_avg_loss': 0.6502251942952474, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 10:27:05 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #111) -------------
2025-10-10 10:27:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=111 aidx=2 | s=5 (candidates=9)
2025-10-10 10:27:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 36, 5, 50, 31] (from 9)
2025-10-10 10:27:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:27:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:27:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 10:27:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:27:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:27:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:27:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:27:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:27:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:27:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:27:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.230438, avg_loss=0.642147, seen=480, correct=313, accuracy=0.652083
2025-10-10 10:27:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:27:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:27:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:27:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2102MB allocated=2006MB
2025-10-10 10:27:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.34464800357819, 'train_avg_loss': 0.6528720666964849, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 10:27:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.2304382324219, 'train_avg_loss': 0.6421467463175455, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 10:27:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 308.2304382324219, 'train_avg_loss': 0.6421467463175455, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 10:27:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 10:27:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:27:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:28:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:28:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.548615, avg_loss=0.661560, seen=480, correct=287, accuracy=0.597917
2025-10-10 10:28:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:28:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:28:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:28:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2080MB allocated=2006MB
2025-10-10 10:28:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.65801918506622, 'train_avg_loss': 0.6554834932088852, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:28:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.5486145019531, 'train_avg_loss': 0.6615596135457357, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 10:28:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 317.5486145019531, 'train_avg_loss': 0.6615596135457357, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 10:28:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:28:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:28:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 10:28:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 10:28:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:28:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:28:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:28:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:28:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:29:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:29:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.210114, avg_loss=0.681688, seen=480, correct=278, accuracy=0.579167
2025-10-10 10:29:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:29:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:29:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:29:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2116MB allocated=2006MB
2025-10-10 10:29:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.73961973190308, 'train_avg_loss': 0.6561634977658589, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 10:29:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.2101135253906, 'train_avg_loss': 0.6816877365112305, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:29:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 327.2101135253906, 'train_avg_loss': 0.6816877365112305, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 10:29:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:29:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:29:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 10:29:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:29:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:29:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:29:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:29:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:29:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:29:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:29:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.013855, avg_loss=0.683362, seen=480, correct=268, accuracy=0.558333
2025-10-10 10:29:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:29:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:29:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:29:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2064MB allocated=2006MB
2025-10-10 10:29:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.5449492931366, 'train_avg_loss': 0.712874577442805, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:29:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.01385498046875, 'train_avg_loss': 0.6833621978759765, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:29:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 328.01385498046875, 'train_avg_loss': 0.6833621978759765, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:29:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:29:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:29:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:30:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:30:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.341888, avg_loss=0.692379, seen=480, correct=259, accuracy=0.539583
2025-10-10 10:30:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:30:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:30:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:30:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2076MB allocated=2006MB
2025-10-10 10:30:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.74974954128265, 'train_avg_loss': 0.6979145795106888, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 10:30:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.3418884277344, 'train_avg_loss': 0.6923789342244466, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:30:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 332.3418884277344, 'train_avg_loss': 0.6923789342244466, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:30:26 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #112) -------------
2025-10-10 10:30:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=112 aidx=2 | s=5 (candidates=9)
2025-10-10 10:30:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 41, 50, 37, 31] (from 9)
2025-10-10 10:30:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 10:30:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:30:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:31:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:31:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.945251, avg_loss=0.643636, seen=480, correct=309, accuracy=0.643750
2025-10-10 10:31:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:31:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:31:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:31:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2102MB allocated=2006MB
2025-10-10 10:31:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.93994230031967, 'train_avg_loss': 0.6494995191693306, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 10:31:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.94525146484375, 'train_avg_loss': 0.6436359405517578, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 10:31:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 308.94525146484375, 'train_avg_loss': 0.6436359405517578, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 10:31:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:31:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:31:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:31:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:31:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.393158, avg_loss=0.663319, seen=480, correct=293, accuracy=0.610417
2025-10-10 10:31:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:31:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:31:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:31:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2064MB allocated=2006MB
2025-10-10 10:31:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.49463254213333, 'train_avg_loss': 0.6541219378511111, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 10:31:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3931579589844, 'train_avg_loss': 0.6633190790812175, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:31:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 318.3931579589844, 'train_avg_loss': 0.6633190790812175, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 10:31:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:31:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:31:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 10:31:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:31:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:31:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:31:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:31:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:31:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:32:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:32:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.429108, avg_loss=0.682144, seen=480, correct=271, accuracy=0.564583
2025-10-10 10:32:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:32:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:32:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:32:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2064MB allocated=2006MB
2025-10-10 10:32:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00089126825333, 'train_avg_loss': 0.7000074272354444, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 10:32:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.4291076660156, 'train_avg_loss': 0.6821439743041993, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 10:32:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 327.4291076660156, 'train_avg_loss': 0.6821439743041993, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 10:32:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 10:32:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:32:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:33:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:33:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.878448, avg_loss=0.683080, seen=480, correct=272, accuracy=0.566667
2025-10-10 10:33:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:33:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:33:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:33:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2064MB allocated=2006MB
2025-10-10 10:33:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.84873193502426, 'train_avg_loss': 0.7154060994585355, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 10:33:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8784484863281, 'train_avg_loss': 0.6830801010131836, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 10:33:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 327.8784484863281, 'train_avg_loss': 0.6830801010131836, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 10:33:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 10:33:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:33:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:33:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:33:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.133392, avg_loss=0.679445, seen=480, correct=268, accuracy=0.558333
2025-10-10 10:33:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:33:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:33:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:33:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2076MB allocated=2006MB
2025-10-10 10:33:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09135043621063, 'train_avg_loss': 0.684094586968422, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 10:33:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1333923339844, 'train_avg_loss': 0.6794445673624675, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:33:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 326.1333923339844, 'train_avg_loss': 0.6794445673624675, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 10:33:44 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #113) -------------
2025-10-10 10:33:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=113 aidx=2 | s=5 (candidates=9)
2025-10-10 10:33:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 41, 5, 32, 50] (from 9)
2025-10-10 10:33:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 10:33:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:33:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:34:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:34:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.282928, avg_loss=0.663089, seen=480, correct=286, accuracy=0.595833
2025-10-10 10:34:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:34:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:34:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:34:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2080MB allocated=2006MB
2025-10-10 10:34:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.03531229496002, 'train_avg_loss': 0.6502942691246668, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:34:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.2829284667969, 'train_avg_loss': 0.6630894343058268, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 10:34:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 318.2829284667969, 'train_avg_loss': 0.6630894343058268, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 10:34:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 10:34:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:34:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:34:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:34:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.010712, avg_loss=0.664606, seen=480, correct=295, accuracy=0.614583
2025-10-10 10:34:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:34:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:35:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:35:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2064MB allocated=2006MB
2025-10-10 10:35:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.73969441652298, 'train_avg_loss': 0.6561641201376915, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 10:35:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0107116699219, 'train_avg_loss': 0.6646056493123372, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 10:35:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 319.0107116699219, 'train_avg_loss': 0.6646056493123372, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 10:35:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 10:35:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:35:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:35:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:35:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.882385, avg_loss=0.683088, seen=480, correct=276, accuracy=0.575000
2025-10-10 10:35:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:35:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:35:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:35:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2116MB allocated=2006MB
2025-10-10 10:35:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.81405299901962, 'train_avg_loss': 0.6651171083251636, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:35:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.88238525390625, 'train_avg_loss': 0.6830883026123047, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 10:35:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 327.88238525390625, 'train_avg_loss': 0.6830883026123047, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 10:35:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 10:35:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:35:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:36:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:36:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.012360, avg_loss=0.650026, seen=480, correct=300, accuracy=0.625000
2025-10-10 10:36:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:36:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:36:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:36:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2064MB allocated=2006MB
2025-10-10 10:36:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.56445091962814, 'train_avg_loss': 0.6380370909969012, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 10:36:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.0123596191406, 'train_avg_loss': 0.650025749206543, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 10:36:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 312.0123596191406, 'train_avg_loss': 0.650025749206543, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 10:36:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 10:36:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:36:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:36:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:36:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.960358, avg_loss=0.683251, seen=480, correct=270, accuracy=0.562500
2025-10-10 10:36:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:36:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:36:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:37:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2064MB allocated=2006MB
2025-10-10 10:37:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76018935441971, 'train_avg_loss': 0.6980015779534976, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 10:37:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9603576660156, 'train_avg_loss': 0.6832507451375326, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 10:37:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 327.9603576660156, 'train_avg_loss': 0.6832507451375326, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 10:37:00 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #114) -------------
2025-10-10 10:37:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=114 aidx=3 | s=5 (candidates=8)
2025-10-10 10:37:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 42, 25, 24, 4] (from 8)
2025-10-10 10:37:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 10:37:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:37:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:37:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:37:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.332733, avg_loss=0.715277, seen=480, correct=252, accuracy=0.525000
2025-10-10 10:37:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:37:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:37:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:37:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2102MB allocated=2056MB
2025-10-10 10:37:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.74285417795181, 'train_avg_loss': 0.7228571181495984, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 10:37:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.3327331542969, 'train_avg_loss': 0.7152765274047852, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 10:37:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 343.3327331542969, 'train_avg_loss': 0.7152765274047852, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 10:37:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:37:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:37:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 10:37:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 10:37:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:37:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:37:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:37:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:37:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:38:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:38:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.939636, avg_loss=0.708208, seen=480, correct=238, accuracy=0.495833
2025-10-10 10:38:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:38:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:38:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:38:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2122MB allocated=2065MB
2025-10-10 10:38:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.20163929462433, 'train_avg_loss': 0.7100136607885361, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 10:38:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.93963623046875, 'train_avg_loss': 0.7082075754801432, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 10:38:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 339.93963623046875, 'train_avg_loss': 0.7082075754801432, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 10:38:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 10:38:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:38:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:38:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:38:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.206970, avg_loss=0.727515, seen=480, correct=233, accuracy=0.485417
2025-10-10 10:38:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:38:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:38:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:39:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2316MB allocated=2073MB
2025-10-10 10:39:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.0339567065239, 'train_avg_loss': 0.7169496392210325, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 10:39:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.20697021484375, 'train_avg_loss': 0.7275145212809245, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 10:39:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 349.20697021484375, 'train_avg_loss': 0.7275145212809245, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 10:39:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 10:39:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:39:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:39:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:39:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:39:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=354.142731, avg_loss=0.737797, seen=480, correct=230, accuracy=0.479167
2025-10-10 10:39:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:39:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:39:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:39:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2316MB allocated=2082MB
2025-10-10 10:39:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.03778076171875, 'train_avg_loss': 0.733648173014323, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:39:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 354.1427307128906, 'train_avg_loss': 0.7377973556518554, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 10:39:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 354.1427307128906, 'train_avg_loss': 0.7377973556518554, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 10:39:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:39:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:39:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:40:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:40:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=352.892609, avg_loss=0.735193, seen=480, correct=218, accuracy=0.454167
2025-10-10 10:40:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:40:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:40:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:40:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2366MB allocated=2090MB
2025-10-10 10:40:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99303913116455, 'train_avg_loss': 0.6832753260930379, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 10:40:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 352.8926086425781, 'train_avg_loss': 0.7351929346720377, 'train_seen': 480, 'train_correct': 218, 'train_acc': 0.45416666666666666}}
2025-10-10 10:40:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 352.8926086425781, 'train_avg_loss': 0.7351929346720377, 'train_seen': 480, 'train_correct': 218, 'train_acc': 0.45416666666666666}}
2025-10-10 10:40:19 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #115) -------------
2025-10-10 10:40:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=115 aidx=3 | s=5 (candidates=8)
2025-10-10 10:40:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 24, 4, 27, 44] (from 8)
2025-10-10 10:40:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 10:40:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:40:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:40:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:40:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.702850, avg_loss=0.705631, seen=480, correct=243, accuracy=0.506250
2025-10-10 10:40:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:40:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:40:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:40:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2350MB allocated=2090MB
2025-10-10 10:40:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.2076244354248, 'train_avg_loss': 0.70173020362854, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 10:40:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.7028503417969, 'train_avg_loss': 0.7056309382120768, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:40:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 338.7028503417969, 'train_avg_loss': 0.7056309382120768, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:40:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 10:40:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:40:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:41:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:41:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.315613, avg_loss=0.713158, seen=480, correct=223, accuracy=0.464583
2025-10-10 10:41:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:41:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:41:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:41:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2332MB allocated=2090MB
2025-10-10 10:41:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35752683877945, 'train_avg_loss': 0.7113127236564954, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 10:41:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.31561279296875, 'train_avg_loss': 0.7131575266520183, 'train_seen': 480, 'train_correct': 223, 'train_acc': 0.46458333333333335}}
2025-10-10 10:41:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 342.31561279296875, 'train_avg_loss': 0.7131575266520183, 'train_seen': 480, 'train_correct': 223, 'train_acc': 0.46458333333333335}}
2025-10-10 10:41:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:41:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:41:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 10:41:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:41:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:41:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:41:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:41:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:41:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:42:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:42:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.238159, avg_loss=0.690079, seen=480, correct=259, accuracy=0.539583
2025-10-10 10:42:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:42:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:42:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:42:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2366MB allocated=2090MB
2025-10-10 10:42:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.48340785503387, 'train_avg_loss': 0.654028398791949, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 10:42:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2381591796875, 'train_avg_loss': 0.6900794982910157, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:42:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 331.2381591796875, 'train_avg_loss': 0.6900794982910157, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 10:42:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:42:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:42:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 10:42:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 10:42:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:42:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:42:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:42:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:42:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:42:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:42:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.210052, avg_loss=0.706688, seen=480, correct=251, accuracy=0.522917
2025-10-10 10:42:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:42:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:42:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:42:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2368MB allocated=2141MB
2025-10-10 10:42:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.2045818567276, 'train_avg_loss': 0.71837151547273, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:42:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.2100524902344, 'train_avg_loss': 0.7066876093546549, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 10:42:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 339.2100524902344, 'train_avg_loss': 0.7066876093546549, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 10:42:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:42:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:42:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 10:42:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 10:42:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:42:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:42:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:42:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:42:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:43:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:43:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.540680, avg_loss=0.705293, seen=480, correct=227, accuracy=0.472917
2025-10-10 10:43:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:43:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:43:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:43:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2358MB allocated=2149MB
2025-10-10 10:43:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.63396763801575, 'train_avg_loss': 0.6886163969834646, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 10:43:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.5406799316406, 'train_avg_loss': 0.705293083190918, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 10:43:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 338.5406799316406, 'train_avg_loss': 0.705293083190918, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 10:43:32 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #116) -------------
2025-10-10 10:43:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=116 aidx=3 | s=5 (candidates=8)
2025-10-10 10:43:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 44, 25, 24, 42] (from 8)
2025-10-10 10:43:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:43:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:43:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:44:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:44:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.831482, avg_loss=0.685066, seen=480, correct=266, accuracy=0.554167
2025-10-10 10:44:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:44:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:44:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:44:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2372MB allocated=2107MB
2025-10-10 10:44:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.087033867836, 'train_avg_loss': 0.6507252822319667, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 10:44:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.83148193359375, 'train_avg_loss': 0.6850655873616537, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 10:44:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 328.83148193359375, 'train_avg_loss': 0.6850655873616537, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 10:44:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 10:44:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:44:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:44:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:44:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.347504, avg_loss=0.698641, seen=480, correct=243, accuracy=0.506250
2025-10-10 10:44:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:44:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:44:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:44:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2332MB allocated=2107MB
2025-10-10 10:44:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32162952423096, 'train_avg_loss': 0.6860135793685913, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 10:44:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.3475036621094, 'train_avg_loss': 0.6986406326293946, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:44:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 335.3475036621094, 'train_avg_loss': 0.6986406326293946, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:44:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:44:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:44:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 10:44:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 10:44:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:44:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:44:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:44:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:44:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:45:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:45:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.041840, avg_loss=0.704254, seen=480, correct=241, accuracy=0.502083
2025-10-10 10:45:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:45:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:45:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:45:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2332MB allocated=2107MB
2025-10-10 10:45:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.24541282653809, 'train_avg_loss': 0.6937117735544841, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 10:45:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.0418395996094, 'train_avg_loss': 0.7042538324991862, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 10:45:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 338.0418395996094, 'train_avg_loss': 0.7042538324991862, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 10:45:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 10:45:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:45:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:46:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:46:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.966888, avg_loss=0.708264, seen=480, correct=232, accuracy=0.483333
2025-10-10 10:46:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:46:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:46:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:46:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2332MB allocated=2107MB
2025-10-10 10:46:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.90300798416138, 'train_avg_loss': 0.7075250665346782, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:46:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.9668884277344, 'train_avg_loss': 0.7082643508911133, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 10:46:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 339.9668884277344, 'train_avg_loss': 0.7082643508911133, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 10:46:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 10:46:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:46:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:46:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:46:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.721313, avg_loss=0.703586, seen=480, correct=229, accuracy=0.477083
2025-10-10 10:46:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:46:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:46:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:46:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2340MB allocated=2107MB
2025-10-10 10:46:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.19361543655396, 'train_avg_loss': 0.7016134619712829, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 10:46:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.7213134765625, 'train_avg_loss': 0.7035860697428385, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 10:46:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 337.7213134765625, 'train_avg_loss': 0.7035860697428385, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 10:46:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #117) -------------
2025-10-10 10:46:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=117 aidx=3 | s=5 (candidates=8)
2025-10-10 10:46:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 33, 24, 4, 30] (from 8)
2025-10-10 10:46:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 10:46:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:46:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:47:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:47:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.087921, avg_loss=0.702267, seen=480, correct=252, accuracy=0.525000
2025-10-10 10:47:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:47:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:47:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:47:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2292MB allocated=2065MB
2025-10-10 10:47:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.50167226791382, 'train_avg_loss': 0.7125139355659484, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 10:47:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.0879211425781, 'train_avg_loss': 0.7022665023803711, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 10:47:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 337.0879211425781, 'train_avg_loss': 0.7022665023803711, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 10:47:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:47:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:47:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 10:47:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 10:47:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:47:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:47:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:47:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:47:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:48:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:48:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.060059, avg_loss=0.704292, seen=480, correct=237, accuracy=0.493750
2025-10-10 10:48:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:48:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:48:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:48:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2292MB allocated=2065MB
2025-10-10 10:48:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2291533946991, 'train_avg_loss': 0.7102429449558259, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 10:48:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.06005859375, 'train_avg_loss': 0.7042917887369792, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 10:48:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 338.06005859375, 'train_avg_loss': 0.7042917887369792, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 10:48:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 10:48:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:48:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:48:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:48:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.324219, avg_loss=0.706925, seen=480, correct=223, accuracy=0.464583
2025-10-10 10:48:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:48:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:48:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:48:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2288MB allocated=2065MB
2025-10-10 10:48:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.5400333404541, 'train_avg_loss': 0.7045002778371176, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 10:48:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.32421875, 'train_avg_loss': 0.7069254557291667, 'train_seen': 480, 'train_correct': 223, 'train_acc': 0.46458333333333335}}
2025-10-10 10:48:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 339.32421875, 'train_avg_loss': 0.7069254557291667, 'train_seen': 480, 'train_correct': 223, 'train_acc': 0.46458333333333335}}
2025-10-10 10:48:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:48:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:48:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:49:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:49:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.087189, avg_loss=0.683515, seen=480, correct=263, accuracy=0.547917
2025-10-10 10:49:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:49:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:49:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:49:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2326MB allocated=2065MB
2025-10-10 10:49:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.1914336681366, 'train_avg_loss': 0.6599286139011383, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 10:49:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0871887207031, 'train_avg_loss': 0.6835149765014649, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 10:49:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 328.0871887207031, 'train_avg_loss': 0.6835149765014649, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 10:49:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 10:49:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:49:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:50:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:50:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.269287, avg_loss=0.696394, seen=480, correct=240, accuracy=0.500000
2025-10-10 10:50:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:50:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:50:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:50:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2316MB allocated=2116MB
2025-10-10 10:50:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.64615440368652, 'train_avg_loss': 0.705384620030721, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 10:50:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.269287109375, 'train_avg_loss': 0.6963943481445313, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 10:50:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 334.269287109375, 'train_avg_loss': 0.6963943481445313, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 10:50:02 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #118) -------------
2025-10-10 10:50:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=118 aidx=3 | s=5 (candidates=8)
2025-10-10 10:50:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 27, 33, 25, 42] (from 8)
2025-10-10 10:50:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 10:50:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:50:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:50:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:50:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.184082, avg_loss=0.689967, seen=480, correct=243, accuracy=0.506250
2025-10-10 10:50:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:50:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:50:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:50:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2332MB allocated=2116MB
2025-10-10 10:50:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.11612844467163, 'train_avg_loss': 0.7009677370389302, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 10:50:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.18408203125, 'train_avg_loss': 0.6899668375651041, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:50:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 331.18408203125, 'train_avg_loss': 0.6899668375651041, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:50:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 10:50:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:50:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:51:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:51:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.743011, avg_loss=0.699465, seen=480, correct=247, accuracy=0.514583
2025-10-10 10:51:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:51:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:51:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:51:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2338MB allocated=2116MB
2025-10-10 10:51:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.57171559333801, 'train_avg_loss': 0.7047642966111501, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 10:51:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7430114746094, 'train_avg_loss': 0.6994646072387696, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:51:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 335.7430114746094, 'train_avg_loss': 0.6994646072387696, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:51:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 10:51:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:51:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:52:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:52:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.220459, avg_loss=0.700459, seen=480, correct=247, accuracy=0.514583
2025-10-10 10:52:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:52:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:52:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:52:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2340MB allocated=2116MB
2025-10-10 10:52:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.76764589548111, 'train_avg_loss': 0.7063970491290092, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 10:52:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.220458984375, 'train_avg_loss': 0.7004592895507813, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:52:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 336.220458984375, 'train_avg_loss': 0.7004592895507813, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:52:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 10:52:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:52:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:52:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:52:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.428436, avg_loss=0.700893, seen=480, correct=255, accuracy=0.531250
2025-10-10 10:52:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:52:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:52:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:52:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2332MB allocated=2116MB
2025-10-10 10:52:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.41477584838867, 'train_avg_loss': 0.6951231320699056, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 10:52:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4284362792969, 'train_avg_loss': 0.7008925755818685, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 10:52:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 336.4284362792969, 'train_avg_loss': 0.7008925755818685, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 10:52:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 10:52:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:52:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:53:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:53:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.113373, avg_loss=0.696070, seen=480, correct=239, accuracy=0.497917
2025-10-10 10:53:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:53:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:53:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:53:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2342MB allocated=2116MB
2025-10-10 10:53:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.06467413902283, 'train_avg_loss': 0.6922056178251902, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 10:53:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1133728027344, 'train_avg_loss': 0.6960695266723633, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 10:53:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 334.1133728027344, 'train_avg_loss': 0.6960695266723633, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 10:53:24 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #119) -------------
2025-10-10 10:53:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=119 aidx=3 | s=5 (candidates=8)
2025-10-10 10:53:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 27, 33, 25, 4] (from 8)
2025-10-10 10:53:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 10:53:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:53:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:53:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:53:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.705383, avg_loss=0.686886, seen=480, correct=267, accuracy=0.556250
2025-10-10 10:53:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:53:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:53:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:54:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2308MB allocated=2074MB
2025-10-10 10:54:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.15294146537781, 'train_avg_loss': 0.6762745122114817, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 10:54:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.70538330078125, 'train_avg_loss': 0.686886215209961, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 10:54:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 329.70538330078125, 'train_avg_loss': 0.686886215209961, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 10:54:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 10:54:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:54:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:54:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:54:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.699402, avg_loss=0.701457, seen=480, correct=245, accuracy=0.510417
2025-10-10 10:54:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:54:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:54:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:54:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2292MB allocated=2074MB
2025-10-10 10:54:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.82330769300461, 'train_avg_loss': 0.7151942307750384, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 10:54:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.69940185546875, 'train_avg_loss': 0.7014570871988932, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 10:54:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 336.69940185546875, 'train_avg_loss': 0.7014570871988932, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 10:54:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 10:54:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:54:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:55:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:55:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.666443, avg_loss=0.699305, seen=480, correct=243, accuracy=0.506250
2025-10-10 10:55:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:55:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:55:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:55:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2292MB allocated=2074MB
2025-10-10 10:55:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.48489952087402, 'train_avg_loss': 0.7040408293406168, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 10:55:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.66644287109375, 'train_avg_loss': 0.6993050893147786, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:55:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 335.66644287109375, 'train_avg_loss': 0.6993050893147786, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 10:55:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 10:55:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:55:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:55:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:55:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.857025, avg_loss=0.703869, seen=480, correct=245, accuracy=0.510417
2025-10-10 10:55:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:55:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:55:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:55:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2288MB allocated=2074MB
2025-10-10 10:55:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.94931197166443, 'train_avg_loss': 0.6995775997638702, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 10:55:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.8570251464844, 'train_avg_loss': 0.7038688023885091, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 10:55:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 337.8570251464844, 'train_avg_loss': 0.7038688023885091, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 10:55:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:55:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:55:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:56:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:56:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.790039, avg_loss=0.682896, seen=480, correct=267, accuracy=0.556250
2025-10-10 10:56:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:56:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:56:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:56:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2326MB allocated=2074MB
2025-10-10 10:56:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.10359752178192, 'train_avg_loss': 0.6675299793481827, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 10:56:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.7900390625, 'train_avg_loss': 0.6828959147135417, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 10:56:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 327.7900390625, 'train_avg_loss': 0.6828959147135417, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 10:56:32 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #120) -------------
2025-10-10 10:56:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=120 aidx=3 | s=5 (candidates=8)
2025-10-10 10:56:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 24, 27, 33, 4] (from 8)
2025-10-10 10:56:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 10:56:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:56:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:57:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:57:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.484100, avg_loss=0.688509, seen=480, correct=254, accuracy=0.529167
2025-10-10 10:57:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:57:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:57:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:57:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2288MB allocated=2074MB
2025-10-10 10:57:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.06958985328674, 'train_avg_loss': 0.7005799154440562, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 10:57:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4841003417969, 'train_avg_loss': 0.6885085423787435, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 10:57:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 330.4841003417969, 'train_avg_loss': 0.6885085423787435, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 10:57:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 10:57:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:57:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:57:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:57:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.374634, avg_loss=0.700780, seen=480, correct=233, accuracy=0.485417
2025-10-10 10:57:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:57:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:57:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:57:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2288MB allocated=2074MB
2025-10-10 10:57:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.22013652324677, 'train_avg_loss': 0.7101678043603897, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 10:57:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.3746337890625, 'train_avg_loss': 0.7007804870605469, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 10:57:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 336.3746337890625, 'train_avg_loss': 0.7007804870605469, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 10:57:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:57:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:57:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 10:57:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 10:57:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:57:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:57:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:57:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:57:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:58:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:58:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.370026, avg_loss=0.698688, seen=480, correct=247, accuracy=0.514583
2025-10-10 10:58:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:58:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:58:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:58:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2292MB allocated=2074MB
2025-10-10 10:58:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3769199848175, 'train_avg_loss': 0.7031409998734792, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 10:58:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.3700256347656, 'train_avg_loss': 0.6986875534057617, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:58:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 335.3700256347656, 'train_avg_loss': 0.6986875534057617, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 10:58:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:58:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:58:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 10:58:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 10:58:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:58:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:58:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:58:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:58:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:59:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:59:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.258667, avg_loss=0.698456, seen=480, correct=256, accuracy=0.533333
2025-10-10 10:59:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:59:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:59:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:59:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2292MB allocated=2074MB
2025-10-10 10:59:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.28173476457596, 'train_avg_loss': 0.7023477897047996, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 10:59:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.2586669921875, 'train_avg_loss': 0.6984555562337239, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 10:59:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 335.2586669921875, 'train_avg_loss': 0.6984555562337239, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 10:59:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 10:59:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:59:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 10:59:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 10:59:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.216492, avg_loss=0.658784, seen=480, correct=309, accuracy=0.643750
2025-10-10 10:59:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 10:59:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:59:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 10:59:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2326MB allocated=2074MB
2025-10-10 10:59:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.67135000228882, 'train_avg_loss': 0.6555945833524068, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 10:59:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.21649169921875, 'train_avg_loss': 0.6587843577067057, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 10:59:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 316.21649169921875, 'train_avg_loss': 0.6587843577067057, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 10:59:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #121) -------------
2025-10-10 10:59:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=121 aidx=3 | s=5 (candidates=8)
2025-10-10 10:59:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 24, 42, 27, 44] (from 8)
2025-10-10 10:59:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 10:59:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 10:59:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:00:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:00:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.665039, avg_loss=0.690969, seen=480, correct=237, accuracy=0.493750
2025-10-10 11:00:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:00:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:00:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:00:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2288MB allocated=2074MB
2025-10-10 11:00:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.54618108272552, 'train_avg_loss': 0.7045515090227127, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 11:00:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6650390625, 'train_avg_loss': 0.6909688313802084, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 11:00:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 331.6650390625, 'train_avg_loss': 0.6909688313802084, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 11:00:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:00:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:00:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:01:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:01:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.632141, avg_loss=0.701317, seen=480, correct=244, accuracy=0.508333
2025-10-10 11:01:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:01:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:01:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:01:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2288MB allocated=2074MB
2025-10-10 11:01:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.20338153839111, 'train_avg_loss': 0.7100281794865926, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 11:01:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.63214111328125, 'train_avg_loss': 0.7013169606526692, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 11:01:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 336.63214111328125, 'train_avg_loss': 0.7013169606526692, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 11:01:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:01:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:01:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:01:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:01:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:01:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.370117, avg_loss=0.686188, seen=480, correct=255, accuracy=0.531250
2025-10-10 11:01:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:01:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:01:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:01:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2308MB allocated=2074MB
2025-10-10 11:01:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36282169818878, 'train_avg_loss': 0.6780235141515731, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 11:01:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3701171875, 'train_avg_loss': 0.686187744140625, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 11:01:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 329.3701171875, 'train_avg_loss': 0.686187744140625, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 11:01:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:01:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:02:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:02:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.694336, avg_loss=0.701447, seen=480, correct=243, accuracy=0.506250
2025-10-10 11:02:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:02:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:02:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:02:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2292MB allocated=2074MB
2025-10-10 11:02:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.08979523181915, 'train_avg_loss': 0.7090816269318263, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 11:02:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.6943359375, 'train_avg_loss': 0.701446533203125, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 11:02:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 336.6943359375, 'train_avg_loss': 0.701446533203125, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 11:02:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:02:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:02:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 11:02:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:02:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:02:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:02:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:02:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:02:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:02:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:02:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.294128, avg_loss=0.688113, seen=480, correct=267, accuracy=0.556250
2025-10-10 11:02:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:02:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:02:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:02:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2288MB allocated=2074MB
2025-10-10 11:02:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.92024028301239, 'train_avg_loss': 0.67433533569177, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 11:02:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.29412841796875, 'train_avg_loss': 0.6881127675374349, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 11:02:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 330.29412841796875, 'train_avg_loss': 0.6881127675374349, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 11:02:59 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #122) -------------
2025-10-10 11:02:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=122 aidx=3 | s=5 (candidates=8)
2025-10-10 11:02:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 30, 25, 4, 33] (from 8)
2025-10-10 11:03:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:03:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:03:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 11:03:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:03:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:03:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:03:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:03:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:03:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:03:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:03:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.495972, avg_loss=0.688533, seen=480, correct=251, accuracy=0.522917
2025-10-10 11:03:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:03:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:03:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:03:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2308MB allocated=2074MB
2025-10-10 11:03:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.74961161613464, 'train_avg_loss': 0.6812467634677887, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 11:03:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4959716796875, 'train_avg_loss': 0.6885332743326823, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:03:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 330.4959716796875, 'train_avg_loss': 0.6885332743326823, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:03:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:03:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:03:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 11:03:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:03:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:03:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:03:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:03:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:03:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:04:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:04:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.486572, avg_loss=0.692680, seen=480, correct=247, accuracy=0.514583
2025-10-10 11:04:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:04:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:04:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:04:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2288MB allocated=2074MB
2025-10-10 11:04:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.84784686565399, 'train_avg_loss': 0.7153987238804499, 'train_seen': 120, 'train_correct': 50, 'train_acc': 0.4166666666666667}}
2025-10-10 11:04:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.486572265625, 'train_avg_loss': 0.6926803588867188, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 11:04:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 332.486572265625, 'train_avg_loss': 0.6926803588867188, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 11:04:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:04:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:04:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:04:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:04:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.472443, avg_loss=0.692651, seen=480, correct=265, accuracy=0.552083
2025-10-10 11:04:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:04:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:04:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:04:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2288MB allocated=2074MB
2025-10-10 11:04:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.58690559864044, 'train_avg_loss': 0.6882242133220037, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:04:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4724426269531, 'train_avg_loss': 0.6926509221394856, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 11:04:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 332.4724426269531, 'train_avg_loss': 0.6926509221394856, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 11:04:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:04:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:04:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 11:05:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:05:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:05:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:05:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:05:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:05:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:05:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:05:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.823730, avg_loss=0.635049, seen=480, correct=313, accuracy=0.652083
2025-10-10 11:05:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:05:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:05:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:05:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2326MB allocated=2074MB
2025-10-10 11:05:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.47425651550293, 'train_avg_loss': 0.6456188042958577, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:05:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.82373046875, 'train_avg_loss': 0.6350494384765625, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:05:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 304.82373046875, 'train_avg_loss': 0.6350494384765625, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:05:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:05:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:05:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:06:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:06:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.610840, avg_loss=0.697106, seen=480, correct=262, accuracy=0.545833
2025-10-10 11:06:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:06:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:06:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:06:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2292MB allocated=2074MB
2025-10-10 11:06:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.59952044487, 'train_avg_loss': 0.7049960037072499, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 11:06:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.61083984375, 'train_avg_loss': 0.6971059163411458, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 11:06:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 334.61083984375, 'train_avg_loss': 0.6971059163411458, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 11:06:13 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #123) -------------
2025-10-10 11:06:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=123 aidx=3 | s=5 (candidates=8)
2025-10-10 11:06:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 44, 30, 25, 42] (from 8)
2025-10-10 11:06:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:06:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:06:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:06:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:06:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.281281, avg_loss=0.638086, seen=480, correct=311, accuracy=0.647917
2025-10-10 11:06:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:06:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:06:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:06:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2326MB allocated=2074MB
2025-10-10 11:06:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.8785930275917, 'train_avg_loss': 0.6489882752299309, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 11:06:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.2812805175781, 'train_avg_loss': 0.6380860010782877, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 11:06:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 306.2812805175781, 'train_avg_loss': 0.6380860010782877, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 11:06:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:06:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:06:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 11:06:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:06:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:06:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:06:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:06:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:06:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:07:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:07:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.731171, avg_loss=0.682773, seen=480, correct=271, accuracy=0.564583
2025-10-10 11:07:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:07:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:07:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:07:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2288MB allocated=2074MB
2025-10-10 11:07:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.96802628040314, 'train_avg_loss': 0.6664002190033594, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:07:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.7311706542969, 'train_avg_loss': 0.6827732721964518, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:07:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 327.7311706542969, 'train_avg_loss': 0.6827732721964518, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:07:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:07:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:07:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:08:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:08:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.611115, avg_loss=0.688773, seen=480, correct=244, accuracy=0.508333
2025-10-10 11:08:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:08:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:08:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:08:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2288MB allocated=2074MB
2025-10-10 11:08:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.89747202396393, 'train_avg_loss': 0.7074789335330327, 'train_seen': 120, 'train_correct': 49, 'train_acc': 0.4083333333333333}}
2025-10-10 11:08:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6111145019531, 'train_avg_loss': 0.6887731552124023, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 11:08:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 330.6111145019531, 'train_avg_loss': 0.6887731552124023, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 11:08:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:08:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:08:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 11:08:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:08:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:08:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:08:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:08:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:08:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:08:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:08:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.117371, avg_loss=0.693995, seen=480, correct=254, accuracy=0.529167
2025-10-10 11:08:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:08:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:08:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:08:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2288MB allocated=2074MB
2025-10-10 11:08:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.20823574066162, 'train_avg_loss': 0.6934019645055135, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:08:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.11737060546875, 'train_avg_loss': 0.6939945220947266, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:08:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 333.11737060546875, 'train_avg_loss': 0.6939945220947266, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:08:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:08:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:08:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:09:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:09:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.029938, avg_loss=0.683396, seen=480, correct=265, accuracy=0.552083
2025-10-10 11:09:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:09:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:09:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2312MB allocated=2074MB
2025-10-10 11:09:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.89163053035736, 'train_avg_loss': 0.6740969210863114, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:09:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0299377441406, 'train_avg_loss': 0.6833957036336263, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 11:09:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 328.0299377441406, 'train_avg_loss': 0.6833957036336263, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 11:09:30 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #124) -------------
2025-10-10 11:09:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=124 aidx=3 | s=5 (candidates=8)
2025-10-10 11:09:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 25, 4, 42, 24] (from 8)
2025-10-10 11:09:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:09:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:09:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:10:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:10:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.256226, avg_loss=0.688034, seen=480, correct=259, accuracy=0.539583
2025-10-10 11:10:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:10:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:10:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:10:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2292MB allocated=2074MB
2025-10-10 11:10:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72003662586212, 'train_avg_loss': 0.689333638548851, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 11:10:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.2562255859375, 'train_avg_loss': 0.6880338033040364, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 11:10:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 330.2562255859375, 'train_avg_loss': 0.6880338033040364, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 11:10:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:10:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:10:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:10:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:10:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.394257, avg_loss=0.696655, seen=480, correct=258, accuracy=0.537500
2025-10-10 11:10:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:10:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:10:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:10:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2288MB allocated=2074MB
2025-10-10 11:10:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.38468480110168, 'train_avg_loss': 0.6948723733425141, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:10:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.3942565917969, 'train_avg_loss': 0.6966547012329102, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 11:10:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 334.3942565917969, 'train_avg_loss': 0.6966547012329102, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 11:10:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:10:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:10:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:11:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:11:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.197205, avg_loss=0.633744, seen=480, correct=313, accuracy=0.652083
2025-10-10 11:11:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:11:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:11:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:11:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2326MB allocated=2074MB
2025-10-10 11:11:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.1619120836258, 'train_avg_loss': 0.6513492673635483, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:11:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.19720458984375, 'train_avg_loss': 0.6337441762288412, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:11:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 304.19720458984375, 'train_avg_loss': 0.6337441762288412, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:11:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:11:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:11:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 11:11:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:11:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:11:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:11:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:11:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:11:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:12:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:12:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.478729, avg_loss=0.673914, seen=480, correct=280, accuracy=0.583333
2025-10-10 11:12:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:12:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:12:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:12:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2308MB allocated=2074MB
2025-10-10 11:12:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.04501235485077, 'train_avg_loss': 0.6587084362904231, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:12:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4787292480469, 'train_avg_loss': 0.6739140192667643, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 11:12:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 323.4787292480469, 'train_avg_loss': 0.6739140192667643, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 11:12:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:12:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:12:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:12:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:12:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.618286, avg_loss=0.701288, seen=480, correct=240, accuracy=0.500000
2025-10-10 11:12:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:12:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:12:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:12:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2288MB allocated=2074MB
2025-10-10 11:12:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.57629668712616, 'train_avg_loss': 0.7131358057260513, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 11:12:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.6182861328125, 'train_avg_loss': 0.7012880961100261, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 11:12:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 336.6182861328125, 'train_avg_loss': 0.7012880961100261, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 11:12:46 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #125) -------------
2025-10-10 11:12:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=125 aidx=3 | s=5 (candidates=8)
2025-10-10 11:12:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 44, 42, 33, 25] (from 8)
2025-10-10 11:12:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:12:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:12:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:13:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:13:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.838257, avg_loss=0.687163, seen=480, correct=252, accuracy=0.525000
2025-10-10 11:13:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:13:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:13:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:13:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2288MB allocated=2074MB
2025-10-10 11:13:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.0785903930664, 'train_avg_loss': 0.7089882532755534, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 11:13:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8382568359375, 'train_avg_loss': 0.6871630350748698, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:13:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 329.8382568359375, 'train_avg_loss': 0.6871630350748698, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:13:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:13:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:13:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:14:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:14:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.403900, avg_loss=0.680008, seen=480, correct=269, accuracy=0.560417
2025-10-10 11:14:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:14:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:14:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:14:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2288MB allocated=2074MB
2025-10-10 11:14:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.56647419929504, 'train_avg_loss': 0.6630539516607921, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:14:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.4039001464844, 'train_avg_loss': 0.6800081253051757, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 11:14:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 326.4039001464844, 'train_avg_loss': 0.6800081253051757, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 11:14:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:14:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:14:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 11:14:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:14:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:14:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:14:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:14:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:14:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:14:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:14:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.642242, avg_loss=0.676338, seen=480, correct=281, accuracy=0.585417
2025-10-10 11:14:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:14:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:14:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:14:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2308MB allocated=2074MB
2025-10-10 11:14:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.35130763053894, 'train_avg_loss': 0.6695942302544912, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 11:14:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6422424316406, 'train_avg_loss': 0.676338005065918, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 11:14:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 324.6422424316406, 'train_avg_loss': 0.676338005065918, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 11:14:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:14:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:14:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:15:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:15:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.013184, avg_loss=0.685444, seen=480, correct=262, accuracy=0.545833
2025-10-10 11:15:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:15:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:15:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:15:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2292MB allocated=2074MB
2025-10-10 11:15:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.0049095749855, 'train_avg_loss': 0.6917075797915458, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 11:15:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.01318359375, 'train_avg_loss': 0.6854441324869792, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 11:15:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 329.01318359375, 'train_avg_loss': 0.6854441324869792, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 11:15:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:15:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:15:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:16:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:16:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.345703, avg_loss=0.692387, seen=480, correct=256, accuracy=0.533333
2025-10-10 11:16:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:16:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:16:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:16:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2288MB allocated=2074MB
2025-10-10 11:16:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.65475165843964, 'train_avg_loss': 0.6887895971536636, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:16:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.345703125, 'train_avg_loss': 0.6923868815104167, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:16:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 332.345703125, 'train_avg_loss': 0.6923868815104167, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:16:02 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #126) -------------
2025-10-10 11:16:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=126 aidx=3 | s=5 (candidates=8)
2025-10-10 11:16:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 44, 4, 30, 42] (from 8)
2025-10-10 11:16:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:16:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:16:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:16:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:16:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.984314, avg_loss=0.689551, seen=480, correct=257, accuracy=0.535417
2025-10-10 11:16:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:16:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:16:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:16:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2292MB allocated=2074MB
2025-10-10 11:16:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.27421367168427, 'train_avg_loss': 0.6939517805973688, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 11:16:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.98431396484375, 'train_avg_loss': 0.6895506540934245, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 11:16:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 330.98431396484375, 'train_avg_loss': 0.6895506540934245, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 11:16:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:16:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:16:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:17:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:17:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.034973, avg_loss=0.679240, seen=480, correct=266, accuracy=0.554167
2025-10-10 11:17:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:17:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:17:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:17:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2288MB allocated=2074MB
2025-10-10 11:17:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.91280603408813, 'train_avg_loss': 0.6659400502840678, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:17:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.03497314453125, 'train_avg_loss': 0.6792395273844402, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:17:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 326.03497314453125, 'train_avg_loss': 0.6792395273844402, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:17:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:17:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:17:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:18:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:18:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.011017, avg_loss=0.637523, seen=480, correct=314, accuracy=0.654167
2025-10-10 11:18:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:18:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:18:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:18:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2326MB allocated=2074MB
2025-10-10 11:18:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.54843997955322, 'train_avg_loss': 0.6462369998296101, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:18:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.0110168457031, 'train_avg_loss': 0.6375229517618816, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 11:18:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 306.0110168457031, 'train_avg_loss': 0.6375229517618816, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 11:18:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:18:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:18:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:18:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:18:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.206085, avg_loss=0.685846, seen=480, correct=251, accuracy=0.522917
2025-10-10 11:18:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:18:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:18:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:18:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2288MB allocated=2074MB
2025-10-10 11:18:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.24172854423523, 'train_avg_loss': 0.7020144045352936, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 11:18:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2060852050781, 'train_avg_loss': 0.6858460108439127, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:18:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 329.2060852050781, 'train_avg_loss': 0.6858460108439127, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:18:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:18:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:18:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:19:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:19:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.531006, avg_loss=0.678190, seen=480, correct=266, accuracy=0.554167
2025-10-10 11:19:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:19:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:19:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:19:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2308MB allocated=2074MB
2025-10-10 11:19:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.18176591396332, 'train_avg_loss': 0.6765147159496944, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 11:19:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.531005859375, 'train_avg_loss': 0.6781895955403646, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:19:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 325.531005859375, 'train_avg_loss': 0.6781895955403646, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:19:22 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #127) -------------
2025-10-10 11:19:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=127 aidx=3 | s=5 (candidates=8)
2025-10-10 11:19:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 24, 4, 42, 44] (from 8)
2025-10-10 11:19:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:19:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:19:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:19:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:19:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.303223, avg_loss=0.700632, seen=480, correct=245, accuracy=0.510417
2025-10-10 11:19:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:19:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:20:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:20:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2292MB allocated=2074MB
2025-10-10 11:20:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.50545918941498, 'train_avg_loss': 0.7125454932451248, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 11:20:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.30322265625, 'train_avg_loss': 0.7006317138671875, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 11:20:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 336.30322265625, 'train_avg_loss': 0.7006317138671875, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 11:20:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:20:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:20:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 11:20:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:20:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:20:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:20:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:20:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:20:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:20:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:20:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.397888, avg_loss=0.694579, seen=480, correct=252, accuracy=0.525000
2025-10-10 11:20:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:20:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:20:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:20:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2288MB allocated=2074MB
2025-10-10 11:20:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.78912341594696, 'train_avg_loss': 0.7065760284662247, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 11:20:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.39788818359375, 'train_avg_loss': 0.6945789337158204, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:20:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 333.39788818359375, 'train_avg_loss': 0.6945789337158204, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:20:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:20:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:20:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:21:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:21:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.840698, avg_loss=0.635085, seen=480, correct=313, accuracy=0.652083
2025-10-10 11:21:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:21:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:21:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:21:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2326MB allocated=2074MB
2025-10-10 11:21:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.21486502885818, 'train_avg_loss': 0.6517905419071516, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:21:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.8406982421875, 'train_avg_loss': 0.6350847880045573, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:21:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 304.8406982421875, 'train_avg_loss': 0.6350847880045573, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 11:21:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:21:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:21:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:21:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:21:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.817841, avg_loss=0.668371, seen=480, correct=277, accuracy=0.577083
2025-10-10 11:21:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:21:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:22:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:22:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2312MB allocated=2074MB
2025-10-10 11:22:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.33879792690277, 'train_avg_loss': 0.6611566493908564, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:22:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.8178405761719, 'train_avg_loss': 0.6683705012003581, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:22:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 320.8178405761719, 'train_avg_loss': 0.6683705012003581, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:22:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:22:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:22:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:22:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:22:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.040649, avg_loss=0.677168, seen=480, correct=271, accuracy=0.564583
2025-10-10 11:22:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:22:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:22:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:22:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2288MB allocated=2074MB
2025-10-10 11:22:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.50660532712936, 'train_avg_loss': 0.6625550443927447, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:22:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0406494140625, 'train_avg_loss': 0.6771680196126302, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:22:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 325.0406494140625, 'train_avg_loss': 0.6771680196126302, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:22:40 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #128) -------------
2025-10-10 11:22:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=128 aidx=3 | s=5 (candidates=8)
2025-10-10 11:22:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 24, 25, 30, 27] (from 8)
2025-10-10 11:22:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:22:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:22:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 11:22:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:22:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:22:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:22:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:22:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:22:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:23:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:23:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.464539, avg_loss=0.632218, seen=480, correct=305, accuracy=0.635417
2025-10-10 11:23:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:23:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:23:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:23:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2326MB allocated=2074MB
2025-10-10 11:23:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.31994765996933, 'train_avg_loss': 0.6526662304997444, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:23:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.46453857421875, 'train_avg_loss': 0.6322177886962891, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 11:23:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 303.46453857421875, 'train_avg_loss': 0.6322177886962891, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 11:23:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:23:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:23:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:23:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:23:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.831055, avg_loss=0.693398, seen=480, correct=251, accuracy=0.522917
2025-10-10 11:23:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:23:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:23:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:23:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2288MB allocated=2074MB
2025-10-10 11:23:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.23100590705872, 'train_avg_loss': 0.7019250492254893, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 11:23:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8310546875, 'train_avg_loss': 0.6933980305989583, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:23:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 332.8310546875, 'train_avg_loss': 0.6933980305989583, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:23:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:24:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:24:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:24:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:24:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.843719, avg_loss=0.683008, seen=480, correct=270, accuracy=0.562500
2025-10-10 11:24:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:24:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:24:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:24:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2288MB allocated=2074MB
2025-10-10 11:24:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.04078584909439, 'train_avg_loss': 0.68367321540912, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 11:24:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8437194824219, 'train_avg_loss': 0.6830077489217122, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 11:24:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 327.8437194824219, 'train_avg_loss': 0.6830077489217122, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 11:24:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:24:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:24:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:25:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:25:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.344849, avg_loss=0.684052, seen=480, correct=254, accuracy=0.529167
2025-10-10 11:25:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:25:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:25:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:25:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2288MB allocated=2074MB
2025-10-10 11:25:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.86662584543228, 'train_avg_loss': 0.707221882045269, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 11:25:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3448486328125, 'train_avg_loss': 0.6840517679850261, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:25:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 328.3448486328125, 'train_avg_loss': 0.6840517679850261, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:25:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:25:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:25:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:25:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:25:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.902557, avg_loss=0.695630, seen=480, correct=256, accuracy=0.533333
2025-10-10 11:25:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:25:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:25:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:25:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2292MB allocated=2074MB
2025-10-10 11:25:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.40250396728516, 'train_avg_loss': 0.7033541997273763, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 11:25:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9025573730469, 'train_avg_loss': 0.6956303278605144, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:25:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 333.9025573730469, 'train_avg_loss': 0.6956303278605144, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:25:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #129) -------------
2025-10-10 11:25:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=129 aidx=3 | s=5 (candidates=8)
2025-10-10 11:25:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 33, 25, 27, 30] (from 8)
2025-10-10 11:25:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:25:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:25:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:26:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:26:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.774628, avg_loss=0.693280, seen=480, correct=254, accuracy=0.529167
2025-10-10 11:26:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:26:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:26:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:26:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2288MB allocated=2074MB
2025-10-10 11:26:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.23191237449646, 'train_avg_loss': 0.7019326031208039, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 11:26:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.7746276855469, 'train_avg_loss': 0.6932804743448894, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:26:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 332.7746276855469, 'train_avg_loss': 0.6932804743448894, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 11:26:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:26:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:26:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 11:26:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:26:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:26:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:26:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:26:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:26:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:27:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:27:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.041595, avg_loss=0.681337, seen=480, correct=268, accuracy=0.558333
2025-10-10 11:27:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:27:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:27:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:27:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2292MB allocated=2074MB
2025-10-10 11:27:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.15125584602356, 'train_avg_loss': 0.684593798716863, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:27:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0415954589844, 'train_avg_loss': 0.6813366572062175, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 11:27:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 327.0415954589844, 'train_avg_loss': 0.6813366572062175, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 11:27:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:27:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:27:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 11:27:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:27:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:27:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:27:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:27:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:27:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:27:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:27:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.455444, avg_loss=0.686366, seen=480, correct=269, accuracy=0.560417
2025-10-10 11:27:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:27:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:27:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:27:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2288MB allocated=2074MB
2025-10-10 11:27:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.16499495506287, 'train_avg_loss': 0.6847082912921906, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 11:27:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4554443359375, 'train_avg_loss': 0.6863655090332031, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 11:27:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 329.4554443359375, 'train_avg_loss': 0.6863655090332031, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 11:27:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:27:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:27:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 11:27:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:27:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:27:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:27:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:27:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:27:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:28:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:28:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.122406, avg_loss=0.687755, seen=480, correct=256, accuracy=0.533333
2025-10-10 11:28:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:28:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:28:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:28:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2292MB allocated=2074MB
2025-10-10 11:28:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.95604944229126, 'train_avg_loss': 0.6913004120190939, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 11:28:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1224060058594, 'train_avg_loss': 0.687755012512207, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:28:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 330.1224060058594, 'train_avg_loss': 0.687755012512207, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 11:28:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:28:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:28:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 11:28:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:28:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:28:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:28:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:28:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:28:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:29:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:29:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.244263, avg_loss=0.683842, seen=480, correct=252, accuracy=0.525000
2025-10-10 11:29:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:29:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:29:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:29:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2288MB allocated=2074MB
2025-10-10 11:29:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.88426041603088, 'train_avg_loss': 0.7073688368002574, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 11:29:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2442626953125, 'train_avg_loss': 0.6838422139485677, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:29:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 328.2442626953125, 'train_avg_loss': 0.6838422139485677, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 11:29:13 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #130) -------------
2025-10-10 11:29:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=130 aidx=3 | s=5 (candidates=8)
2025-10-10 11:29:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 25, 4, 27, 30] (from 8)
2025-10-10 11:29:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:29:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:29:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:29:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:29:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.949554, avg_loss=0.681145, seen=480, correct=266, accuracy=0.554167
2025-10-10 11:29:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:29:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:29:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:29:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2292MB allocated=2074MB
2025-10-10 11:29:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.89992392063141, 'train_avg_loss': 0.6824993660052617, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:29:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9495544433594, 'train_avg_loss': 0.681144905090332, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:29:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 326.9495544433594, 'train_avg_loss': 0.681144905090332, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:29:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:29:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:29:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:30:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:30:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.365479, avg_loss=0.688261, seen=480, correct=266, accuracy=0.554167
2025-10-10 11:30:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:30:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:30:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:30:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2288MB allocated=2074MB
2025-10-10 11:30:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.44737541675568, 'train_avg_loss': 0.6870614618062973, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:30:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.365478515625, 'train_avg_loss': 0.6882614135742188, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:30:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 330.365478515625, 'train_avg_loss': 0.6882614135742188, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 11:30:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:30:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:30:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 11:30:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:30:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:30:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:30:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:30:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:30:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:31:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:31:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.931152, avg_loss=0.633190, seen=480, correct=316, accuracy=0.658333
2025-10-10 11:31:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:31:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:31:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:31:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2326MB allocated=2074MB
2025-10-10 11:31:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.56361490488052, 'train_avg_loss': 0.646363457540671, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 11:31:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.93115234375, 'train_avg_loss': 0.6331899007161458, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 11:31:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 303.93115234375, 'train_avg_loss': 0.6331899007161458, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 11:31:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:31:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:31:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:31:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:31:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.331177, avg_loss=0.686107, seen=480, correct=260, accuracy=0.541667
2025-10-10 11:31:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:31:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:31:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:31:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2294MB allocated=2074MB
2025-10-10 11:31:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.8354914188385, 'train_avg_loss': 0.6902957618236542, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:31:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3311767578125, 'train_avg_loss': 0.6861066182454427, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:31:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 329.3311767578125, 'train_avg_loss': 0.6861066182454427, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:31:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:31:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:31:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:32:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:32:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.159546, avg_loss=0.677416, seen=480, correct=258, accuracy=0.537500
2025-10-10 11:32:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:32:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:32:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:32:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2288MB allocated=2074MB
2025-10-10 11:32:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.96412873268127, 'train_avg_loss': 0.699701072772344, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 11:32:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.1595458984375, 'train_avg_loss': 0.6774157206217448, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 11:32:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 325.1595458984375, 'train_avg_loss': 0.6774157206217448, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 11:32:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #131) -------------
2025-10-10 11:32:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=131 aidx=3 | s=5 (candidates=8)
2025-10-10 11:32:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 44, 24, 33, 4] (from 8)
2025-10-10 11:32:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:32:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:32:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:33:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:33:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.840424, avg_loss=0.687168, seen=480, correct=270, accuracy=0.562500
2025-10-10 11:33:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:33:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:33:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:33:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2288MB allocated=2074MB
2025-10-10 11:33:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.74613064527512, 'train_avg_loss': 0.6812177553772927, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:33:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8404235839844, 'train_avg_loss': 0.6871675491333008, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 11:33:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 329.8404235839844, 'train_avg_loss': 0.6871675491333008, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 11:33:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:33:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:33:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:33:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:33:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.183838, avg_loss=0.667050, seen=480, correct=278, accuracy=0.579167
2025-10-10 11:33:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:33:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:33:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:33:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2288MB allocated=2074MB
2025-10-10 11:33:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.94533884525299, 'train_avg_loss': 0.641211157043775, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:33:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.183837890625, 'train_avg_loss': 0.6670496622721355, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 11:33:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 320.183837890625, 'train_avg_loss': 0.6670496622721355, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 11:33:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:33:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:33:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:34:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:34:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.298523, avg_loss=0.694372, seen=480, correct=241, accuracy=0.502083
2025-10-10 11:34:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:34:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:34:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:34:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2288MB allocated=2074MB
2025-10-10 11:34:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.05323922634125, 'train_avg_loss': 0.7087769935528437, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 11:34:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.29852294921875, 'train_avg_loss': 0.6943719228108723, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 11:34:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 333.29852294921875, 'train_avg_loss': 0.6943719228108723, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 11:34:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:34:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:34:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 11:34:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:34:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:34:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:34:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:34:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:34:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:35:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:35:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.634857, avg_loss=0.680489, seen=480, correct=273, accuracy=0.568750
2025-10-10 11:35:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:35:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:35:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:35:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2292MB allocated=2074MB
2025-10-10 11:35:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.11398911476135, 'train_avg_loss': 0.6842832426230113, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:35:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6348571777344, 'train_avg_loss': 0.6804892857869466, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 11:35:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 326.6348571777344, 'train_avg_loss': 0.6804892857869466, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 11:35:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:35:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:35:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 11:35:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:35:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:35:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:35:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:35:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:35:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:35:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:35:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.811462, avg_loss=0.637107, seen=480, correct=308, accuracy=0.641667
2025-10-10 11:35:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:35:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:35:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:35:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2326MB allocated=2074MB
2025-10-10 11:35:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.76606595516205, 'train_avg_loss': 0.6480505496263504, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 11:35:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.81146240234375, 'train_avg_loss': 0.6371072133382162, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 11:35:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 305.81146240234375, 'train_avg_loss': 0.6371072133382162, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 11:35:42 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #132) -------------
2025-10-10 11:35:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=132 aidx=3 | s=5 (candidates=8)
2025-10-10 11:35:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 25, 27, 24, 42] (from 8)
2025-10-10 11:35:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:35:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:35:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:36:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:36:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.193146, avg_loss=0.664986, seen=480, correct=284, accuracy=0.591667
2025-10-10 11:36:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:36:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:36:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:36:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2288MB allocated=2074MB
2025-10-10 11:36:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.43227469921112, 'train_avg_loss': 0.6369356224934261, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 11:36:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.1931457519531, 'train_avg_loss': 0.664985720316569, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 11:36:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 319.1931457519531, 'train_avg_loss': 0.664985720316569, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 11:36:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:36:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:36:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:37:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:37:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.385498, avg_loss=0.686220, seen=480, correct=268, accuracy=0.558333
2025-10-10 11:37:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:37:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:37:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:37:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2288MB allocated=2074MB
2025-10-10 11:37:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.05021470785141, 'train_avg_loss': 0.6837517892320951, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:37:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.385498046875, 'train_avg_loss': 0.6862197875976562, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 11:37:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 329.385498046875, 'train_avg_loss': 0.6862197875976562, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 11:37:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:37:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:37:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:37:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:37:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.368195, avg_loss=0.690350, seen=480, correct=260, accuracy=0.541667
2025-10-10 11:37:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:37:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:37:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:37:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2292MB allocated=2074MB
2025-10-10 11:37:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.366912484169, 'train_avg_loss': 0.6947242707014084, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:37:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3681945800781, 'train_avg_loss': 0.6903504053751628, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:37:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 331.3681945800781, 'train_avg_loss': 0.6903504053751628, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:37:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:37:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:37:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:38:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:38:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.979736, avg_loss=0.693708, seen=480, correct=246, accuracy=0.512500
2025-10-10 11:38:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:38:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:38:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:38:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2288MB allocated=2074MB
2025-10-10 11:38:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.96244639158249, 'train_avg_loss': 0.7080203865965208, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 11:38:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.979736328125, 'train_avg_loss': 0.6937077840169271, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 11:38:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 332.979736328125, 'train_avg_loss': 0.6937077840169271, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 11:38:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:38:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:38:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:38:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:38:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.656433, avg_loss=0.659701, seen=480, correct=296, accuracy=0.616667
2025-10-10 11:38:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:38:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:39:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:39:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2312MB allocated=2074MB
2025-10-10 11:39:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.16409504413605, 'train_avg_loss': 0.6513674587011338, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 11:39:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.65643310546875, 'train_avg_loss': 0.6597009023030599, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 11:39:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 316.65643310546875, 'train_avg_loss': 0.6597009023030599, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 11:39:02 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #133) -------------
2025-10-10 11:39:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=133 aidx=3 | s=5 (candidates=8)
2025-10-10 11:39:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 4, 27, 24, 44] (from 8)
2025-10-10 11:39:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:39:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:39:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:39:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:39:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.502563, avg_loss=0.648964, seen=480, correct=297, accuracy=0.618750
2025-10-10 11:39:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:39:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:39:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:39:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2312MB allocated=2074MB
2025-10-10 11:39:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.62275969982147, 'train_avg_loss': 0.6385229974985123, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 11:39:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.5025634765625, 'train_avg_loss': 0.6489636739095052, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 11:39:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 311.5025634765625, 'train_avg_loss': 0.6489636739095052, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 11:39:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:39:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:39:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:40:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:40:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=288.930084, avg_loss=0.601938, seen=480, correct=327, accuracy=0.681250
2025-10-10 11:40:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:40:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:40:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:40:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2326MB allocated=2074MB
2025-10-10 11:40:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.96071302890778, 'train_avg_loss': 0.6413392752408982, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 11:40:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 288.9300842285156, 'train_avg_loss': 0.6019376754760742, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 11:40:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 288.9300842285156, 'train_avg_loss': 0.6019376754760742, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 11:40:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:40:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:40:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:40:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:40:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.390594, avg_loss=0.694564, seen=480, correct=261, accuracy=0.543750
2025-10-10 11:40:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:40:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:40:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:40:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2292MB allocated=2074MB
2025-10-10 11:40:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.08713096380234, 'train_avg_loss': 0.7007260913650195, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:40:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3905944824219, 'train_avg_loss': 0.6945637385050456, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 11:40:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 333.3905944824219, 'train_avg_loss': 0.6945637385050456, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 11:40:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:40:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:40:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 11:41:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:41:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:41:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:41:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:41:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:41:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:41:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:41:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.364197, avg_loss=0.698675, seen=480, correct=251, accuracy=0.522917
2025-10-10 11:41:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:41:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:41:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:41:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2288MB allocated=2074MB
2025-10-10 11:41:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.13868898153305, 'train_avg_loss': 0.7178224081794421, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 11:41:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.36419677734375, 'train_avg_loss': 0.6986754099527995, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:41:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 335.36419677734375, 'train_avg_loss': 0.6986754099527995, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 11:41:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:41:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:41:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:42:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:42:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.880768, avg_loss=0.662252, seen=480, correct=291, accuracy=0.606250
2025-10-10 11:42:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:42:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:42:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:42:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2288MB allocated=2074MB
2025-10-10 11:42:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.98628747463226, 'train_avg_loss': 0.6248857289552688, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 11:42:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8807678222656, 'train_avg_loss': 0.66225159962972, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 11:42:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 317.8807678222656, 'train_avg_loss': 0.66225159962972, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 11:42:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #134) -------------
2025-10-10 11:42:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=134 aidx=3 | s=5 (candidates=8)
2025-10-10 11:42:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 33, 42, 25, 4] (from 8)
2025-10-10 11:42:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:42:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:42:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:42:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:42:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.351227, avg_loss=0.690315, seen=480, correct=260, accuracy=0.541667
2025-10-10 11:42:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:42:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:42:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:42:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2292MB allocated=2074MB
2025-10-10 11:42:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.7664783000946, 'train_avg_loss': 0.6980539858341217, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 11:42:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3512268066406, 'train_avg_loss': 0.690315055847168, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:42:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 331.3512268066406, 'train_avg_loss': 0.690315055847168, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 11:42:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:42:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:42:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:43:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:43:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.430115, avg_loss=0.682146, seen=480, correct=277, accuracy=0.577083
2025-10-10 11:43:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:43:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:43:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:43:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2292MB allocated=2074MB
2025-10-10 11:43:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97335731983185, 'train_avg_loss': 0.6914446443319321, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:43:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.43011474609375, 'train_avg_loss': 0.6821460723876953, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:43:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 327.43011474609375, 'train_avg_loss': 0.6821460723876953, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:43:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:43:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:43:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:44:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:44:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.308105, avg_loss=0.648559, seen=480, correct=306, accuracy=0.637500
2025-10-10 11:44:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:44:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:44:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:44:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2310MB allocated=2074MB
2025-10-10 11:44:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.51477235555649, 'train_avg_loss': 0.6376231029629708, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 11:44:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.30810546875, 'train_avg_loss': 0.6485585530598958, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 11:44:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 311.30810546875, 'train_avg_loss': 0.6485585530598958, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 11:44:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:44:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:44:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 11:44:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:44:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:44:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:44:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:44:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:44:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:44:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:44:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.841553, avg_loss=0.685087, seen=480, correct=277, accuracy=0.577083
2025-10-10 11:44:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:44:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:44:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:44:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2288MB allocated=2074MB
2025-10-10 11:44:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.84443259239197, 'train_avg_loss': 0.6903702716032664, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 11:44:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.841552734375, 'train_avg_loss': 0.6850865681966146, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:44:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 328.841552734375, 'train_avg_loss': 0.6850865681966146, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 11:44:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:44:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:44:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:45:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:45:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.052826, avg_loss=0.598027, seen=480, correct=333, accuracy=0.693750
2025-10-10 11:45:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:45:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:45:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:45:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2326MB allocated=2074MB
2025-10-10 11:45:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.20238530635834, 'train_avg_loss': 0.6350198775529862, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 11:45:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.0528259277344, 'train_avg_loss': 0.59802672068278, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 11:45:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 287.0528259277344, 'train_avg_loss': 0.59802672068278, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 11:45:33 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #135) -------------
2025-10-10 11:45:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=135 aidx=3 | s=5 (candidates=8)
2025-10-10 11:45:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 25, 24, 30, 4] (from 8)
2025-10-10 11:45:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:45:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:45:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:46:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:46:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.217590, avg_loss=0.650453, seen=480, correct=296, accuracy=0.616667
2025-10-10 11:46:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:46:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:46:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:46:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2288MB allocated=2074MB
2025-10-10 11:46:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.25928920507431, 'train_avg_loss': 0.6104940767089526, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 11:46:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.21759033203125, 'train_avg_loss': 0.6504533131917317, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 11:46:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 312.21759033203125, 'train_avg_loss': 0.6504533131917317, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 11:46:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:46:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:46:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 11:46:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:46:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:46:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:46:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:46:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:46:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:46:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:46:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.389008, avg_loss=0.688310, seen=480, correct=271, accuracy=0.564583
2025-10-10 11:46:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:46:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:46:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:46:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2288MB allocated=2074MB
2025-10-10 11:46:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.19995945692062, 'train_avg_loss': 0.6933329954743386, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 11:46:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3890075683594, 'train_avg_loss': 0.6883104324340821, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:46:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 330.3890075683594, 'train_avg_loss': 0.6883104324340821, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 11:46:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:46:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:46:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:47:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:47:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.484497, avg_loss=0.701009, seen=480, correct=255, accuracy=0.531250
2025-10-10 11:47:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:47:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:47:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:47:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2288MB allocated=2074MB
2025-10-10 11:47:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.5991672873497, 'train_avg_loss': 0.7216597273945808, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 11:47:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4844970703125, 'train_avg_loss': 0.7010093688964844, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 11:47:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 336.4844970703125, 'train_avg_loss': 0.7010093688964844, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 11:47:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:47:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:47:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:48:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:48:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.383453, avg_loss=0.669549, seen=480, correct=272, accuracy=0.566667
2025-10-10 11:48:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:48:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:48:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:48:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2288MB allocated=2074MB
2025-10-10 11:48:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.99970006942749, 'train_avg_loss': 0.7083308339118958, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 11:48:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3834533691406, 'train_avg_loss': 0.6695488611857097, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 11:48:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 321.3834533691406, 'train_avg_loss': 0.6695488611857097, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 11:48:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:48:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:48:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:48:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:48:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=272.019775, avg_loss=0.566708, seen=480, correct=344, accuracy=0.716667
2025-10-10 11:48:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:48:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:48:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:48:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2326MB allocated=2074MB
2025-10-10 11:48:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.39842063188553, 'train_avg_loss': 0.619986838599046, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 11:48:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 272.019775390625, 'train_avg_loss': 0.5667078653971355, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-10 11:48:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 272.019775390625, 'train_avg_loss': 0.5667078653971355, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-10 11:48:53 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #136) -------------
2025-10-10 11:48:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=136 aidx=3 | s=5 (candidates=8)
2025-10-10 11:48:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 42, 30, 33, 4] (from 8)
2025-10-10 11:48:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 11:48:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:48:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:49:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:49:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.067993, avg_loss=0.700142, seen=480, correct=261, accuracy=0.543750
2025-10-10 11:49:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:49:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:49:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:49:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2292MB allocated=2074MB
2025-10-10 11:49:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.70049858093262, 'train_avg_loss': 0.7058374881744385, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 11:49:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.0679931640625, 'train_avg_loss': 0.7001416524251302, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 11:49:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 336.0679931640625, 'train_avg_loss': 0.7001416524251302, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 11:49:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:49:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:49:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:50:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:50:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.155457, avg_loss=0.654491, seen=480, correct=300, accuracy=0.625000
2025-10-10 11:50:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:50:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:50:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:50:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2308MB allocated=2074MB
2025-10-10 11:50:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.41808438301086, 'train_avg_loss': 0.6368173698584239, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 11:50:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.15545654296875, 'train_avg_loss': 0.6544905344645182, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 11:50:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 314.15545654296875, 'train_avg_loss': 0.6544905344645182, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 11:50:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 11:50:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:50:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:50:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:50:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.294800, avg_loss=0.673531, seen=480, correct=273, accuracy=0.568750
2025-10-10 11:50:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:50:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:50:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:50:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2288MB allocated=2074MB
2025-10-10 11:50:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.25189226865768, 'train_avg_loss': 0.7104324355721474, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 11:50:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.2947998046875, 'train_avg_loss': 0.6735308329264323, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 11:50:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 323.2947998046875, 'train_avg_loss': 0.6735308329264323, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 11:50:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:50:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:50:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:51:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:51:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.878174, avg_loss=0.689330, seen=480, correct=279, accuracy=0.581250
2025-10-10 11:51:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:51:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:51:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:51:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2292MB allocated=2074MB
2025-10-10 11:51:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49234384298325, 'train_avg_loss': 0.7041028653581937, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 11:51:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.878173828125, 'train_avg_loss': 0.6893295288085938, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 11:51:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 330.878173828125, 'train_avg_loss': 0.6893295288085938, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 11:51:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:51:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:51:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:52:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:52:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=259.105286, avg_loss=0.539803, seen=480, correct=357, accuracy=0.743750
2025-10-10 11:52:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:52:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:52:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:52:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2326MB allocated=2074MB
2025-10-10 11:52:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.92137551307678, 'train_avg_loss': 0.6076781292756398, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 11:52:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 259.10528564453125, 'train_avg_loss': 0.5398026784261067, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-10 11:52:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 259.10528564453125, 'train_avg_loss': 0.5398026784261067, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-10 11:52:14 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #137) -------------
2025-10-10 11:52:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=137 aidx=3 | s=5 (candidates=8)
2025-10-10 11:52:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 33, 4, 25, 42] (from 8)
2025-10-10 11:52:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:52:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:52:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 11:52:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:52:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:52:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:52:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:52:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:52:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:52:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:52:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.312622, avg_loss=0.704818, seen=480, correct=253, accuracy=0.527083
2025-10-10 11:52:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:52:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:52:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:52:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2288MB allocated=2074MB
2025-10-10 11:52:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.07374423742294, 'train_avg_loss': 0.7256145353118578, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 11:52:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.3126220703125, 'train_avg_loss': 0.7048179626464843, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 11:52:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 338.3126220703125, 'train_avg_loss': 0.7048179626464843, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 11:52:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:52:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:52:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 11:52:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:52:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:52:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:52:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:52:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:52:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:53:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:53:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.902832, avg_loss=0.695631, seen=480, correct=276, accuracy=0.575000
2025-10-10 11:53:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:53:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:53:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:53:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2292MB allocated=2074MB
2025-10-10 11:53:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.01154971122742, 'train_avg_loss': 0.7084295809268951, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 11:53:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.90283203125, 'train_avg_loss': 0.6956309000651042, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 11:53:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 333.90283203125, 'train_avg_loss': 0.6956309000651042, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 11:53:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:53:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:53:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 11:53:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:53:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:53:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:53:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:53:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:53:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:54:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:54:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=242.122803, avg_loss=0.504423, seen=480, correct=369, accuracy=0.768750
2025-10-10 11:54:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:54:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:54:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:54:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2326MB allocated=2074MB
2025-10-10 11:54:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.0526792705059, 'train_avg_loss': 0.5837723272542159, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 11:54:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 242.122802734375, 'train_avg_loss': 0.5044225056966146, 'train_seen': 480, 'train_correct': 369, 'train_acc': 0.76875}}
2025-10-10 11:54:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 242.122802734375, 'train_avg_loss': 0.5044225056966146, 'train_seen': 480, 'train_correct': 369, 'train_acc': 0.76875}}
2025-10-10 11:54:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:54:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:54:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 11:54:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:54:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:54:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:54:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:54:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:54:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:54:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:54:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.716980, avg_loss=0.693160, seen=480, correct=275, accuracy=0.572917
2025-10-10 11:54:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:54:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:54:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:54:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2288MB allocated=2074MB
2025-10-10 11:54:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.47044456005096, 'train_avg_loss': 0.6955870380004247, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 11:54:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.71697998046875, 'train_avg_loss': 0.6931603749593099, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 11:54:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 332.71697998046875, 'train_avg_loss': 0.6931603749593099, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 11:54:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:54:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:54:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:55:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:55:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.643555, avg_loss=0.661757, seen=480, correct=293, accuracy=0.610417
2025-10-10 11:55:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:55:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:55:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:55:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2308MB allocated=2074MB
2025-10-10 11:55:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.81662636995316, 'train_avg_loss': 0.640138553082943, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 11:55:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.6435546875, 'train_avg_loss': 0.6617574055989583, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 11:55:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 317.6435546875, 'train_avg_loss': 0.6617574055989583, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 11:55:29 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #138) -------------
2025-10-10 11:55:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=138 aidx=3 | s=5 (candidates=8)
2025-10-10 11:55:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 33, 24, 44, 42] (from 8)
2025-10-10 11:55:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 11:55:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:55:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:56:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:56:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=245.969803, avg_loss=0.512437, seen=480, correct=366, accuracy=0.762500
2025-10-10 11:56:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:56:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:56:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:56:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2326MB allocated=2074MB
2025-10-10 11:56:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.34315817058086, 'train_avg_loss': 0.5861929847548405, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 11:56:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 245.9698028564453, 'train_avg_loss': 0.512437089284261, 'train_seen': 480, 'train_correct': 366, 'train_acc': 0.7625}}
2025-10-10 11:56:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 245.9698028564453, 'train_avg_loss': 0.512437089284261, 'train_seen': 480, 'train_correct': 366, 'train_acc': 0.7625}}
2025-10-10 11:56:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 11:56:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:56:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:56:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:56:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.515900, avg_loss=0.686491, seen=480, correct=284, accuracy=0.591667
2025-10-10 11:56:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:56:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:56:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:56:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2292MB allocated=2074MB
2025-10-10 11:56:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.16768950223923, 'train_avg_loss': 0.6930640791853269, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 11:56:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5158996582031, 'train_avg_loss': 0.6864914576212565, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 11:56:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 329.5158996582031, 'train_avg_loss': 0.6864914576212565, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 11:56:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:56:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:56:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 11:56:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 11:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:56:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:56:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:56:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:56:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:57:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:57:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.793304, avg_loss=0.703736, seen=480, correct=257, accuracy=0.535417
2025-10-10 11:57:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:57:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:57:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:57:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2288MB allocated=2074MB
2025-10-10 11:57:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.80417656898499, 'train_avg_loss': 0.7233681380748749, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 11:57:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.7933044433594, 'train_avg_loss': 0.7037360509236653, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 11:57:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 337.7933044433594, 'train_avg_loss': 0.7037360509236653, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 11:57:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 11:57:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:57:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:58:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:58:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.205841, avg_loss=0.644179, seen=480, correct=300, accuracy=0.625000
2025-10-10 11:58:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:58:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:58:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:58:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2288MB allocated=2074MB
2025-10-10 11:58:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.2082587480545, 'train_avg_loss': 0.5934021562337876, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 11:58:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.2058410644531, 'train_avg_loss': 0.644178835550944, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 11:58:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 309.2058410644531, 'train_avg_loss': 0.644178835550944, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 11:58:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:58:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:58:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 11:58:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:58:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:58:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:58:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:58:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:58:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:58:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:58:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.710083, avg_loss=0.643146, seen=480, correct=303, accuracy=0.631250
2025-10-10 11:58:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:58:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:58:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:58:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2308MB allocated=2074MB
2025-10-10 11:58:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.5965319275856, 'train_avg_loss': 0.6216377660632133, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 11:58:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.7100830078125, 'train_avg_loss': 0.643146006266276, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 11:58:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 308.7100830078125, 'train_avg_loss': 0.643146006266276, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 11:58:49 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #139) -------------
2025-10-10 11:58:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=139 aidx=3 | s=5 (candidates=8)
2025-10-10 11:58:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 25, 44, 33, 27] (from 8)
2025-10-10 11:58:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 11:58:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:58:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 11:59:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 11:59:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.661377, avg_loss=0.632628, seen=480, correct=305, accuracy=0.635417
2025-10-10 11:59:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 11:59:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:59:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 11:59:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2308MB allocated=2074MB
2025-10-10 11:59:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.34446901082993, 'train_avg_loss': 0.6112039084235827, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 11:59:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.661376953125, 'train_avg_loss': 0.6326278686523438, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 11:59:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 303.661376953125, 'train_avg_loss': 0.6326278686523438, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 11:59:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 11:59:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 11:59:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:00:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:00:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.027008, avg_loss=0.695890, seen=480, correct=278, accuracy=0.579167
2025-10-10 12:00:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:00:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:00:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:00:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2288MB allocated=2074MB
2025-10-10 12:00:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.09842205047607, 'train_avg_loss': 0.7008201837539673, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:00:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0270080566406, 'train_avg_loss': 0.6958896001180013, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 12:00:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 334.0270080566406, 'train_avg_loss': 0.6958896001180013, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 12:00:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 12:00:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:00:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:00:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:00:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.821289, avg_loss=0.643378, seen=480, correct=304, accuracy=0.633333
2025-10-10 12:00:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:00:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:00:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:00:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2288MB allocated=2074MB
2025-10-10 12:00:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.40624934434891, 'train_avg_loss': 0.5950520778695743, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 12:00:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.8212890625, 'train_avg_loss': 0.643377685546875, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 12:00:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 308.8212890625, 'train_avg_loss': 0.643377685546875, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 12:00:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 12:00:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:00:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:01:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:01:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.826599, avg_loss=0.691305, seen=480, correct=283, accuracy=0.589583
2025-10-10 12:01:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:01:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:01:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:01:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2292MB allocated=2074MB
2025-10-10 12:01:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.21493059396744, 'train_avg_loss': 0.701791088283062, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 12:01:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.82659912109375, 'train_avg_loss': 0.691305414835612, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 12:01:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 331.82659912109375, 'train_avg_loss': 0.691305414835612, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 12:01:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:01:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:01:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 12:01:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 12:01:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:01:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:01:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:01:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:01:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:02:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:02:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.013214, avg_loss=0.695861, seen=480, correct=263, accuracy=0.547917
2025-10-10 12:02:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:02:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:02:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:02:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2292MB allocated=2074MB
2025-10-10 12:02:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.58349883556366, 'train_avg_loss': 0.7048624902963638, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 12:02:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0132141113281, 'train_avg_loss': 0.6958608627319336, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:02:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 334.0132141113281, 'train_avg_loss': 0.6958608627319336, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:02:05 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #140) -------------
2025-10-10 12:02:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=140 aidx=3 | s=5 (candidates=8)
2025-10-10 12:02:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 25, 24, 4, 30] (from 8)
2025-10-10 12:02:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:02:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:02:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 12:02:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 12:02:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:02:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:02:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:02:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:02:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:02:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:02:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.974762, avg_loss=0.679114, seen=480, correct=279, accuracy=0.581250
2025-10-10 12:02:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:02:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:02:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:02:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2292MB allocated=2074MB
2025-10-10 12:02:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17865234613419, 'train_avg_loss': 0.6848221028844516, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 12:02:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.9747619628906, 'train_avg_loss': 0.6791140874226888, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 12:02:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 325.9747619628906, 'train_avg_loss': 0.6791140874226888, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 12:02:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:02:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:02:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 12:02:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 12:02:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:02:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:02:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:02:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:02:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:03:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:03:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.705353, avg_loss=0.686886, seen=480, correct=277, accuracy=0.577083
2025-10-10 12:03:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:03:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:03:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:03:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2288MB allocated=2074MB
2025-10-10 12:03:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3551994562149, 'train_avg_loss': 0.6946266621351243, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:03:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7053527832031, 'train_avg_loss': 0.6868861516316732, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 12:03:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 329.7053527832031, 'train_avg_loss': 0.6868861516316732, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 12:03:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 12:03:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:03:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:04:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:04:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.167755, avg_loss=0.700349, seen=480, correct=253, accuracy=0.527083
2025-10-10 12:04:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:04:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:04:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:04:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2288MB allocated=2074MB
2025-10-10 12:04:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.43086153268814, 'train_avg_loss': 0.7119238461057346, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:04:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.1677551269531, 'train_avg_loss': 0.700349489847819, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:04:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 336.1677551269531, 'train_avg_loss': 0.700349489847819, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:04:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 12:04:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:04:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:04:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:04:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=251.918549, avg_loss=0.524830, seen=480, correct=370, accuracy=0.770833
2025-10-10 12:04:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:04:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:04:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:04:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2326MB allocated=2074MB
2025-10-10 12:04:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.51381601393223, 'train_avg_loss': 0.5876151334494353, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 12:04:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 251.91854858398438, 'train_avg_loss': 0.5248303095499675, 'train_seen': 480, 'train_correct': 370, 'train_acc': 0.7708333333333334}}
2025-10-10 12:04:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 251.91854858398438, 'train_avg_loss': 0.5248303095499675, 'train_seen': 480, 'train_correct': 370, 'train_acc': 0.7708333333333334}}
2025-10-10 12:04:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 12:04:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:04:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:05:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:05:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.502472, avg_loss=0.663547, seen=480, correct=280, accuracy=0.583333
2025-10-10 12:05:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:05:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:05:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:05:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2288MB allocated=2074MB
2025-10-10 12:05:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49042296409607, 'train_avg_loss': 0.6957535247008005, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:05:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.5024719238281, 'train_avg_loss': 0.6635468165079753, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 12:05:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 318.5024719238281, 'train_avg_loss': 0.6635468165079753, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 12:05:20 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #141) -------------
2025-10-10 12:05:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=141 aidx=3 | s=5 (candidates=8)
2025-10-10 12:05:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 4, 27, 30, 24] (from 8)
2025-10-10 12:05:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 12:05:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:05:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:05:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:05:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.954956, avg_loss=0.633239, seen=480, correct=310, accuracy=0.645833
2025-10-10 12:05:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:05:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:06:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:06:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2308MB allocated=2074MB
2025-10-10 12:06:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.68638795614243, 'train_avg_loss': 0.6057198996345202, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 12:06:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.9549560546875, 'train_avg_loss': 0.6332394917805989, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 12:06:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 303.9549560546875, 'train_avg_loss': 0.6332394917805989, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 12:06:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:06:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:06:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 12:06:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 12:06:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:06:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:06:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:06:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:06:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:06:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:06:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=252.157593, avg_loss=0.525328, seen=480, correct=369, accuracy=0.768750
2025-10-10 12:06:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:06:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:06:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:06:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2326MB allocated=2074MB
2025-10-10 12:06:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.8774428665638, 'train_avg_loss': 0.5823120238880316, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 12:06:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 252.1575927734375, 'train_avg_loss': 0.5253283182779948, 'train_seen': 480, 'train_correct': 369, 'train_acc': 0.76875}}
2025-10-10 12:06:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 252.1575927734375, 'train_avg_loss': 0.5253283182779948, 'train_seen': 480, 'train_correct': 369, 'train_acc': 0.76875}}
2025-10-10 12:06:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:06:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:06:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 12:06:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 12:06:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:06:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:06:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:06:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:06:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:07:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:07:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.084503, avg_loss=0.675176, seen=480, correct=273, accuracy=0.568750
2025-10-10 12:07:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:07:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:07:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:07:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2292MB allocated=2074MB
2025-10-10 12:07:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.14158964157104, 'train_avg_loss': 0.6761799136797587, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 12:07:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0845031738281, 'train_avg_loss': 0.6751760482788086, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 12:07:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 324.0845031738281, 'train_avg_loss': 0.6751760482788086, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 12:07:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:07:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:07:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 12:07:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 12:07:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:07:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:07:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:07:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:07:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:07:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:07:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.929077, avg_loss=0.651936, seen=480, correct=282, accuracy=0.587500
2025-10-10 12:07:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:07:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:07:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:07:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2288MB allocated=2074MB
2025-10-10 12:07:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88872933387756, 'train_avg_loss': 0.682406077782313, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 12:07:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.9290771484375, 'train_avg_loss': 0.6519355773925781, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 12:07:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 312.9290771484375, 'train_avg_loss': 0.6519355773925781, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 12:07:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 12:07:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:07:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:08:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:08:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.578674, avg_loss=0.701206, seen=480, correct=248, accuracy=0.516667
2025-10-10 12:08:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:08:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:08:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:08:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2288MB allocated=2074MB
2025-10-10 12:08:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.78684729337692, 'train_avg_loss': 0.7148903941114744, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 12:08:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.57867431640625, 'train_avg_loss': 0.7012055714925131, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:08:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 336.57867431640625, 'train_avg_loss': 0.7012055714925131, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:08:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #142) -------------
2025-10-10 12:08:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=142 aidx=3 | s=5 (candidates=8)
2025-10-10 12:08:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 24, 42, 30, 33] (from 8)
2025-10-10 12:08:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 12:08:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:08:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:09:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:09:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.498108, avg_loss=0.673954, seen=480, correct=275, accuracy=0.572917
2025-10-10 12:09:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:09:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:09:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:09:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2292MB allocated=2074MB
2025-10-10 12:09:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.71278703212738, 'train_avg_loss': 0.6726065586010616, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:09:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.49810791015625, 'train_avg_loss': 0.6739543914794922, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:09:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 323.49810791015625, 'train_avg_loss': 0.6739543914794922, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:09:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:09:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:09:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 12:09:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 12:09:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:09:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:09:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:09:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:09:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:09:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:09:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.810577, avg_loss=0.687105, seen=480, correct=262, accuracy=0.545833
2025-10-10 12:09:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:09:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:09:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:09:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2288MB allocated=2074MB
2025-10-10 12:09:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.22933620214462, 'train_avg_loss': 0.7019111350178718, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 12:09:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8105773925781, 'train_avg_loss': 0.687105369567871, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:09:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 329.8105773925781, 'train_avg_loss': 0.687105369567871, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:09:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 12:09:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:09:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:10:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:10:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.678467, avg_loss=0.634747, seen=480, correct=308, accuracy=0.641667
2025-10-10 12:10:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:10:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:10:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:10:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2308MB allocated=2074MB
2025-10-10 12:10:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.89679861068726, 'train_avg_loss': 0.6158066550890605, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 12:10:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.678466796875, 'train_avg_loss': 0.634746805826823, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 12:10:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 304.678466796875, 'train_avg_loss': 0.634746805826823, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 12:10:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 12:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:10:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:11:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:11:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.119507, avg_loss=0.658582, seen=480, correct=287, accuracy=0.597917
2025-10-10 12:11:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:11:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:11:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:11:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2288MB allocated=2074MB
2025-10-10 12:11:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.11760258674622, 'train_avg_loss': 0.6926466882228851, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:11:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.1195068359375, 'train_avg_loss': 0.6585823059082031, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 12:11:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 316.1195068359375, 'train_avg_loss': 0.6585823059082031, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 12:11:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 12:11:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:11:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:11:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:11:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.477051, avg_loss=0.678077, seen=480, correct=275, accuracy=0.572917
2025-10-10 12:11:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:11:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:11:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:11:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2292MB allocated=2074MB
2025-10-10 12:11:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.68007230758667, 'train_avg_loss': 0.6890006025632223, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:11:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.47705078125, 'train_avg_loss': 0.6780771891276042, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:11:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 325.47705078125, 'train_avg_loss': 0.6780771891276042, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:11:57 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #143) -------------
2025-10-10 12:11:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=143 aidx=3 | s=5 (candidates=8)
2025-10-10 12:11:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 44, 4, 30, 25] (from 8)
2025-10-10 12:11:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 12:11:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:11:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:12:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:12:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.810822, avg_loss=0.637106, seen=480, correct=301, accuracy=0.627083
2025-10-10 12:12:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:12:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:12:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:12:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2308MB allocated=2074MB
2025-10-10 12:12:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.68118566274643, 'train_avg_loss': 0.614009880522887, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 12:12:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.8108215332031, 'train_avg_loss': 0.6371058781941732, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 12:12:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 305.8108215332031, 'train_avg_loss': 0.6371058781941732, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 12:12:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 12:12:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:12:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:13:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:13:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.177185, avg_loss=0.650369, seen=480, correct=297, accuracy=0.618750
2025-10-10 12:13:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:13:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:13:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:13:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2288MB allocated=2074MB
2025-10-10 12:13:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.13447451591492, 'train_avg_loss': 0.6177872876326244, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 12:13:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.17718505859375, 'train_avg_loss': 0.650369135538737, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 12:13:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 312.17718505859375, 'train_avg_loss': 0.650369135538737, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 12:13:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 12:13:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:13:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:13:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:13:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=262.222198, avg_loss=0.546296, seen=480, correct=370, accuracy=0.770833
2025-10-10 12:13:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:13:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:13:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:13:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2326MB allocated=2074MB
2025-10-10 12:13:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.14556297659874, 'train_avg_loss': 0.5845463581383228, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 12:13:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 262.2221984863281, 'train_avg_loss': 0.5462962468465169, 'train_seen': 480, 'train_correct': 370, 'train_acc': 0.7708333333333334}}
2025-10-10 12:13:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 262.2221984863281, 'train_avg_loss': 0.5462962468465169, 'train_seen': 480, 'train_correct': 370, 'train_acc': 0.7708333333333334}}
2025-10-10 12:13:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 12:13:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:13:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:14:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:14:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.175629, avg_loss=0.660783, seen=480, correct=285, accuracy=0.593750
2025-10-10 12:14:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:14:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:14:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:14:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2288MB allocated=2074MB
2025-10-10 12:14:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.437429189682, 'train_avg_loss': 0.6869785765806834, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 12:14:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.1756286621094, 'train_avg_loss': 0.6607825597127278, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 12:14:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 317.1756286621094, 'train_avg_loss': 0.6607825597127278, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 12:14:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 12:14:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:14:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:15:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:15:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.598450, avg_loss=0.684580, seen=480, correct=271, accuracy=0.564583
2025-10-10 12:15:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:15:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:15:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:15:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2288MB allocated=2074MB
2025-10-10 12:15:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.30254399776459, 'train_avg_loss': 0.6858545333147049, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:15:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.59844970703125, 'train_avg_loss': 0.6845801035563152, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 12:15:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 328.59844970703125, 'train_avg_loss': 0.6845801035563152, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 12:15:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #144) -------------
2025-10-10 12:15:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=144 aidx=3 | s=5 (candidates=8)
2025-10-10 12:15:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 44, 4, 25, 24] (from 8)
2025-10-10 12:15:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 12:15:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:15:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:15:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:15:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.734894, avg_loss=0.676531, seen=480, correct=270, accuracy=0.562500
2025-10-10 12:15:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:15:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:15:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:15:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2294MB allocated=2074MB
2025-10-10 12:15:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.35222661495209, 'train_avg_loss': 0.6779352217912674, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 12:15:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7348937988281, 'train_avg_loss': 0.6765310287475585, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 12:15:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 324.7348937988281, 'train_avg_loss': 0.6765310287475585, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 12:15:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 12:16:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:16:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:16:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:16:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.317535, avg_loss=0.648578, seen=480, correct=301, accuracy=0.627083
2025-10-10 12:16:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:16:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:16:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:16:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2288MB allocated=2074MB
2025-10-10 12:16:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.05377101898193, 'train_avg_loss': 0.6254480918248494, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 12:16:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.3175354003906, 'train_avg_loss': 0.6485781987508138, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 12:16:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 311.3175354003906, 'train_avg_loss': 0.6485781987508138, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 12:16:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:16:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:16:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 12:16:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 12:16:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:16:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:16:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:16:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:16:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:17:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:17:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=266.718689, avg_loss=0.555664, seen=480, correct=368, accuracy=0.766667
2025-10-10 12:17:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:17:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:17:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:17:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2326MB allocated=2074MB
2025-10-10 12:17:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.11792051792145, 'train_avg_loss': 0.584316004316012, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 12:17:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 266.71868896484375, 'train_avg_loss': 0.5556639353434245, 'train_seen': 480, 'train_correct': 368, 'train_acc': 0.7666666666666667}}
2025-10-10 12:17:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 266.71868896484375, 'train_avg_loss': 0.5556639353434245, 'train_seen': 480, 'train_correct': 368, 'train_acc': 0.7666666666666667}}
2025-10-10 12:17:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 12:17:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:17:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:17:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:17:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.976807, avg_loss=0.674952, seen=480, correct=275, accuracy=0.572917
2025-10-10 12:17:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:17:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:17:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:17:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2288MB allocated=2074MB
2025-10-10 12:17:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.92734575271606, 'train_avg_loss': 0.6827278812726338, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 12:17:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.976806640625, 'train_avg_loss': 0.674951680501302, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:17:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 323.976806640625, 'train_avg_loss': 0.674951680501302, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 12:17:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 12:17:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:17:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:18:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:18:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.174713, avg_loss=0.687864, seen=480, correct=263, accuracy=0.547917
2025-10-10 12:18:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:18:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:18:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:18:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2288MB allocated=2074MB
2025-10-10 12:18:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12557744979858, 'train_avg_loss': 0.7010464787483215, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:18:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1747131347656, 'train_avg_loss': 0.6878639856974283, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:18:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 330.1747131347656, 'train_avg_loss': 0.6878639856974283, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:18:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #145) -------------
2025-10-10 12:18:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=145 aidx=4 | s=5 (candidates=17)
2025-10-10 12:18:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 38, 18, 17, 49] (from 17)
2025-10-10 12:18:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:18:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:18:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 12:18:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:18:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:18:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:18:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:18:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:18:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:19:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:19:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.572632, avg_loss=0.709526, seen=480, correct=264, accuracy=0.550000
2025-10-10 12:19:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:19:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:19:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:19:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2314MB allocated=2124MB
2025-10-10 12:19:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.09356755018234, 'train_avg_loss': 0.7091130629181862, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 12:19:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.5726318359375, 'train_avg_loss': 0.7095263163248698, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 12:19:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 340.5726318359375, 'train_avg_loss': 0.7095263163248698, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 12:19:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:19:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:19:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 12:19:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 12:19:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:19:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:19:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:19:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:19:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:19:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:19:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.611755, avg_loss=0.703358, seen=480, correct=255, accuracy=0.531250
2025-10-10 12:19:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:19:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:19:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:19:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2334MB allocated=2133MB
2025-10-10 12:19:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91165864467621, 'train_avg_loss': 0.6992638220389684, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:19:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.61175537109375, 'train_avg_loss': 0.7033578236897786, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 12:19:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 337.61175537109375, 'train_avg_loss': 0.7033578236897786, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 12:19:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 12:20:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:20:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:20:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:20:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.928467, avg_loss=0.712351, seen=480, correct=249, accuracy=0.518750
2025-10-10 12:20:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:20:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:20:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:20:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2370MB allocated=2141MB
2025-10-10 12:20:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.7931969165802, 'train_avg_loss': 0.7232766409715017, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:20:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.928466796875, 'train_avg_loss': 0.7123509724934896, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:20:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 341.928466796875, 'train_avg_loss': 0.7123509724934896, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:20:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:20:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:20:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 12:20:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:20:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:20:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:20:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:20:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:20:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:21:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:21:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.171387, avg_loss=0.710774, seen=480, correct=243, accuracy=0.506250
2025-10-10 12:21:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:21:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:21:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:21:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2368MB allocated=2150MB
2025-10-10 12:21:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.25888097286224, 'train_avg_loss': 0.7271573414405187, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 12:21:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.17138671875, 'train_avg_loss': 0.7107737223307292, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 12:21:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 341.17138671875, 'train_avg_loss': 0.7107737223307292, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 12:21:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:21:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:21:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 12:21:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 12:21:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:21:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:21:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:21:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:21:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:21:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:21:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=350.661072, avg_loss=0.730544, seen=480, correct=237, accuracy=0.493750
2025-10-10 12:21:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:21:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:21:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:21:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2368MB allocated=2158MB
2025-10-10 12:21:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 91.6601870059967, 'train_avg_loss': 0.7638348917166392, 'train_seen': 120, 'train_correct': 48, 'train_acc': 0.4}}
2025-10-10 12:21:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 350.66107177734375, 'train_avg_loss': 0.7305438995361329, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 12:21:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 350.66107177734375, 'train_avg_loss': 0.7305438995361329, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 12:21:57 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #146) -------------
2025-10-10 12:21:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=146 aidx=4 | s=5 (candidates=17)
2025-10-10 12:21:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 19, 13, 39, 17] (from 17)
2025-10-10 12:21:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:21:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:21:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 12:22:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 12:22:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:22:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:22:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:22:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:22:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:22:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:22:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.907928, avg_loss=0.701892, seen=480, correct=247, accuracy=0.514583
2025-10-10 12:22:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:22:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:22:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:22:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2372MB allocated=2209MB
2025-10-10 12:22:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.79399913549423, 'train_avg_loss': 0.6982833261291186, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:22:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9079284667969, 'train_avg_loss': 0.7018915176391601, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:22:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 336.9079284667969, 'train_avg_loss': 0.7018915176391601, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:22:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:22:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:22:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 12:22:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 12:22:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:22:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:22:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:22:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:22:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:23:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:23:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.359680, avg_loss=0.704916, seen=480, correct=244, accuracy=0.508333
2025-10-10 12:23:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:23:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:23:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:23:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2428MB allocated=2217MB
2025-10-10 12:23:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.63617253303528, 'train_avg_loss': 0.7136347711086273, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 12:23:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.35968017578125, 'train_avg_loss': 0.7049160003662109, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 12:23:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 338.35968017578125, 'train_avg_loss': 0.7049160003662109, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 12:23:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 12:23:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:23:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:23:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:23:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.867676, avg_loss=0.703891, seen=480, correct=247, accuracy=0.514583
2025-10-10 12:23:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:23:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:23:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:24:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2360MB allocated=2225MB
2025-10-10 12:24:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.95636063814163, 'train_avg_loss': 0.6996363386511802, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 12:24:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.86767578125, 'train_avg_loss': 0.7038909912109375, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:24:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 337.86767578125, 'train_avg_loss': 0.7038909912109375, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:24:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:24:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:24:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 12:24:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 12:24:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:24:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:24:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:24:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:24:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:24:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:24:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.149170, avg_loss=0.706561, seen=480, correct=247, accuracy=0.514583
2025-10-10 12:24:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:24:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:24:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:24:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2358MB allocated=2234MB
2025-10-10 12:24:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.47008103132248, 'train_avg_loss': 0.7122506752610207, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:24:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.149169921875, 'train_avg_loss': 0.7065607706705729, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:24:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 339.149169921875, 'train_avg_loss': 0.7065607706705729, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:24:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:24:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:24:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 12:24:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:24:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:24:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:24:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:24:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:24:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:25:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:25:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.811279, avg_loss=0.705857, seen=480, correct=251, accuracy=0.522917
2025-10-10 12:25:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:25:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:25:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:25:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2362MB allocated=2192MB
2025-10-10 12:25:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.71128076314926, 'train_avg_loss': 0.7059273396929105, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:25:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.811279296875, 'train_avg_loss': 0.7058568318684896, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 12:25:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 338.811279296875, 'train_avg_loss': 0.7058568318684896, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 12:25:20 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #147) -------------
2025-10-10 12:25:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=147 aidx=4 | s=5 (candidates=17)
2025-10-10 12:25:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 23, 38, 49, 35] (from 17)
2025-10-10 12:25:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:25:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:25:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 12:25:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 12:25:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:25:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:25:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:25:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:25:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:26:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:26:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.477478, avg_loss=0.698911, seen=480, correct=243, accuracy=0.506250
2025-10-10 12:26:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:26:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:26:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:26:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2342MB allocated=2201MB
2025-10-10 12:26:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.31786000728607, 'train_avg_loss': 0.7109821667273839, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 12:26:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.47747802734375, 'train_avg_loss': 0.6989114125569661, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 12:26:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 335.47747802734375, 'train_avg_loss': 0.6989114125569661, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 12:26:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:26:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:26:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 12:26:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:26:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:26:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:26:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:26:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:26:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:26:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:26:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.299103, avg_loss=0.702706, seen=480, correct=253, accuracy=0.527083
2025-10-10 12:26:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:26:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:26:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:26:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2288MB allocated=2159MB
2025-10-10 12:26:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.79605507850647, 'train_avg_loss': 0.7066337923208873, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:26:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.2991027832031, 'train_avg_loss': 0.7027064641316731, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:26:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 337.2991027832031, 'train_avg_loss': 0.7027064641316731, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:26:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 12:26:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:26:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:27:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:27:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.375000, avg_loss=0.690365, seen=480, correct=269, accuracy=0.560417
2025-10-10 12:27:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:27:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:27:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:27:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2310MB allocated=2159MB
2025-10-10 12:27:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.11296021938324, 'train_avg_loss': 0.6842746684948603, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:27:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.375, 'train_avg_loss': 0.6903645833333333, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 12:27:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 331.375, 'train_avg_loss': 0.6903645833333333, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 12:27:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 12:27:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:27:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:28:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:28:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.767700, avg_loss=0.703683, seen=480, correct=237, accuracy=0.493750
2025-10-10 12:28:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:28:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:28:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:28:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2326MB allocated=2159MB
2025-10-10 12:28:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.58177578449249, 'train_avg_loss': 0.7131814648707707, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 12:28:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.7677001953125, 'train_avg_loss': 0.7036827087402344, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 12:28:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 337.7677001953125, 'train_avg_loss': 0.7036827087402344, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 12:28:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:28:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:28:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 12:28:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 12:28:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:28:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:28:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:28:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:28:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:28:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:28:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.239502, avg_loss=0.704666, seen=480, correct=241, accuracy=0.502083
2025-10-10 12:28:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:28:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:28:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:28:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2358MB allocated=2209MB
2025-10-10 12:28:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.60988390445709, 'train_avg_loss': 0.7050823658704758, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:28:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.239501953125, 'train_avg_loss': 0.7046656290690104, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 12:28:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 338.239501953125, 'train_avg_loss': 0.7046656290690104, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 12:28:52 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #148) -------------
2025-10-10 12:28:52 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=148 aidx=4 | s=5 (candidates=17)
2025-10-10 12:28:52 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 46, 39, 17, 23] (from 17)
2025-10-10 12:28:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:28:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:28:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 12:28:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 12:28:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:28:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:28:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:28:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:28:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:29:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:29:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.473328, avg_loss=0.694736, seen=480, correct=242, accuracy=0.504167
2025-10-10 12:29:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:29:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:29:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:29:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2382MB allocated=2259MB
2025-10-10 12:29:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.70482182502747, 'train_avg_loss': 0.7058735152085622, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 12:29:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.47332763671875, 'train_avg_loss': 0.694736099243164, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:29:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 333.47332763671875, 'train_avg_loss': 0.694736099243164, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:29:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:29:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:29:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 12:29:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 12:29:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:29:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:29:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:29:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:29:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:30:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:30:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.085876, avg_loss=0.696012, seen=480, correct=247, accuracy=0.514583
2025-10-10 12:30:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:30:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:30:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:30:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2392MB allocated=2268MB
2025-10-10 12:30:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.71071529388428, 'train_avg_loss': 0.714255960782369, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 12:30:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.08587646484375, 'train_avg_loss': 0.6960122426350911, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:30:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 334.08587646484375, 'train_avg_loss': 0.6960122426350911, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:30:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 12:30:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:30:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:30:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:30:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.474274, avg_loss=0.696821, seen=480, correct=268, accuracy=0.558333
2025-10-10 12:30:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:30:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:30:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:30:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2332MB allocated=2226MB
2025-10-10 12:30:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5376700758934, 'train_avg_loss': 0.696147250632445, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 12:30:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4742736816406, 'train_avg_loss': 0.6968214035034179, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 12:30:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 334.4742736816406, 'train_avg_loss': 0.6968214035034179, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 12:30:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:31:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:31:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:31:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:31:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.473328, avg_loss=0.692653, seen=480, correct=259, accuracy=0.539583
2025-10-10 12:31:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:31:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:31:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:31:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2368MB allocated=2226MB
2025-10-10 12:31:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.47811686992645, 'train_avg_loss': 0.6956509739160538, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:31:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.47332763671875, 'train_avg_loss': 0.6926527659098307, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:31:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 332.47332763671875, 'train_avg_loss': 0.6926527659098307, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:31:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:31:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:31:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 12:31:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:31:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:31:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:31:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:31:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:31:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:32:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:32:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.171692, avg_loss=0.700358, seen=480, correct=262, accuracy=0.545833
2025-10-10 12:32:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:32:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:32:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:32:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2332MB allocated=2226MB
2025-10-10 12:32:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.27534413337708, 'train_avg_loss': 0.7022945344448089, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:32:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.17169189453125, 'train_avg_loss': 0.7003576914469402, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:32:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 336.17169189453125, 'train_avg_loss': 0.7003576914469402, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:32:22 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #149) -------------
2025-10-10 12:32:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=149 aidx=4 | s=5 (candidates=17)
2025-10-10 12:32:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 9, 10, 12, 14] (from 17)
2025-10-10 12:32:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 12:32:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:32:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:33:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:33:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.100525, avg_loss=0.698126, seen=480, correct=242, accuracy=0.504167
2025-10-10 12:33:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:33:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:33:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:33:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2314MB allocated=2184MB
2025-10-10 12:33:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.23527228832245, 'train_avg_loss': 0.7102939357360204, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 12:33:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.10052490234375, 'train_avg_loss': 0.6981260935465495, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:33:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 335.10052490234375, 'train_avg_loss': 0.6981260935465495, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:33:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:33:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:33:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 12:33:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 12:33:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:33:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:33:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:33:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:33:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:33:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:33:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.078796, avg_loss=0.691831, seen=480, correct=236, accuracy=0.491667
2025-10-10 12:33:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:33:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:33:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:33:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2294MB allocated=2184MB
2025-10-10 12:33:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.60934591293335, 'train_avg_loss': 0.6967445492744446, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 12:33:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.07879638671875, 'train_avg_loss': 0.691830825805664, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 12:33:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 332.07879638671875, 'train_avg_loss': 0.691830825805664, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 12:33:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:33:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:33:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 12:33:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 12:33:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:33:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:33:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:33:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:33:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:34:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:34:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.176270, avg_loss=0.692034, seen=480, correct=246, accuracy=0.512500
2025-10-10 12:34:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:34:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:34:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:34:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2342MB allocated=2234MB
2025-10-10 12:34:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.99786972999573, 'train_avg_loss': 0.691648914416631, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:34:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.17626953125, 'train_avg_loss': 0.6920338948567708, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:34:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 332.17626953125, 'train_avg_loss': 0.6920338948567708, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:34:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:34:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:34:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 12:34:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 12:34:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:34:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:34:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:34:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:34:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:35:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:35:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.976288, avg_loss=0.697867, seen=480, correct=240, accuracy=0.500000
2025-10-10 12:35:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:35:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:35:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:35:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2328MB allocated=2242MB
2025-10-10 12:35:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.21762198209763, 'train_avg_loss': 0.7018135165174803, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 12:35:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9762878417969, 'train_avg_loss': 0.6978672663370769, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 12:35:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 334.9762878417969, 'train_avg_loss': 0.6978672663370769, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 12:35:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 12:35:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:35:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:35:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:35:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.114075, avg_loss=0.706488, seen=480, correct=245, accuracy=0.510417
2025-10-10 12:35:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:35:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:35:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:35:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2314MB allocated=2251MB
2025-10-10 12:35:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.062107026577, 'train_avg_loss': 0.6921842252214749, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 12:35:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.11407470703125, 'train_avg_loss': 0.7064876556396484, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 12:35:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 339.11407470703125, 'train_avg_loss': 0.7064876556396484, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 12:35:48 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #150) -------------
2025-10-10 12:35:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=150 aidx=4 | s=5 (candidates=17)
2025-10-10 12:35:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 12, 17, 39, 13] (from 17)
2025-10-10 12:35:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:35:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:35:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:36:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:36:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.674011, avg_loss=0.707654, seen=480, correct=235, accuracy=0.489583
2025-10-10 12:36:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:36:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:36:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:36:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2332MB allocated=2251MB
2025-10-10 12:36:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.31029164791107, 'train_avg_loss': 0.7109190970659256, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 12:36:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.67401123046875, 'train_avg_loss': 0.7076541900634765, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 12:36:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 339.67401123046875, 'train_avg_loss': 0.7076541900634765, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 12:36:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 12:36:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:36:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:37:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:37:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.852386, avg_loss=0.710109, seen=480, correct=232, accuracy=0.483333
2025-10-10 12:37:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:37:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:37:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:37:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2338MB allocated=2251MB
2025-10-10 12:37:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.92586308717728, 'train_avg_loss': 0.7160488590598106, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 12:37:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.8523864746094, 'train_avg_loss': 0.7101091384887696, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 12:37:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 340.8523864746094, 'train_avg_loss': 0.7101091384887696, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 12:37:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:37:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:37:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:37:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:37:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.980682, avg_loss=0.702043, seen=480, correct=248, accuracy=0.516667
2025-10-10 12:37:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:37:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:37:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:37:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2364MB allocated=2251MB
2025-10-10 12:37:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.98606377840042, 'train_avg_loss': 0.6915505314866702, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:37:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9806823730469, 'train_avg_loss': 0.702043088277181, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:37:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 336.9806823730469, 'train_avg_loss': 0.702043088277181, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:37:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 12:37:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:37:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:38:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:38:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.274658, avg_loss=0.696406, seen=480, correct=256, accuracy=0.533333
2025-10-10 12:38:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:38:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:38:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:38:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2332MB allocated=2251MB
2025-10-10 12:38:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.44100594520569, 'train_avg_loss': 0.7036750495433808, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 12:38:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.274658203125, 'train_avg_loss': 0.696405537923177, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:38:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 334.274658203125, 'train_avg_loss': 0.696405537923177, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:38:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:38:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:38:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 12:38:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 12:38:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:38:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:38:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:38:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:38:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:39:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:39:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.933411, avg_loss=0.708195, seen=480, correct=242, accuracy=0.504167
2025-10-10 12:39:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:39:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:39:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:39:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2336MB allocated=2251MB
2025-10-10 12:39:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.02949512004852, 'train_avg_loss': 0.7085791260004044, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:39:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.93341064453125, 'train_avg_loss': 0.7081946055094401, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:39:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 339.93341064453125, 'train_avg_loss': 0.7081946055094401, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 12:39:12 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #151) -------------
2025-10-10 12:39:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=151 aidx=4 | s=5 (candidates=17)
2025-10-10 12:39:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 35, 13, 52, 53] (from 17)
2025-10-10 12:39:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:39:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:39:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 12:39:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 12:39:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:39:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:39:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:39:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:39:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:39:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:39:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.907806, avg_loss=0.695641, seen=480, correct=247, accuracy=0.514583
2025-10-10 12:39:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:39:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:39:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:39:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2328MB allocated=2209MB
2025-10-10 12:39:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.58095467090607, 'train_avg_loss': 0.7048412889242173, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 12:39:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9078063964844, 'train_avg_loss': 0.6956412633260091, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:39:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 333.9078063964844, 'train_avg_loss': 0.6956412633260091, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 12:39:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 12:39:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:39:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:40:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:40:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.756683, avg_loss=0.691160, seen=480, correct=263, accuracy=0.547917
2025-10-10 12:40:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:40:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:40:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:40:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2336MB allocated=2209MB
2025-10-10 12:40:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.09119427204132, 'train_avg_loss': 0.6924266189336776, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 12:40:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7566833496094, 'train_avg_loss': 0.6911597569783529, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:40:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 331.7566833496094, 'train_avg_loss': 0.6911597569783529, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 12:40:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 12:40:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:40:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:41:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:41:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.602966, avg_loss=0.686673, seen=480, correct=256, accuracy=0.533333
2025-10-10 12:41:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:41:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:41:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:41:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2292MB allocated=2209MB
2025-10-10 12:41:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.04002940654755, 'train_avg_loss': 0.6836669117212295, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:41:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.60296630859375, 'train_avg_loss': 0.6866728464762369, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:41:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 329.60296630859375, 'train_avg_loss': 0.6866728464762369, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:41:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:41:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:41:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 12:41:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 12:41:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:41:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:41:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:41:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:41:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:41:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:41:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.995392, avg_loss=0.689574, seen=480, correct=254, accuracy=0.529167
2025-10-10 12:41:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:41:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:41:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:42:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2318MB allocated=2259MB
2025-10-10 12:42:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78262948989868, 'train_avg_loss': 0.6815219124158224, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:42:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9953918457031, 'train_avg_loss': 0.6895737330118815, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 12:42:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 330.9953918457031, 'train_avg_loss': 0.6895737330118815, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 12:42:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:42:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:42:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 12:42:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 12:42:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:42:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:42:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:42:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:42:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:42:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:42:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.038727, avg_loss=0.693831, seen=480, correct=238, accuracy=0.495833
2025-10-10 12:42:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:42:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:42:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:42:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2294MB allocated=2217MB
2025-10-10 12:42:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.20477426052094, 'train_avg_loss': 0.6933731188376745, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 12:42:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0387268066406, 'train_avg_loss': 0.6938306808471679, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 12:42:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 333.0387268066406, 'train_avg_loss': 0.6938306808471679, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 12:42:41 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #152) -------------
2025-10-10 12:42:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=152 aidx=4 | s=5 (candidates=17)
2025-10-10 12:42:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 19, 17, 35, 9] (from 17)
2025-10-10 12:42:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 12:42:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:42:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:43:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:43:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.552429, avg_loss=0.696984, seen=480, correct=261, accuracy=0.543750
2025-10-10 12:43:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:43:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:43:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:43:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2288MB allocated=2217MB
2025-10-10 12:43:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45953834056854, 'train_avg_loss': 0.6788294861714045, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 12:43:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.55242919921875, 'train_avg_loss': 0.6969842274983724, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 12:43:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 334.55242919921875, 'train_avg_loss': 0.6969842274983724, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 12:43:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 12:43:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:43:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:43:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:43:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.066437, avg_loss=0.691805, seen=480, correct=249, accuracy=0.518750
2025-10-10 12:43:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:43:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:44:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:44:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2344MB allocated=2217MB
2025-10-10 12:44:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45071923732758, 'train_avg_loss': 0.6787559936443964, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 12:44:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0664367675781, 'train_avg_loss': 0.691805076599121, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:44:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 332.0664367675781, 'train_avg_loss': 0.691805076599121, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:44:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:44:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:44:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 12:44:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:44:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:44:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:44:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:44:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:44:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:44:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:44:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.524475, avg_loss=0.688593, seen=480, correct=259, accuracy=0.539583
2025-10-10 12:44:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:44:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:44:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:44:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2314MB allocated=2217MB
2025-10-10 12:44:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.10024189949036, 'train_avg_loss': 0.7008353491624196, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 12:44:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.52447509765625, 'train_avg_loss': 0.6885926564534505, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:44:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 330.52447509765625, 'train_avg_loss': 0.6885926564534505, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:44:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 12:44:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:44:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:45:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:45:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.063568, avg_loss=0.691799, seen=480, correct=259, accuracy=0.539583
2025-10-10 12:45:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:45:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:45:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:45:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2336MB allocated=2217MB
2025-10-10 12:45:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.40190660953522, 'train_avg_loss': 0.6950158884127935, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:45:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0635681152344, 'train_avg_loss': 0.6917991002400716, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:45:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 332.0635681152344, 'train_avg_loss': 0.6917991002400716, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:45:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:45:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:45:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 12:45:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 12:45:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:45:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:45:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:45:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:45:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:46:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:46:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.845093, avg_loss=0.689261, seen=480, correct=251, accuracy=0.522917
2025-10-10 12:46:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:46:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:46:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:46:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2294MB allocated=2217MB
2025-10-10 12:46:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.67614448070526, 'train_avg_loss': 0.6973012040058771, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 12:46:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8450927734375, 'train_avg_loss': 0.6892606099446614, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 12:46:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 330.8450927734375, 'train_avg_loss': 0.6892606099446614, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 12:46:06 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #153) -------------
2025-10-10 12:46:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=153 aidx=4 | s=5 (candidates=17)
2025-10-10 12:46:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 18, 39, 12, 46] (from 17)
2025-10-10 12:46:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:46:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:46:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 12:46:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 12:46:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:46:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:46:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:46:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:46:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:46:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:46:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.245148, avg_loss=0.683844, seen=480, correct=246, accuracy=0.512500
2025-10-10 12:46:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:46:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:46:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:46:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2294MB allocated=2217MB
2025-10-10 12:46:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.23398751020432, 'train_avg_loss': 0.693616562585036, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 12:46:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2451477050781, 'train_avg_loss': 0.6838440577189128, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:46:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 328.2451477050781, 'train_avg_loss': 0.6838440577189128, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:46:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 12:46:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:46:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:47:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:47:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.229950, avg_loss=0.692146, seen=480, correct=240, accuracy=0.500000
2025-10-10 12:47:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:47:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:47:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:47:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2314MB allocated=2217MB
2025-10-10 12:47:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.39779877662659, 'train_avg_loss': 0.7033149898052216, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 12:47:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.2299499511719, 'train_avg_loss': 0.6921457290649414, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 12:47:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 332.2299499511719, 'train_avg_loss': 0.6921457290649414, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 12:47:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:47:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:47:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 12:47:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 12:47:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:47:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:47:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:47:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:47:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:48:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:48:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.520020, avg_loss=0.692750, seen=480, correct=261, accuracy=0.543750
2025-10-10 12:48:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:48:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:48:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:48:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2288MB allocated=2217MB
2025-10-10 12:48:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.31367778778076, 'train_avg_loss': 0.6942806482315064, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 12:48:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.52001953125, 'train_avg_loss': 0.6927500406901042, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 12:48:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 332.52001953125, 'train_avg_loss': 0.6927500406901042, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 12:48:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 12:48:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:48:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:48:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:48:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.024231, avg_loss=0.693800, seen=480, correct=244, accuracy=0.508333
2025-10-10 12:48:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:48:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:48:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:48:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2292MB allocated=2217MB
2025-10-10 12:48:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.88679558038712, 'train_avg_loss': 0.6990566298365593, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 12:48:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.02423095703125, 'train_avg_loss': 0.6938004811604818, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 12:48:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 333.02423095703125, 'train_avg_loss': 0.6938004811604818, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 12:48:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 12:48:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:48:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:49:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:49:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.720703, avg_loss=0.691085, seen=480, correct=253, accuracy=0.527083
2025-10-10 12:49:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:49:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:49:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:49:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2310MB allocated=2217MB
2025-10-10 12:49:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49151575565338, 'train_avg_loss': 0.7040959646304449, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 12:49:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.720703125, 'train_avg_loss': 0.6910847981770833, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:49:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 331.720703125, 'train_avg_loss': 0.6910847981770833, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 12:49:26 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #154) -------------
2025-10-10 12:49:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=154 aidx=4 | s=5 (candidates=17)
2025-10-10 12:49:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 38, 52, 35, 17] (from 17)
2025-10-10 12:49:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:49:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:49:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:50:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:50:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.136261, avg_loss=0.687784, seen=480, correct=259, accuracy=0.539583
2025-10-10 12:50:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:50:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:50:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:50:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2288MB allocated=2217MB
2025-10-10 12:50:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.18853890895844, 'train_avg_loss': 0.6932378242413203, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:50:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1362609863281, 'train_avg_loss': 0.6877838770548502, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:50:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 330.1362609863281, 'train_avg_loss': 0.6877838770548502, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 12:50:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:50:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:50:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 12:50:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 12:50:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:50:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:50:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:50:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:50:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:50:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:50:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.117065, avg_loss=0.691911, seen=480, correct=252, accuracy=0.525000
2025-10-10 12:50:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:50:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:50:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:50:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2308MB allocated=2217MB
2025-10-10 12:50:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.84889268875122, 'train_avg_loss': 0.6904074390729268, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:50:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.1170654296875, 'train_avg_loss': 0.6919105529785157, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 12:50:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 332.1170654296875, 'train_avg_loss': 0.6919105529785157, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 12:50:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 12:50:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:50:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:51:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:51:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.427002, avg_loss=0.688390, seen=480, correct=249, accuracy=0.518750
2025-10-10 12:51:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:51:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:51:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:51:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2288MB allocated=2217MB
2025-10-10 12:51:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32978212833405, 'train_avg_loss': 0.6777481844027837, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:51:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.427001953125, 'train_avg_loss': 0.6883895874023438, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:51:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 330.427001953125, 'train_avg_loss': 0.6883895874023438, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 12:51:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 12:51:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:51:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:52:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:52:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.495300, avg_loss=0.690615, seen=480, correct=260, accuracy=0.541667
2025-10-10 12:52:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:52:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:52:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:52:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2336MB allocated=2217MB
2025-10-10 12:52:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.4281485080719, 'train_avg_loss': 0.6952345709005991, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:52:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.49530029296875, 'train_avg_loss': 0.6906152089436849, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 12:52:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 331.49530029296875, 'train_avg_loss': 0.6906152089436849, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 12:52:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:52:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:52:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 12:52:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:52:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:52:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:52:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:52:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:52:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:52:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:52:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.068176, avg_loss=0.685559, seen=480, correct=269, accuracy=0.560417
2025-10-10 12:52:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:52:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:52:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:52:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2316MB allocated=2217MB
2025-10-10 12:52:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.32709884643555, 'train_avg_loss': 0.6943924903869629, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 12:52:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.06817626953125, 'train_avg_loss': 0.6855587005615235, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 12:52:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 329.06817626953125, 'train_avg_loss': 0.6855587005615235, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 12:52:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #155) -------------
2025-10-10 12:52:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=155 aidx=4 | s=5 (candidates=17)
2025-10-10 12:52:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 23, 17, 13, 18] (from 17)
2025-10-10 12:52:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 12:52:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:52:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:53:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:53:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.280029, avg_loss=0.683917, seen=480, correct=260, accuracy=0.541667
2025-10-10 12:53:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:53:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:53:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:53:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2314MB allocated=2217MB
2025-10-10 12:53:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61724734306335, 'train_avg_loss': 0.6801437278588612, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:53:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.280029296875, 'train_avg_loss': 0.6839167277018229, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 12:53:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 328.280029296875, 'train_avg_loss': 0.6839167277018229, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 12:53:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 12:53:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:53:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:54:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:54:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.522858, avg_loss=0.690673, seen=480, correct=264, accuracy=0.550000
2025-10-10 12:54:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:54:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:54:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:54:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2288MB allocated=2217MB
2025-10-10 12:54:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.35101807117462, 'train_avg_loss': 0.6945918172597885, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 12:54:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5228576660156, 'train_avg_loss': 0.6906726201375325, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 12:54:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 331.5228576660156, 'train_avg_loss': 0.6906726201375325, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 12:54:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:54:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:54:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:54:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:54:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.996643, avg_loss=0.681243, seen=480, correct=268, accuracy=0.558333
2025-10-10 12:54:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:54:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:54:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:54:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2320MB allocated=2217MB
2025-10-10 12:54:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06556868553162, 'train_avg_loss': 0.6838797390460968, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 12:54:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.99664306640625, 'train_avg_loss': 0.6812430063883463, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 12:54:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 326.99664306640625, 'train_avg_loss': 0.6812430063883463, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 12:54:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 12:54:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:54:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:55:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:55:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.341858, avg_loss=0.684046, seen=480, correct=256, accuracy=0.533333
2025-10-10 12:55:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:55:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:55:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:55:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2290MB allocated=2217MB
2025-10-10 12:55:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.56770360469818, 'train_avg_loss': 0.6880641967058182, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:55:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.34185791015625, 'train_avg_loss': 0.6840455373128255, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:55:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 328.34185791015625, 'train_avg_loss': 0.6840455373128255, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 12:55:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 12:55:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:55:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:56:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:56:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.445679, avg_loss=0.688428, seen=480, correct=255, accuracy=0.531250
2025-10-10 12:56:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:56:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:56:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:56:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2314MB allocated=2217MB
2025-10-10 12:56:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.85889834165573, 'train_avg_loss': 0.6988241528471311, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 12:56:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4456787109375, 'train_avg_loss': 0.6884284973144531, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 12:56:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 330.4456787109375, 'train_avg_loss': 0.6884284973144531, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 12:56:14 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #156) -------------
2025-10-10 12:56:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=156 aidx=4 | s=5 (candidates=17)
2025-10-10 12:56:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 52, 49, 19, 10] (from 17)
2025-10-10 12:56:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 12:56:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:56:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:56:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:56:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.666077, avg_loss=0.688888, seen=480, correct=246, accuracy=0.512500
2025-10-10 12:56:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:56:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:56:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2292MB allocated=2217MB
2025-10-10 12:56:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60853350162506, 'train_avg_loss': 0.6884044458468755, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 12:56:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.66607666015625, 'train_avg_loss': 0.6888876597086588, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:56:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 330.66607666015625, 'train_avg_loss': 0.6888876597086588, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 12:56:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 12:56:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:56:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:57:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:57:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.988007, avg_loss=0.685392, seen=480, correct=262, accuracy=0.545833
2025-10-10 12:57:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:57:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:57:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:57:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2288MB allocated=2217MB
2025-10-10 12:57:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36917918920517, 'train_avg_loss': 0.6780764932433764, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 12:57:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.9880065917969, 'train_avg_loss': 0.6853916803995769, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:57:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 328.9880065917969, 'train_avg_loss': 0.6853916803995769, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:57:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 12:57:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:57:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:58:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:58:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.596252, avg_loss=0.690826, seen=480, correct=248, accuracy=0.516667
2025-10-10 12:58:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:58:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:58:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:58:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2328MB allocated=2217MB
2025-10-10 12:58:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.97872132062912, 'train_avg_loss': 0.716489344338576, 'train_seen': 120, 'train_correct': 51, 'train_acc': 0.425}}
2025-10-10 12:58:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.59625244140625, 'train_avg_loss': 0.6908255259195963, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:58:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 331.59625244140625, 'train_avg_loss': 0.6908255259195963, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 12:58:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:58:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:58:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 12:58:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 12:58:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:58:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:58:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:58:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:58:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:58:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:58:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.208557, avg_loss=0.685851, seen=480, correct=262, accuracy=0.545833
2025-10-10 12:58:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:58:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:58:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:58:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2344MB allocated=2217MB
2025-10-10 12:58:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.62750911712646, 'train_avg_loss': 0.6635625759760538, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 12:58:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.20855712890625, 'train_avg_loss': 0.6858511606852213, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:58:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 329.20855712890625, 'train_avg_loss': 0.6858511606852213, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 12:58:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 12:58:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:58:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 12:59:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 12:59:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.730621, avg_loss=0.680689, seen=480, correct=278, accuracy=0.579167
2025-10-10 12:59:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 12:59:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:59:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 12:59:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2314MB allocated=2217MB
2025-10-10 12:59:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.0899441242218, 'train_avg_loss': 0.675749534368515, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 12:59:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7306213378906, 'train_avg_loss': 0.6806887944539388, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 12:59:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 326.7306213378906, 'train_avg_loss': 0.6806887944539388, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 12:59:36 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #157) -------------
2025-10-10 12:59:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=157 aidx=4 | s=5 (candidates=17)
2025-10-10 12:59:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 39, 10, 18, 13] (from 17)
2025-10-10 12:59:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 12:59:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 12:59:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:00:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:00:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.666901, avg_loss=0.678473, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:00:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:00:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:00:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:00:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2314MB allocated=2217MB
2025-10-10 13:00:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.8062424659729, 'train_avg_loss': 0.6817186872164408, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 13:00:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6669006347656, 'train_avg_loss': 0.6784727096557617, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:00:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 325.6669006347656, 'train_avg_loss': 0.6784727096557617, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:00:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:00:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:00:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 13:00:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 13:00:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:00:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:00:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:00:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:00:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:00:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:00:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.037140, avg_loss=0.687577, seen=480, correct=270, accuracy=0.562500
2025-10-10 13:00:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:00:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:00:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:00:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2288MB allocated=2217MB
2025-10-10 13:00:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.38518607616425, 'train_avg_loss': 0.6865432173013687, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 13:00:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.0371398925781, 'train_avg_loss': 0.6875773747762044, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 13:00:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 330.0371398925781, 'train_avg_loss': 0.6875773747762044, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 13:00:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:01:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:01:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:01:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:01:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.833923, avg_loss=0.670487, seen=480, correct=290, accuracy=0.604167
2025-10-10 13:01:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:01:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:01:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:01:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2314MB allocated=2217MB
2025-10-10 13:01:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.01304888725281, 'train_avg_loss': 0.6667754073937734, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 13:01:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.83392333984375, 'train_avg_loss': 0.6704873402913412, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:01:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 321.83392333984375, 'train_avg_loss': 0.6704873402913412, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:01:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:01:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:02:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:02:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.293274, avg_loss=0.681861, seen=480, correct=260, accuracy=0.541667
2025-10-10 13:02:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:02:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:02:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:02:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2314MB allocated=2217MB
2025-10-10 13:02:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.88027536869049, 'train_avg_loss': 0.6990022947390874, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 13:02:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.29327392578125, 'train_avg_loss': 0.6818609873453776, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 13:02:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 327.29327392578125, 'train_avg_loss': 0.6818609873453776, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 13:02:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:02:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:02:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:03:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:03:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.138702, avg_loss=0.679456, seen=480, correct=274, accuracy=0.570833
2025-10-10 13:03:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:03:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:03:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:03:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2290MB allocated=2217MB
2025-10-10 13:03:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42798793315887, 'train_avg_loss': 0.6868998994429906, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:03:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1387023925781, 'train_avg_loss': 0.6794556299845378, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 13:03:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 326.1387023925781, 'train_avg_loss': 0.6794556299845378, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 13:03:03 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #158) -------------
2025-10-10 13:03:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=158 aidx=4 | s=5 (candidates=17)
2025-10-10 13:03:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 12, 49, 18, 23] (from 17)
2025-10-10 13:03:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:03:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:03:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:03:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:03:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.028198, avg_loss=0.670892, seen=480, correct=275, accuracy=0.572917
2025-10-10 13:03:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:03:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:03:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:03:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2314MB allocated=2217MB
2025-10-10 13:03:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.0529659986496, 'train_avg_loss': 0.6671080499887466, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:03:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0281982421875, 'train_avg_loss': 0.670892079671224, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:03:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 322.0281982421875, 'train_avg_loss': 0.670892079671224, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:03:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:03:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:03:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 13:03:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:03:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:03:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:03:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:03:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:03:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:04:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:04:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.796021, avg_loss=0.687075, seen=480, correct=254, accuracy=0.529167
2025-10-10 13:04:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:04:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:04:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:04:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2292MB allocated=2217MB
2025-10-10 13:04:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.10454660654068, 'train_avg_loss': 0.692537888387839, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 13:04:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7960205078125, 'train_avg_loss': 0.6870750427246094, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 13:04:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 329.7960205078125, 'train_avg_loss': 0.6870750427246094, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 13:04:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 13:04:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:04:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:05:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:05:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.095459, avg_loss=0.687699, seen=480, correct=256, accuracy=0.533333
2025-10-10 13:05:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:05:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:05:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:05:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2328MB allocated=2217MB
2025-10-10 13:05:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.67984801530838, 'train_avg_loss': 0.6973320667942365, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 13:05:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.095458984375, 'train_avg_loss': 0.6876988728841146, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:05:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 330.095458984375, 'train_avg_loss': 0.6876988728841146, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:05:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:05:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:05:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:05:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:05:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.188477, avg_loss=0.677476, seen=480, correct=264, accuracy=0.550000
2025-10-10 13:05:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:05:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:05:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:05:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2314MB allocated=2217MB
2025-10-10 13:05:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.86585175991058, 'train_avg_loss': 0.6905487646659215, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 13:05:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.1884765625, 'train_avg_loss': 0.6774759928385417, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 13:05:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 325.1884765625, 'train_avg_loss': 0.6774759928385417, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 13:05:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:05:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:05:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 13:05:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 13:05:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:05:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:05:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:05:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:05:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:06:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:06:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.901978, avg_loss=0.689379, seen=480, correct=256, accuracy=0.533333
2025-10-10 13:06:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:06:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:06:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:06:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2288MB allocated=2217MB
2025-10-10 13:06:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.06951946020126, 'train_avg_loss': 0.6922459955016772, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 13:06:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9019775390625, 'train_avg_loss': 0.6893791198730469, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:06:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 330.9019775390625, 'train_avg_loss': 0.6893791198730469, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:06:25 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #159) -------------
2025-10-10 13:06:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=159 aidx=4 | s=5 (candidates=17)
2025-10-10 13:06:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 17, 10, 9, 35] (from 17)
2025-10-10 13:06:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:06:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:06:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 13:06:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:06:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:06:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:06:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:06:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:06:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:07:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:07:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.835571, avg_loss=0.685074, seen=480, correct=267, accuracy=0.556250
2025-10-10 13:07:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:07:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:07:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:07:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2288MB allocated=2217MB
2025-10-10 13:07:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.24693816900253, 'train_avg_loss': 0.6687244847416878, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 13:07:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.8355712890625, 'train_avg_loss': 0.6850741068522136, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 13:07:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 328.8355712890625, 'train_avg_loss': 0.6850741068522136, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 13:07:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 13:07:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:07:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:07:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:07:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.569305, avg_loss=0.674103, seen=480, correct=272, accuracy=0.566667
2025-10-10 13:07:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:07:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:07:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:07:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2314MB allocated=2217MB
2025-10-10 13:07:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.25596046447754, 'train_avg_loss': 0.6771330038706461, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:07:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.5693054199219, 'train_avg_loss': 0.6741027196248373, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:07:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 323.5693054199219, 'train_avg_loss': 0.6741027196248373, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:07:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:07:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:07:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 13:07:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:07:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:07:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:07:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:07:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:07:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:08:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:08:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.341125, avg_loss=0.667377, seen=480, correct=281, accuracy=0.585417
2025-10-10 13:08:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:08:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:08:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:08:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2314MB allocated=2217MB
2025-10-10 13:08:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.09601306915283, 'train_avg_loss': 0.6674667755762737, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 13:08:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.34112548828125, 'train_avg_loss': 0.6673773447672526, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:08:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 320.34112548828125, 'train_avg_loss': 0.6673773447672526, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:08:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:08:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:08:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 13:08:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 13:08:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:08:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:08:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:08:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:08:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:09:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:09:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.502502, avg_loss=0.676047, seen=480, correct=272, accuracy=0.566667
2025-10-10 13:09:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:09:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:09:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:09:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2304MB allocated=2217MB
2025-10-10 13:09:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17698502540588, 'train_avg_loss': 0.684808208545049, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 13:09:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.50250244140625, 'train_avg_loss': 0.676046880086263, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:09:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 324.50250244140625, 'train_avg_loss': 0.676046880086263, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:09:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:09:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:09:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:09:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:09:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.351379, avg_loss=0.688232, seen=480, correct=268, accuracy=0.558333
2025-10-10 13:09:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:09:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:09:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:09:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2336MB allocated=2217MB
2025-10-10 13:09:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.10822141170502, 'train_avg_loss': 0.6925685117642085, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 13:09:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.35137939453125, 'train_avg_loss': 0.6882320404052734, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 13:09:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 330.35137939453125, 'train_avg_loss': 0.6882320404052734, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 13:09:58 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #160) -------------
2025-10-10 13:09:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=160 aidx=4 | s=5 (candidates=17)
2025-10-10 13:09:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 38, 35, 18, 46] (from 17)
2025-10-10 13:09:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:10:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:10:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:10:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:10:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.279297, avg_loss=0.667249, seen=480, correct=282, accuracy=0.587500
2025-10-10 13:10:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:10:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:10:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:10:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2290MB allocated=2217MB
2025-10-10 13:10:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7887636423111, 'train_avg_loss': 0.6732396970192591, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:10:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.279296875, 'train_avg_loss': 0.66724853515625, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:10:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 320.279296875, 'train_avg_loss': 0.66724853515625, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:10:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 13:10:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:10:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:11:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:11:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.619873, avg_loss=0.682541, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:11:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:11:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:11:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:11:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2308MB allocated=2217MB
2025-10-10 13:11:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.48616629838943, 'train_avg_loss': 0.679051385819912, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:11:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.619873046875, 'train_avg_loss': 0.6825414021809896, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:11:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 327.619873046875, 'train_avg_loss': 0.6825414021809896, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:11:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:11:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:11:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 13:11:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:11:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:11:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:11:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:11:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:11:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:12:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:12:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.069580, avg_loss=0.681395, seen=480, correct=272, accuracy=0.566667
2025-10-10 13:12:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:12:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:12:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:12:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2336MB allocated=2217MB
2025-10-10 13:12:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.9760959148407, 'train_avg_loss': 0.6831341326236725, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 13:12:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.069580078125, 'train_avg_loss': 0.6813949584960938, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:12:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 327.069580078125, 'train_avg_loss': 0.6813949584960938, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 13:12:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:12:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:12:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:12:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:12:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.706848, avg_loss=0.678556, seen=480, correct=267, accuracy=0.556250
2025-10-10 13:12:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:12:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:12:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:12:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2312MB allocated=2217MB
2025-10-10 13:12:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49765121936798, 'train_avg_loss': 0.6958137601613998, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 13:12:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.70684814453125, 'train_avg_loss': 0.6785559336344401, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 13:12:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 325.70684814453125, 'train_avg_loss': 0.6785559336344401, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 13:12:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 13:12:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:12:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:13:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:13:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.118103, avg_loss=0.683579, seen=480, correct=263, accuracy=0.547917
2025-10-10 13:13:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:13:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:13:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:13:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2310MB allocated=2217MB
2025-10-10 13:13:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49869936704636, 'train_avg_loss': 0.6958224947253863, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 13:13:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.11810302734375, 'train_avg_loss': 0.6835793813069662, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 13:13:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 328.11810302734375, 'train_avg_loss': 0.6835793813069662, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 13:13:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #161) -------------
2025-10-10 13:13:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=161 aidx=4 | s=5 (candidates=17)
2025-10-10 13:13:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 9, 49, 18, 14] (from 17)
2025-10-10 13:13:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:13:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:13:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 13:13:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 13:13:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:13:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:13:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:13:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:13:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:14:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:14:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.246826, avg_loss=0.677598, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:14:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:14:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:14:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:14:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2344MB allocated=2217MB
2025-10-10 13:14:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.75053572654724, 'train_avg_loss': 0.6562544643878937, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 13:14:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.246826171875, 'train_avg_loss': 0.6775975545247396, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:14:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 325.246826171875, 'train_avg_loss': 0.6775975545247396, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:14:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 13:14:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:14:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:14:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:14:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.618500, avg_loss=0.678372, seen=480, correct=261, accuracy=0.543750
2025-10-10 13:14:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:14:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:14:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:14:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2304MB allocated=2217MB
2025-10-10 13:14:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.36727118492126, 'train_avg_loss': 0.6863939265410105, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 13:14:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6184997558594, 'train_avg_loss': 0.6783718744913737, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 13:14:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 325.6184997558594, 'train_avg_loss': 0.6783718744913737, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 13:14:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 13:14:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:14:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:15:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:15:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.083435, avg_loss=0.685590, seen=480, correct=256, accuracy=0.533333
2025-10-10 13:15:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:15:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:15:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:15:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2328MB allocated=2217MB
2025-10-10 13:15:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.22108715772629, 'train_avg_loss': 0.7018423929810524, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 13:15:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.08343505859375, 'train_avg_loss': 0.6855904897054036, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:15:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 329.08343505859375, 'train_avg_loss': 0.6855904897054036, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 13:15:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:15:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:15:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:16:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:16:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.693939, avg_loss=0.676446, seen=480, correct=273, accuracy=0.568750
2025-10-10 13:16:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:16:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:16:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:16:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2314MB allocated=2217MB
2025-10-10 13:16:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.52791512012482, 'train_avg_loss': 0.6960659593343734, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 13:16:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6939392089844, 'train_avg_loss': 0.6764457066853841, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 13:16:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 324.6939392089844, 'train_avg_loss': 0.6764457066853841, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 13:16:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:16:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:16:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:16:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:16:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.410034, avg_loss=0.680021, seen=480, correct=273, accuracy=0.568750
2025-10-10 13:16:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:16:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:16:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:16:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2288MB allocated=2217MB
2025-10-10 13:16:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.96787947416306, 'train_avg_loss': 0.6580656622846921, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 13:16:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.4100341796875, 'train_avg_loss': 0.6800209045410156, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 13:16:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 326.4100341796875, 'train_avg_loss': 0.6800209045410156, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 13:16:55 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #162) -------------
2025-10-10 13:16:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=162 aidx=4 | s=5 (candidates=17)
2025-10-10 13:16:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 17, 46, 19, 12] (from 17)
2025-10-10 13:16:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:16:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:16:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:17:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:17:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.072510, avg_loss=0.683484, seen=480, correct=264, accuracy=0.550000
2025-10-10 13:17:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:17:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:17:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:17:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2290MB allocated=2217MB
2025-10-10 13:17:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.98038083314896, 'train_avg_loss': 0.6915031736095746, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 13:17:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.072509765625, 'train_avg_loss': 0.6834843953450521, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 13:17:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 328.072509765625, 'train_avg_loss': 0.6834843953450521, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 13:17:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 13:17:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:17:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:18:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:18:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.111450, avg_loss=0.685649, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:18:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:18:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:18:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:18:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2314MB allocated=2217MB
2025-10-10 13:18:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.21099984645844, 'train_avg_loss': 0.668424998720487, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 13:18:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1114501953125, 'train_avg_loss': 0.6856488545735677, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:18:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 329.1114501953125, 'train_avg_loss': 0.6856488545735677, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:18:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 13:18:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:18:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:18:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:18:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.593811, avg_loss=0.690820, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:18:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:18:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:18:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:18:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2310MB allocated=2217MB
2025-10-10 13:18:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.38373410701752, 'train_avg_loss': 0.7115311175584793, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 13:18:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.59381103515625, 'train_avg_loss': 0.6908204396565755, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:18:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 331.59381103515625, 'train_avg_loss': 0.6908204396565755, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:18:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 13:18:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:18:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:19:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:19:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.008972, avg_loss=0.689602, seen=480, correct=270, accuracy=0.562500
2025-10-10 13:19:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:19:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:19:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:19:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2344MB allocated=2217MB
2025-10-10 13:19:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26732587814331, 'train_avg_loss': 0.7022277156511942, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 13:19:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.00897216796875, 'train_avg_loss': 0.6896020253499349, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 13:19:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 331.00897216796875, 'train_avg_loss': 0.6896020253499349, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 13:19:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:19:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:19:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 13:19:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:19:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:19:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:19:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:19:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:19:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:20:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:20:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.149902, avg_loss=0.700312, seen=480, correct=242, accuracy=0.504167
2025-10-10 13:20:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:20:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:20:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:20:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2292MB allocated=2217MB
2025-10-10 13:20:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.87082862854004, 'train_avg_loss': 0.7072569052378337, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 13:20:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.14990234375, 'train_avg_loss': 0.7003122965494791, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 13:20:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 336.14990234375, 'train_avg_loss': 0.7003122965494791, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 13:20:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #163) -------------
2025-10-10 13:20:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=163 aidx=4 | s=5 (candidates=17)
2025-10-10 13:20:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 46, 18, 52, 35] (from 17)
2025-10-10 13:20:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 13:20:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:20:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:20:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:20:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.810425, avg_loss=0.682938, seen=480, correct=275, accuracy=0.572917
2025-10-10 13:20:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:20:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:20:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:21:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2308MB allocated=2217MB
2025-10-10 13:21:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3368399143219, 'train_avg_loss': 0.6778069992860158, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 13:21:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8104248046875, 'train_avg_loss': 0.6829383850097657, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:21:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 327.8104248046875, 'train_avg_loss': 0.6829383850097657, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:21:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 13:21:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:21:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:21:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:21:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.082336, avg_loss=0.679338, seen=480, correct=274, accuracy=0.570833
2025-10-10 13:21:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:21:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:21:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:21:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2310MB allocated=2217MB
2025-10-10 13:21:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90991932153702, 'train_avg_loss': 0.6825826610128085, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:21:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.08233642578125, 'train_avg_loss': 0.6793382008870442, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 13:21:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 326.08233642578125, 'train_avg_loss': 0.6793382008870442, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 13:21:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:21:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:21:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:22:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:22:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.079498, avg_loss=0.675166, seen=480, correct=280, accuracy=0.583333
2025-10-10 13:22:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:22:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:22:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:22:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2314MB allocated=2217MB
2025-10-10 13:22:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.58222270011902, 'train_avg_loss': 0.6965185225009918, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 13:22:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0794982910156, 'train_avg_loss': 0.6751656214396159, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 13:22:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 324.0794982910156, 'train_avg_loss': 0.6751656214396159, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 13:22:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:22:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:22:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:23:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:23:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.090332, avg_loss=0.677272, seen=480, correct=269, accuracy=0.560417
2025-10-10 13:23:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:23:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:23:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:23:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2288MB allocated=2217MB
2025-10-10 13:23:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39949071407318, 'train_avg_loss': 0.6699957559506099, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:23:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.09033203125, 'train_avg_loss': 0.6772715250651041, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:23:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 325.09033203125, 'train_avg_loss': 0.6772715250651041, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 13:23:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:23:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:23:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:23:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:23:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.026733, avg_loss=0.681306, seen=480, correct=279, accuracy=0.581250
2025-10-10 13:23:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:23:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:23:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:23:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2336MB allocated=2217MB
2025-10-10 13:23:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.39209151268005, 'train_avg_loss': 0.6866007626056672, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:23:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0267333984375, 'train_avg_loss': 0.6813056945800782, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 13:23:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 327.0267333984375, 'train_avg_loss': 0.6813056945800782, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 13:23:50 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #164) -------------
2025-10-10 13:23:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=164 aidx=4 | s=5 (candidates=17)
2025-10-10 13:23:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 53, 52, 9, 12] (from 17)
2025-10-10 13:23:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:23:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:23:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:24:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:24:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.377625, avg_loss=0.671620, seen=480, correct=281, accuracy=0.585417
2025-10-10 13:24:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:24:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:24:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:24:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2288MB allocated=2217MB
2025-10-10 13:24:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.26389819383621, 'train_avg_loss': 0.6521991516153017, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 13:24:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.37762451171875, 'train_avg_loss': 0.6716200510660807, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:24:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 322.37762451171875, 'train_avg_loss': 0.6716200510660807, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:24:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 13:24:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:24:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:25:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:25:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.589600, avg_loss=0.682478, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:25:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:25:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:25:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:25:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2294MB allocated=2217MB
2025-10-10 13:25:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.65855652093887, 'train_avg_loss': 0.6638213043411573, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 13:25:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.589599609375, 'train_avg_loss': 0.6824783325195313, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:25:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 327.589599609375, 'train_avg_loss': 0.6824783325195313, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:25:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:25:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:25:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:25:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:25:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.013062, avg_loss=0.679194, seen=480, correct=265, accuracy=0.552083
2025-10-10 13:25:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:25:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:25:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:25:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2288MB allocated=2217MB
2025-10-10 13:25:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7229734659195, 'train_avg_loss': 0.6726914455493291, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:25:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.0130615234375, 'train_avg_loss': 0.6791938781738281, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 13:25:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 326.0130615234375, 'train_avg_loss': 0.6791938781738281, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 13:25:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:25:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:25:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 13:25:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 13:25:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:25:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:25:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:25:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:25:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:26:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:26:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.555450, avg_loss=0.676157, seen=480, correct=282, accuracy=0.587500
2025-10-10 13:26:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:26:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:26:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:26:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2304MB allocated=2217MB
2025-10-10 13:26:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.30446469783783, 'train_avg_loss': 0.6858705391486486, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 13:26:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.5554504394531, 'train_avg_loss': 0.6761571884155273, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:26:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 324.5554504394531, 'train_avg_loss': 0.6761571884155273, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:26:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:26:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:26:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:27:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:27:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.705048, avg_loss=0.676469, seen=480, correct=282, accuracy=0.587500
2025-10-10 13:27:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:27:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:27:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:27:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2292MB allocated=2217MB
2025-10-10 13:27:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09776723384857, 'train_avg_loss': 0.6841480602820714, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:27:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7050476074219, 'train_avg_loss': 0.6764688491821289, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:27:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 324.7050476074219, 'train_avg_loss': 0.6764688491821289, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 13:27:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #165) -------------
2025-10-10 13:27:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=165 aidx=4 | s=5 (candidates=17)
2025-10-10 13:27:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 35, 10, 7, 13] (from 17)
2025-10-10 13:27:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:27:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:27:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 13:27:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 13:27:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:27:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:27:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:27:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:27:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:27:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:27:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.268951, avg_loss=0.667227, seen=480, correct=295, accuracy=0.614583
2025-10-10 13:27:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:27:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:27:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:27:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2314MB allocated=2217MB
2025-10-10 13:27:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.71547341346741, 'train_avg_loss': 0.6642956117788951, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:27:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.2689514160156, 'train_avg_loss': 0.6672269821166992, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 13:27:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 320.2689514160156, 'train_avg_loss': 0.6672269821166992, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 13:27:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:27:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:27:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:28:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:28:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.027313, avg_loss=0.672974, seen=480, correct=284, accuracy=0.591667
2025-10-10 13:28:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:28:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:28:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:28:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2336MB allocated=2217MB
2025-10-10 13:28:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.88332641124725, 'train_avg_loss': 0.6740277200937271, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:28:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0273132324219, 'train_avg_loss': 0.6729735692342123, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:28:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 323.0273132324219, 'train_avg_loss': 0.6729735692342123, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:28:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:28:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:28:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:29:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:29:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.597412, avg_loss=0.649161, seen=480, correct=300, accuracy=0.625000
2025-10-10 13:29:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:29:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:29:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:29:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2314MB allocated=2217MB
2025-10-10 13:29:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.13138788938522, 'train_avg_loss': 0.6510948990782102, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 13:29:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.597412109375, 'train_avg_loss': 0.6491612752278646, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 13:29:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 311.597412109375, 'train_avg_loss': 0.6491612752278646, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 13:29:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:29:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:29:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 13:29:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 13:29:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:29:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:29:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:29:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:29:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:29:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:29:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.064270, avg_loss=0.668884, seen=480, correct=287, accuracy=0.597917
2025-10-10 13:29:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:29:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:29:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:29:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2306MB allocated=2217MB
2025-10-10 13:29:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.95349436998367, 'train_avg_loss': 0.7079457864165306, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 13:29:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.06427001953125, 'train_avg_loss': 0.6688838958740234, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 13:29:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 321.06427001953125, 'train_avg_loss': 0.6688838958740234, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 13:29:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:30:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:30:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:30:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:30:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.182892, avg_loss=0.648298, seen=480, correct=304, accuracy=0.633333
2025-10-10 13:30:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:30:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:30:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:30:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2290MB allocated=2217MB
2025-10-10 13:30:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.13733303546906, 'train_avg_loss': 0.6594777752955755, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 13:30:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.1828918457031, 'train_avg_loss': 0.6482976913452149, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 13:30:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 311.1828918457031, 'train_avg_loss': 0.6482976913452149, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 13:30:40 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #166) -------------
2025-10-10 13:30:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=166 aidx=4 | s=5 (candidates=17)
2025-10-10 13:30:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 38, 46, 14, 23] (from 17)
2025-10-10 13:30:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:30:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:30:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 13:30:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:30:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:30:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:30:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:30:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:30:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:31:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:31:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.243317, avg_loss=0.663007, seen=480, correct=294, accuracy=0.612500
2025-10-10 13:31:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:31:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:31:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:31:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2292MB allocated=2217MB
2025-10-10 13:31:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.93528324365616, 'train_avg_loss': 0.6744606936971347, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:31:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.2433166503906, 'train_avg_loss': 0.6630069096883138, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 13:31:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 318.2433166503906, 'train_avg_loss': 0.6630069096883138, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 13:31:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 13:31:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:31:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:32:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:32:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.942383, avg_loss=0.672797, seen=480, correct=275, accuracy=0.572917
2025-10-10 13:32:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:32:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:32:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:32:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2308MB allocated=2217MB
2025-10-10 13:32:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.97445106506348, 'train_avg_loss': 0.6664537588755289, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:32:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.9423828125, 'train_avg_loss': 0.672796630859375, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:32:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 322.9423828125, 'train_avg_loss': 0.672796630859375, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:32:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 13:32:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:32:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:32:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:32:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.805237, avg_loss=0.678761, seen=480, correct=276, accuracy=0.575000
2025-10-10 13:32:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:32:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:32:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:32:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2310MB allocated=2217MB
2025-10-10 13:32:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.81510996818542, 'train_avg_loss': 0.6817925830682119, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 13:32:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.80523681640625, 'train_avg_loss': 0.6787609100341797, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 13:32:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 325.80523681640625, 'train_avg_loss': 0.6787609100341797, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 13:32:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:32:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:32:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:33:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:33:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.862000, avg_loss=0.664296, seen=480, correct=289, accuracy=0.602083
2025-10-10 13:33:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:33:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:33:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:33:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2288MB allocated=2217MB
2025-10-10 13:33:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.12492799758911, 'train_avg_loss': 0.6427077333132426, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 13:33:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.86199951171875, 'train_avg_loss': 0.6642958323160807, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:33:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 318.86199951171875, 'train_avg_loss': 0.6642958323160807, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:33:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 13:33:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:33:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:34:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:34:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.392639, avg_loss=0.675818, seen=480, correct=271, accuracy=0.564583
2025-10-10 13:34:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:34:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:34:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:34:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2288MB allocated=2217MB
2025-10-10 13:34:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74375587701797, 'train_avg_loss': 0.6895312989751498, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 13:34:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.39263916015625, 'train_avg_loss': 0.6758179982503255, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 13:34:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 324.39263916015625, 'train_avg_loss': 0.6758179982503255, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 13:34:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #167) -------------
2025-10-10 13:34:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=167 aidx=4 | s=5 (candidates=17)
2025-10-10 13:34:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 23, 39, 46, 35] (from 17)
2025-10-10 13:34:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:34:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:34:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 13:34:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 13:34:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:34:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:34:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:34:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:34:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:34:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:34:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.958435, avg_loss=0.664497, seen=480, correct=290, accuracy=0.604167
2025-10-10 13:34:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:34:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:34:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:34:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2306MB allocated=2217MB
2025-10-10 13:34:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.06479954719543, 'train_avg_loss': 0.7172066628932953, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 13:34:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.95843505859375, 'train_avg_loss': 0.6644967397054037, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:34:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 318.95843505859375, 'train_avg_loss': 0.6644967397054037, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:34:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:34:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:34:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 13:34:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 13:34:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:34:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:34:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:34:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:34:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:35:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:35:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.673523, avg_loss=0.659737, seen=480, correct=292, accuracy=0.608333
2025-10-10 13:35:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:35:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:35:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:35:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2288MB allocated=2217MB
2025-10-10 13:35:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45171815156937, 'train_avg_loss': 0.6787643179297447, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 13:35:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.67352294921875, 'train_avg_loss': 0.6597365061442058, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 13:35:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 316.67352294921875, 'train_avg_loss': 0.6597365061442058, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 13:35:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 13:35:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:35:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:36:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:36:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.015503, avg_loss=0.677116, seen=480, correct=279, accuracy=0.581250
2025-10-10 13:36:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:36:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:36:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:36:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2288MB allocated=2217MB
2025-10-10 13:36:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.55135774612427, 'train_avg_loss': 0.6629279812177022, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 13:36:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0155029296875, 'train_avg_loss': 0.6771156311035156, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 13:36:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 325.0155029296875, 'train_avg_loss': 0.6771156311035156, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 13:36:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:36:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:36:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 13:36:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 13:36:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:36:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:36:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:36:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:36:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:36:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:36:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.144897, avg_loss=0.677385, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:36:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:36:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:36:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2310MB allocated=2217MB
2025-10-10 13:36:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82966828346252, 'train_avg_loss': 0.6735805690288543, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 13:36:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.1448974609375, 'train_avg_loss': 0.6773852030436198, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:36:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 325.1448974609375, 'train_avg_loss': 0.6773852030436198, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:36:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:36:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:36:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:37:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:37:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.749084, avg_loss=0.672394, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:37:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:37:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:37:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:37:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2336MB allocated=2217MB
2025-10-10 13:37:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.41287076473236, 'train_avg_loss': 0.6701072563727697, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:37:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.74908447265625, 'train_avg_loss': 0.6723939259847005, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:37:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 322.74908447265625, 'train_avg_loss': 0.6723939259847005, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:37:38 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #168) -------------
2025-10-10 13:37:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=168 aidx=4 | s=5 (candidates=17)
2025-10-10 13:37:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 10, 52, 9, 53] (from 17)
2025-10-10 13:37:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 13:37:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:37:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:38:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:38:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.525757, avg_loss=0.661512, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:38:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:38:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:38:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:38:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2344MB allocated=2217MB
2025-10-10 13:38:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.61342060565948, 'train_avg_loss': 0.6467785050471624, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 13:38:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.5257568359375, 'train_avg_loss': 0.6615119934082031, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:38:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 317.5257568359375, 'train_avg_loss': 0.6615119934082031, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:38:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:38:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:38:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:38:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:38:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.058075, avg_loss=0.641788, seen=480, correct=297, accuracy=0.618750
2025-10-10 13:38:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:38:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:38:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:39:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2314MB allocated=2217MB
2025-10-10 13:39:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.26560723781586, 'train_avg_loss': 0.6438800603151321, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 13:39:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.0580749511719, 'train_avg_loss': 0.6417876561482747, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 13:39:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 308.0580749511719, 'train_avg_loss': 0.6417876561482747, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 13:39:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:39:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:39:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:39:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:39:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.619476, avg_loss=0.667957, seen=480, correct=280, accuracy=0.583333
2025-10-10 13:39:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:39:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:39:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:39:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2288MB allocated=2217MB
2025-10-10 13:39:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.35126632452011, 'train_avg_loss': 0.6612605527043343, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:39:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.6194763183594, 'train_avg_loss': 0.6679572423299154, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 13:39:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 320.6194763183594, 'train_avg_loss': 0.6679572423299154, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 13:39:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 13:39:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:39:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:40:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:40:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.852997, avg_loss=0.672610, seen=480, correct=284, accuracy=0.591667
2025-10-10 13:40:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:40:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:40:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:40:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2304MB allocated=2217MB
2025-10-10 13:40:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.04662263393402, 'train_avg_loss': 0.6837218552827835, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:40:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8529968261719, 'train_avg_loss': 0.6726104100545247, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:40:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 322.8529968261719, 'train_avg_loss': 0.6726104100545247, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:40:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 13:40:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:40:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:41:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:41:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.801056, avg_loss=0.680836, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:41:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:41:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:41:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:41:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2294MB allocated=2217MB
2025-10-10 13:41:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.57486271858215, 'train_avg_loss': 0.646457189321518, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 13:41:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.8010559082031, 'train_avg_loss': 0.6808355331420899, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:41:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 326.8010559082031, 'train_avg_loss': 0.6808355331420899, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:41:05 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #169) -------------
2025-10-10 13:41:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=169 aidx=4 | s=5 (candidates=17)
2025-10-10 13:41:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 53, 18, 52, 38] (from 17)
2025-10-10 13:41:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:41:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:41:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:41:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:41:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.542725, avg_loss=0.626131, seen=480, correct=317, accuracy=0.660417
2025-10-10 13:41:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:41:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:41:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:41:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2290MB allocated=2217MB
2025-10-10 13:41:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.66884928941727, 'train_avg_loss': 0.6389070774118105, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 13:41:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.542724609375, 'train_avg_loss': 0.6261306762695312, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 13:41:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 300.542724609375, 'train_avg_loss': 0.6261306762695312, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 13:41:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 13:41:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:41:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:42:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:42:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.138580, avg_loss=0.673205, seen=480, correct=284, accuracy=0.591667
2025-10-10 13:42:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:42:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:42:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:42:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2294MB allocated=2217MB
2025-10-10 13:42:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.07223552465439, 'train_avg_loss': 0.6422686293721199, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:42:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.1385803222656, 'train_avg_loss': 0.6732053756713867, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:42:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 323.1385803222656, 'train_avg_loss': 0.6732053756713867, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:42:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 13:42:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:42:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:42:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:42:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.379639, avg_loss=0.663291, seen=480, correct=286, accuracy=0.595833
2025-10-10 13:42:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:42:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:43:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:43:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2314MB allocated=2217MB
2025-10-10 13:43:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.51382559537888, 'train_avg_loss': 0.6959485466281573, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 13:43:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.379638671875, 'train_avg_loss': 0.6632909138997396, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 13:43:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 318.379638671875, 'train_avg_loss': 0.6632909138997396, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 13:43:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:43:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:43:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:43:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:43:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.246368, avg_loss=0.665097, seen=480, correct=283, accuracy=0.589583
2025-10-10 13:43:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:43:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:43:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:43:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2288MB allocated=2217MB
2025-10-10 13:43:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.23151016235352, 'train_avg_loss': 0.6602625846862793, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 13:43:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.2463684082031, 'train_avg_loss': 0.6650966008504232, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 13:43:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 319.2463684082031, 'train_avg_loss': 0.6650966008504232, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 13:43:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 13:43:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:43:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:44:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:44:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.627563, avg_loss=0.670057, seen=480, correct=275, accuracy=0.572917
2025-10-10 13:44:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:44:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:44:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:44:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2308MB allocated=2217MB
2025-10-10 13:44:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.67661446332932, 'train_avg_loss': 0.663971787194411, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 13:44:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.6275634765625, 'train_avg_loss': 0.6700574239095052, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:44:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 321.6275634765625, 'train_avg_loss': 0.6700574239095052, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 13:44:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #170) -------------
2025-10-10 13:44:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=170 aidx=4 | s=5 (candidates=17)
2025-10-10 13:44:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 12, 23, 35, 53] (from 17)
2025-10-10 13:44:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:44:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:44:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:45:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:45:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.605988, avg_loss=0.661679, seen=480, correct=287, accuracy=0.597917
2025-10-10 13:45:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:45:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:45:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:45:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2288MB allocated=2217MB
2025-10-10 13:45:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.41237735748291, 'train_avg_loss': 0.6534364779790243, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 13:45:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.6059875488281, 'train_avg_loss': 0.6616791407267253, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 13:45:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 317.6059875488281, 'train_avg_loss': 0.6616791407267253, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 13:45:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:45:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:45:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:45:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:45:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.839478, avg_loss=0.657999, seen=480, correct=290, accuracy=0.604167
2025-10-10 13:45:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:45:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:45:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:45:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2292MB allocated=2217MB
2025-10-10 13:45:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.29831820726395, 'train_avg_loss': 0.6691526517271995, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:45:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.8394775390625, 'train_avg_loss': 0.6579989115397136, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:45:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 315.8394775390625, 'train_avg_loss': 0.6579989115397136, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:45:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 13:45:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:45:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:46:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:46:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.330200, avg_loss=0.654855, seen=480, correct=288, accuracy=0.600000
2025-10-10 13:46:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:46:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:46:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:46:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2288MB allocated=2217MB
2025-10-10 13:46:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.09283775091171, 'train_avg_loss': 0.6757736479242643, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 13:46:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.3302001953125, 'train_avg_loss': 0.6548545837402344, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 13:46:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 314.3302001953125, 'train_avg_loss': 0.6548545837402344, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 13:46:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 13:46:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:46:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:47:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:47:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.745911, avg_loss=0.666137, seen=480, correct=281, accuracy=0.585417
2025-10-10 13:47:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:47:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:47:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:47:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2336MB allocated=2217MB
2025-10-10 13:47:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.98647892475128, 'train_avg_loss': 0.666553991039594, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:47:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.74591064453125, 'train_avg_loss': 0.6661373138427734, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:47:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 319.74591064453125, 'train_avg_loss': 0.6661373138427734, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 13:47:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:47:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:47:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 13:47:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 13:47:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:47:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:47:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:47:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:47:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:47:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:47:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.354767, avg_loss=0.671572, seen=480, correct=278, accuracy=0.579167
2025-10-10 13:47:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:47:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:47:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:47:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2294MB allocated=2217MB
2025-10-10 13:47:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.58763599395752, 'train_avg_loss': 0.638230299949646, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 13:47:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.3547668457031, 'train_avg_loss': 0.6715724309285481, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:47:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 322.3547668457031, 'train_avg_loss': 0.6715724309285481, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 13:47:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #171) -------------
2025-10-10 13:47:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=171 aidx=4 | s=5 (candidates=17)
2025-10-10 13:47:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 14, 7, 13, 17] (from 17)
2025-10-10 13:47:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 13:47:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:47:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:48:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:48:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.187714, avg_loss=0.662891, seen=480, correct=286, accuracy=0.595833
2025-10-10 13:48:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:48:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:48:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:48:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2288MB allocated=2217MB
2025-10-10 13:48:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.04403728246689, 'train_avg_loss': 0.6587003106872241, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 13:48:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.1877136230469, 'train_avg_loss': 0.6628910700480143, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 13:48:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 318.1877136230469, 'train_avg_loss': 0.6628910700480143, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 13:48:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:48:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:48:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:49:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:49:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.422577, avg_loss=0.652964, seen=480, correct=298, accuracy=0.620833
2025-10-10 13:49:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:49:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:49:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:49:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2288MB allocated=2217MB
2025-10-10 13:49:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.9624086022377, 'train_avg_loss': 0.6163534050186475, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 13:49:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4225769042969, 'train_avg_loss': 0.6529637018839518, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 13:49:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 313.4225769042969, 'train_avg_loss': 0.6529637018839518, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 13:49:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 13:49:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:49:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:50:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:50:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.181152, avg_loss=0.664961, seen=480, correct=289, accuracy=0.602083
2025-10-10 13:50:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:50:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:50:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:50:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2306MB allocated=2217MB
2025-10-10 13:50:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.5432847738266, 'train_avg_loss': 0.712860706448555, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 13:50:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.18115234375, 'train_avg_loss': 0.6649607340494792, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:50:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 319.18115234375, 'train_avg_loss': 0.6649607340494792, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:50:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:50:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:50:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:50:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:50:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.556274, avg_loss=0.624076, seen=480, correct=318, accuracy=0.662500
2025-10-10 13:50:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:50:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:50:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:50:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2290MB allocated=2217MB
2025-10-10 13:50:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.89468330144882, 'train_avg_loss': 0.6407890275120736, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 13:50:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.5562744140625, 'train_avg_loss': 0.6240755716959635, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 13:50:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 299.5562744140625, 'train_avg_loss': 0.6240755716959635, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 13:50:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 13:50:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:50:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:51:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:51:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.572144, avg_loss=0.653275, seen=480, correct=305, accuracy=0.635417
2025-10-10 13:51:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:51:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:51:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:51:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2320MB allocated=2217MB
2025-10-10 13:51:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.25028961896896, 'train_avg_loss': 0.643752413491408, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 13:51:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.5721435546875, 'train_avg_loss': 0.6532752990722657, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 13:51:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 313.5721435546875, 'train_avg_loss': 0.6532752990722657, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 13:51:25 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #172) -------------
2025-10-10 13:51:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=172 aidx=4 | s=5 (candidates=17)
2025-10-10 13:51:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 19, 13, 23, 7] (from 17)
2025-10-10 13:51:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:51:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:51:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 13:51:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:51:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:51:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:51:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:51:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:51:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:52:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:52:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.418335, avg_loss=0.634205, seen=480, correct=307, accuracy=0.639583
2025-10-10 13:52:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:52:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:52:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:52:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2314MB allocated=2217MB
2025-10-10 13:52:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.70402628183365, 'train_avg_loss': 0.630866885681947, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 13:52:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.4183349609375, 'train_avg_loss': 0.6342048645019531, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 13:52:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 304.4183349609375, 'train_avg_loss': 0.6342048645019531, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 13:52:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 13:52:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:52:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:52:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:52:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.001587, avg_loss=0.656253, seen=480, correct=291, accuracy=0.606250
2025-10-10 13:52:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:52:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:52:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:52:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2344MB allocated=2217MB
2025-10-10 13:52:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.23183310031891, 'train_avg_loss': 0.6435986091693242, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 13:52:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.0015869140625, 'train_avg_loss': 0.6562533060709635, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 13:52:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 315.0015869140625, 'train_avg_loss': 0.6562533060709635, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 13:52:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:52:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:52:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:53:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:53:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.240265, avg_loss=0.621334, seen=480, correct=325, accuracy=0.677083
2025-10-10 13:53:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:53:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:53:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:53:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2290MB allocated=2217MB
2025-10-10 13:53:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.09832334518433, 'train_avg_loss': 0.6424860278765361, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 13:53:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.2402648925781, 'train_avg_loss': 0.6213338851928711, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 13:53:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 298.2402648925781, 'train_avg_loss': 0.6213338851928711, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 13:53:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 13:53:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:53:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:54:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:54:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.613159, avg_loss=0.655444, seen=480, correct=290, accuracy=0.604167
2025-10-10 13:54:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:54:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:54:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:54:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2288MB allocated=2217MB
2025-10-10 13:54:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69941329956055, 'train_avg_loss': 0.6724951108296712, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 13:54:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.6131591796875, 'train_avg_loss': 0.655444081624349, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:54:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 314.6131591796875, 'train_avg_loss': 0.655444081624349, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 13:54:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 13:54:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:54:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:54:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:54:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.865417, avg_loss=0.662220, seen=480, correct=291, accuracy=0.606250
2025-10-10 13:54:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:54:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:54:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:54:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2306MB allocated=2217MB
2025-10-10 13:54:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.88066333532333, 'train_avg_loss': 0.7156721944610278, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 13:54:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.86541748046875, 'train_avg_loss': 0.6622196197509765, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 13:54:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 317.86541748046875, 'train_avg_loss': 0.6622196197509765, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 13:54:52 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #173) -------------
2025-10-10 13:54:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=173 aidx=4 | s=5 (candidates=17)
2025-10-10 13:54:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 13, 10, 39, 17] (from 17)
2025-10-10 13:54:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:54:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:54:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 13:54:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 13:54:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:54:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:54:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:54:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:54:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:55:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:55:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.312225, avg_loss=0.656900, seen=480, correct=289, accuracy=0.602083
2025-10-10 13:55:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:55:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:55:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:55:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2292MB allocated=2217MB
2025-10-10 13:55:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.77217972278595, 'train_avg_loss': 0.6731014976898829, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 13:55:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.3122253417969, 'train_avg_loss': 0.6569004694620768, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:55:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 315.3122253417969, 'train_avg_loss': 0.6569004694620768, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 13:55:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 13:55:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:55:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:56:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:56:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.972046, avg_loss=0.612442, seen=480, correct=327, accuracy=0.681250
2025-10-10 13:56:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:56:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:56:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:56:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2290MB allocated=2217MB
2025-10-10 13:56:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.93195736408234, 'train_avg_loss': 0.6327663113673528, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 13:56:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.9720458984375, 'train_avg_loss': 0.6124417622884114, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 13:56:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 293.9720458984375, 'train_avg_loss': 0.6124417622884114, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 13:56:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 13:56:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:56:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:56:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:56:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.206787, avg_loss=0.631681, seen=480, correct=308, accuracy=0.641667
2025-10-10 13:56:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:56:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:56:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:56:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2314MB allocated=2217MB
2025-10-10 13:56:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.13572800159454, 'train_avg_loss': 0.6344644000132879, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 13:56:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.206787109375, 'train_avg_loss': 0.6316808064778646, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 13:56:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 303.206787109375, 'train_avg_loss': 0.6316808064778646, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 13:56:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 13:56:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:56:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:57:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:57:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.272583, avg_loss=0.673485, seen=480, correct=277, accuracy=0.577083
2025-10-10 13:57:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:57:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:57:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:57:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2288MB allocated=2217MB
2025-10-10 13:57:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.85023963451385, 'train_avg_loss': 0.6570853302876155, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 13:57:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.2725830078125, 'train_avg_loss': 0.6734845479329427, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 13:57:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 323.2725830078125, 'train_avg_loss': 0.6734845479329427, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 13:57:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 13:57:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:57:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:58:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:58:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.774139, avg_loss=0.639113, seen=480, correct=308, accuracy=0.641667
2025-10-10 13:58:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:58:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:58:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:58:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2320MB allocated=2217MB
2025-10-10 13:58:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.39340800046921, 'train_avg_loss': 0.6282784000039101, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 13:58:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.7741394042969, 'train_avg_loss': 0.6391127904256185, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 13:58:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 306.7741394042969, 'train_avg_loss': 0.6391127904256185, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 13:58:12 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #174) -------------
2025-10-10 13:58:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=174 aidx=4 | s=5 (candidates=17)
2025-10-10 13:58:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 49, 9, 23, 35] (from 17)
2025-10-10 13:58:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:58:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:58:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 13:58:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 13:58:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:58:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:58:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:58:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:58:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:58:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:58:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.727905, avg_loss=0.645266, seen=480, correct=284, accuracy=0.591667
2025-10-10 13:58:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:58:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:58:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:58:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2288MB allocated=2217MB
2025-10-10 13:58:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.14601516723633, 'train_avg_loss': 0.609550126393636, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 13:58:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.7279052734375, 'train_avg_loss': 0.6452664693196615, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:58:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 309.7279052734375, 'train_avg_loss': 0.6452664693196615, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 13:58:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 13:58:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:58:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 13:59:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 13:59:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.041168, avg_loss=0.673002, seen=480, correct=277, accuracy=0.577083
2025-10-10 13:59:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 13:59:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:59:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 13:59:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2328MB allocated=2217MB
2025-10-10 13:59:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.28015205264091, 'train_avg_loss': 0.6940012671053409, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 13:59:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0411682128906, 'train_avg_loss': 0.6730024337768554, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 13:59:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 323.0411682128906, 'train_avg_loss': 0.6730024337768554, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 13:59:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 13:59:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 13:59:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:00:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:00:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.612946, avg_loss=0.667944, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:00:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:00:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:00:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:00:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2304MB allocated=2217MB
2025-10-10 14:00:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.08687394857407, 'train_avg_loss': 0.6923906162381173, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 14:00:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.6129455566406, 'train_avg_loss': 0.6679436365763346, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:00:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 320.6129455566406, 'train_avg_loss': 0.6679436365763346, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:00:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:00:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:00:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:00:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:00:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.593689, avg_loss=0.653320, seen=480, correct=298, accuracy=0.620833
2025-10-10 14:00:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:00:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:00:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:00:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2288MB allocated=2217MB
2025-10-10 14:00:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.29920053482056, 'train_avg_loss': 0.669160004456838, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 14:00:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.59368896484375, 'train_avg_loss': 0.6533201853434245, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:00:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 313.59368896484375, 'train_avg_loss': 0.6533201853434245, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:00:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:00:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:00:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:01:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:01:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.686646, avg_loss=0.663931, seen=480, correct=283, accuracy=0.589583
2025-10-10 14:01:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:01:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:01:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:01:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2336MB allocated=2217MB
2025-10-10 14:01:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.84527063369751, 'train_avg_loss': 0.6653772552808126, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 14:01:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.6866455078125, 'train_avg_loss': 0.6639305114746094, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 14:01:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 318.6866455078125, 'train_avg_loss': 0.6639305114746094, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 14:01:42 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #175) -------------
2025-10-10 14:01:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=175 aidx=4 | s=5 (candidates=17)
2025-10-10 14:01:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 17, 7, 13, 19] (from 17)
2025-10-10 14:01:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:01:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:01:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:02:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:02:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.371613, avg_loss=0.644524, seen=480, correct=293, accuracy=0.610417
2025-10-10 14:02:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:02:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:02:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:02:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2288MB allocated=2217MB
2025-10-10 14:02:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.54137128591537, 'train_avg_loss': 0.6045114273826281, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:02:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.3716125488281, 'train_avg_loss': 0.6445241928100586, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 14:02:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 309.3716125488281, 'train_avg_loss': 0.6445241928100586, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 14:02:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:02:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:02:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 14:02:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:02:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:02:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:02:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:02:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:02:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:02:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:02:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.769867, avg_loss=0.624521, seen=480, correct=310, accuracy=0.645833
2025-10-10 14:02:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:02:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:03:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:03:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2320MB allocated=2217MB
2025-10-10 14:03:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.74713236093521, 'train_avg_loss': 0.6062261030077934, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:03:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.7698669433594, 'train_avg_loss': 0.6245205561319987, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:03:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 299.7698669433594, 'train_avg_loss': 0.6245205561319987, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:03:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:03:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:03:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:03:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:03:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.446350, avg_loss=0.644680, seen=480, correct=304, accuracy=0.633333
2025-10-10 14:03:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:03:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:03:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:03:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2306MB allocated=2217MB
2025-10-10 14:03:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.69344961643219, 'train_avg_loss': 0.7057787468036015, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 14:03:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.44635009765625, 'train_avg_loss': 0.6446798960367839, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:03:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 309.44635009765625, 'train_avg_loss': 0.6446798960367839, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:03:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 14:03:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:03:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:04:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:04:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.776093, avg_loss=0.609950, seen=480, correct=333, accuracy=0.693750
2025-10-10 14:04:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:04:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:04:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:04:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2290MB allocated=2217MB
2025-10-10 14:04:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.75328975915909, 'train_avg_loss': 0.631277414659659, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 14:04:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.7760925292969, 'train_avg_loss': 0.6099501927693685, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 14:04:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 292.7760925292969, 'train_avg_loss': 0.6099501927693685, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 14:04:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:04:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:04:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:04:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:04:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.075928, avg_loss=0.648075, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:04:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:04:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:04:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:05:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2344MB allocated=2217MB
2025-10-10 14:05:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.95368176698685, 'train_avg_loss': 0.6329473480582237, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:05:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.075927734375, 'train_avg_loss': 0.6480748494466145, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:05:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 311.075927734375, 'train_avg_loss': 0.6480748494466145, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:05:01 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #176) -------------
2025-10-10 14:05:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=176 aidx=4 | s=5 (candidates=17)
2025-10-10 14:05:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 18, 17, 14, 7] (from 17)
2025-10-10 14:05:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 14:05:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:05:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:05:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:05:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.368408, avg_loss=0.657018, seen=480, correct=294, accuracy=0.612500
2025-10-10 14:05:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:05:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:05:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:05:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2292MB allocated=2217MB
2025-10-10 14:05:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.01441323757172, 'train_avg_loss': 0.6751201103130976, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 14:05:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.368408203125, 'train_avg_loss': 0.6570175170898438, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:05:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 315.368408203125, 'train_avg_loss': 0.6570175170898438, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:05:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:05:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:05:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 14:05:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 14:05:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:05:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:05:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:05:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:05:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:06:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:06:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.137390, avg_loss=0.654453, seen=480, correct=291, accuracy=0.606250
2025-10-10 14:06:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:06:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:06:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:06:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2314MB allocated=2217MB
2025-10-10 14:06:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.47904843091965, 'train_avg_loss': 0.6956587369243304, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 14:06:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.13739013671875, 'train_avg_loss': 0.654452896118164, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:06:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 314.13739013671875, 'train_avg_loss': 0.654452896118164, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:06:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:06:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:06:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 14:06:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:06:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:06:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:06:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:06:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:06:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:07:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:07:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.955444, avg_loss=0.624907, seen=480, correct=307, accuracy=0.639583
2025-10-10 14:07:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:07:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:07:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:07:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2320MB allocated=2217MB
2025-10-10 14:07:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.63035750389099, 'train_avg_loss': 0.6135863125324249, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 14:07:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.9554443359375, 'train_avg_loss': 0.6249071756998698, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 14:07:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 299.9554443359375, 'train_avg_loss': 0.6249071756998698, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 14:07:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:07:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:07:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 14:07:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:07:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:07:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:07:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:07:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:07:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:07:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:07:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.677490, avg_loss=0.636828, seen=480, correct=294, accuracy=0.612500
2025-10-10 14:07:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:07:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:07:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:07:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2288MB allocated=2217MB
2025-10-10 14:07:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.32328706979752, 'train_avg_loss': 0.594360725581646, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:07:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.677490234375, 'train_avg_loss': 0.6368281046549479, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:07:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 305.677490234375, 'train_avg_loss': 0.6368281046549479, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:07:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:07:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:07:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:08:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:08:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.087769, avg_loss=0.646016, seen=480, correct=299, accuracy=0.622917
2025-10-10 14:08:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:08:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:08:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:08:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2306MB allocated=2217MB
2025-10-10 14:08:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26264578104019, 'train_avg_loss': 0.7021887148420016, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 14:08:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.0877685546875, 'train_avg_loss': 0.6460161844889323, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 14:08:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 310.0877685546875, 'train_avg_loss': 0.6460161844889323, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 14:08:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #177) -------------
2025-10-10 14:08:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=177 aidx=4 | s=5 (candidates=17)
2025-10-10 14:08:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 17, 52, 46, 19] (from 17)
2025-10-10 14:08:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:08:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:08:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:09:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:09:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.538483, avg_loss=0.632372, seen=480, correct=310, accuracy=0.645833
2025-10-10 14:09:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:09:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:09:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:09:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2288MB allocated=2217MB
2025-10-10 14:09:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.0967521071434, 'train_avg_loss': 0.5841396008928617, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 14:09:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.5384826660156, 'train_avg_loss': 0.6323718388875326, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:09:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 303.5384826660156, 'train_avg_loss': 0.6323718388875326, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:09:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:09:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:09:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:09:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:09:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.763611, avg_loss=0.626591, seen=480, correct=308, accuracy=0.641667
2025-10-10 14:09:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:09:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:09:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:09:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2320MB allocated=2217MB
2025-10-10 14:09:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.54033893346786, 'train_avg_loss': 0.6211694911122322, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 14:09:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.76361083984375, 'train_avg_loss': 0.6265908559163411, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:09:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 300.76361083984375, 'train_avg_loss': 0.6265908559163411, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:09:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:09:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:09:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 14:09:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 14:09:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:09:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:09:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:09:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:09:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:10:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:10:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.315918, avg_loss=0.658991, seen=480, correct=289, accuracy=0.602083
2025-10-10 14:10:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:10:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:10:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:10:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2288MB allocated=2217MB
2025-10-10 14:10:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.81378918886185, 'train_avg_loss': 0.640114909907182, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 14:10:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.31591796875, 'train_avg_loss': 0.6589914957682291, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 14:10:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 316.31591796875, 'train_avg_loss': 0.6589914957682291, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 14:10:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:10:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:10:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 14:10:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 14:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:10:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:10:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:10:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:10:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:11:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:11:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.215027, avg_loss=0.673365, seen=480, correct=279, accuracy=0.581250
2025-10-10 14:11:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:11:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:11:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:11:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2310MB allocated=2217MB
2025-10-10 14:11:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.03056412935257, 'train_avg_loss': 0.650254701077938, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:11:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.21502685546875, 'train_avg_loss': 0.6733646392822266, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 14:11:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 323.21502685546875, 'train_avg_loss': 0.6733646392822266, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 14:11:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:11:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:11:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 14:11:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:11:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:11:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:11:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:11:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:11:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:11:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:11:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.311981, avg_loss=0.631900, seen=480, correct=306, accuracy=0.637500
2025-10-10 14:11:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:11:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:11:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:11:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2344MB allocated=2217MB
2025-10-10 14:11:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.20066609978676, 'train_avg_loss': 0.6100055508315563, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 14:11:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.3119812011719, 'train_avg_loss': 0.6318999608357747, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 14:11:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 303.3119812011719, 'train_avg_loss': 0.6318999608357747, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 14:11:57 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #178) -------------
2025-10-10 14:11:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=178 aidx=4 | s=5 (candidates=17)
2025-10-10 14:11:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 14, 19, 10, 49] (from 17)
2025-10-10 14:11:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:11:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:11:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 14:11:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:11:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:12:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:12:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:12:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:12:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:12:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:12:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.944000, avg_loss=0.656133, seen=480, correct=293, accuracy=0.610417
2025-10-10 14:12:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:12:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:12:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:12:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2336MB allocated=2217MB
2025-10-10 14:12:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.22503879666328, 'train_avg_loss': 0.668541989972194, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 14:12:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9440002441406, 'train_avg_loss': 0.6561333338419596, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 14:12:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 314.9440002441406, 'train_avg_loss': 0.6561333338419596, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 14:12:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:12:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:12:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:13:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:13:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.825409, avg_loss=0.630886, seen=480, correct=306, accuracy=0.637500
2025-10-10 14:13:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:13:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:13:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:13:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2288MB allocated=2217MB
2025-10-10 14:13:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.20173913240433, 'train_avg_loss': 0.585014492770036, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 14:13:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.8254089355469, 'train_avg_loss': 0.6308862686157226, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 14:13:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 302.8254089355469, 'train_avg_loss': 0.6308862686157226, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 14:13:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:13:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:13:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:13:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:13:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.580841, avg_loss=0.619960, seen=480, correct=317, accuracy=0.660417
2025-10-10 14:13:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:13:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:13:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:13:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2344MB allocated=2217MB
2025-10-10 14:13:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.35906225442886, 'train_avg_loss': 0.5946588521202405, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 14:13:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.5808410644531, 'train_avg_loss': 0.6199600855509441, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 14:13:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 297.5808410644531, 'train_avg_loss': 0.6199600855509441, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 14:13:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:13:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:13:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 14:14:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:14:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:14:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:14:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:14:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:14:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:14:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:14:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.581146, avg_loss=0.622044, seen=480, correct=308, accuracy=0.641667
2025-10-10 14:14:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:14:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:14:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:14:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2314MB allocated=2217MB
2025-10-10 14:14:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.41224101185799, 'train_avg_loss': 0.6117686750988166, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 14:14:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.5811462402344, 'train_avg_loss': 0.622044054667155, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:14:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 298.5811462402344, 'train_avg_loss': 0.622044054667155, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:14:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:14:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:14:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:15:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:15:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.045349, avg_loss=0.677178, seen=480, correct=284, accuracy=0.591667
2025-10-10 14:15:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:15:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:15:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:15:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2328MB allocated=2217MB
2025-10-10 14:15:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.39795523881912, 'train_avg_loss': 0.6949829603234927, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 14:15:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.04534912109375, 'train_avg_loss': 0.6771778106689453, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 14:15:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 325.04534912109375, 'train_avg_loss': 0.6771778106689453, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 14:15:19 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #179) -------------
2025-10-10 14:15:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=179 aidx=4 | s=5 (candidates=17)
2025-10-10 14:15:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 49, 23, 46, 35] (from 17)
2025-10-10 14:15:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:15:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:15:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:16:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:16:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.334137, avg_loss=0.631946, seen=480, correct=312, accuracy=0.650000
2025-10-10 14:16:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:16:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:16:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:16:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2306MB allocated=2217MB
2025-10-10 14:16:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9370042681694, 'train_avg_loss': 0.6994750355680783, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 14:16:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.3341369628906, 'train_avg_loss': 0.6319461186726888, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 14:16:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 303.3341369628906, 'train_avg_loss': 0.6319461186726888, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 14:16:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:16:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:16:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:16:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:16:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.981354, avg_loss=0.662461, seen=480, correct=291, accuracy=0.606250
2025-10-10 14:16:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:16:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:16:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:16:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2328MB allocated=2217MB
2025-10-10 14:16:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.60188868641853, 'train_avg_loss': 0.6716824057201545, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:16:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.9813537597656, 'train_avg_loss': 0.6624611536661784, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:16:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 317.9813537597656, 'train_avg_loss': 0.6624611536661784, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:16:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:16:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:16:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:17:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:17:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.135559, avg_loss=0.648199, seen=480, correct=300, accuracy=0.625000
2025-10-10 14:17:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:17:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:17:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:17:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2288MB allocated=2217MB
2025-10-10 14:17:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5284811258316, 'train_avg_loss': 0.6710706760485967, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 14:17:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.13555908203125, 'train_avg_loss': 0.6481990814208984, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 14:17:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 311.13555908203125, 'train_avg_loss': 0.6481990814208984, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 14:17:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 14:17:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:17:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:18:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:18:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.563538, avg_loss=0.669924, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:18:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:18:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:18:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:18:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2310MB allocated=2217MB
2025-10-10 14:18:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.85487306118011, 'train_avg_loss': 0.6487906088431676, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 14:18:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.56353759765625, 'train_avg_loss': 0.6699240366617839, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:18:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 321.56353759765625, 'train_avg_loss': 0.6699240366617839, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:18:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:18:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:18:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:18:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:18:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.496704, avg_loss=0.653118, seen=480, correct=289, accuracy=0.602083
2025-10-10 14:18:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:18:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:18:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:18:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2336MB allocated=2217MB
2025-10-10 14:18:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.96963304281235, 'train_avg_loss': 0.6580802753567696, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 14:18:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4967041015625, 'train_avg_loss': 0.6531181335449219, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 14:18:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 313.4967041015625, 'train_avg_loss': 0.6531181335449219, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 14:18:52 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #180) -------------
2025-10-10 14:18:52 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=180 aidx=4 | s=5 (candidates=17)
2025-10-10 14:18:52 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 13, 18, 17, 52] (from 17)
2025-10-10 14:18:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:18:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:18:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:19:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:19:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.277954, avg_loss=0.621412, seen=480, correct=314, accuracy=0.654167
2025-10-10 14:19:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:19:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:19:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:19:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2314MB allocated=2217MB
2025-10-10 14:19:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.72815278172493, 'train_avg_loss': 0.6144012731810411, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 14:19:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.2779541015625, 'train_avg_loss': 0.6214124043782552, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:19:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 298.2779541015625, 'train_avg_loss': 0.6214124043782552, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:19:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 14:19:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:19:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:20:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:20:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=288.641754, avg_loss=0.601337, seen=480, correct=326, accuracy=0.679167
2025-10-10 14:20:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:20:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:20:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:20:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2290MB allocated=2217MB
2025-10-10 14:20:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.3253418803215, 'train_avg_loss': 0.6193778490026792, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:20:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 288.6417541503906, 'train_avg_loss': 0.6013369878133138, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 14:20:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 288.6417541503906, 'train_avg_loss': 0.6013369878133138, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 14:20:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:20:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:20:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 14:20:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 14:20:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:20:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:20:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:20:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:20:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:20:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:20:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.874664, avg_loss=0.655989, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:20:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:20:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:20:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:20:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2314MB allocated=2217MB
2025-10-10 14:20:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.21972680091858, 'train_avg_loss': 0.7018310566743214, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 14:20:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.8746643066406, 'train_avg_loss': 0.6559888839721679, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:20:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 314.8746643066406, 'train_avg_loss': 0.6559888839721679, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:20:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:20:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:20:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:21:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:21:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.151276, avg_loss=0.623232, seen=480, correct=314, accuracy=0.654167
2025-10-10 14:21:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:21:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:21:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:21:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2320MB allocated=2217MB
2025-10-10 14:21:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.38536459207535, 'train_avg_loss': 0.6032113716006279, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 14:21:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.1512756347656, 'train_avg_loss': 0.6232318242390951, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:21:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 299.1512756347656, 'train_avg_loss': 0.6232318242390951, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:21:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 14:21:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:21:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:22:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:22:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.984100, avg_loss=0.656217, seen=480, correct=294, accuracy=0.612500
2025-10-10 14:22:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:22:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:22:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:22:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2288MB allocated=2217MB
2025-10-10 14:22:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.73545449972153, 'train_avg_loss': 0.6394621208310127, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 14:22:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9841003417969, 'train_avg_loss': 0.6562168757120769, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:22:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 314.9841003417969, 'train_avg_loss': 0.6562168757120769, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:22:15 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #181) -------------
2025-10-10 14:22:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=181 aidx=4 | s=5 (candidates=17)
2025-10-10 14:22:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 53, 23, 19, 9] (from 17)
2025-10-10 14:22:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:22:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:22:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:22:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:22:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.896088, avg_loss=0.666450, seen=480, correct=288, accuracy=0.600000
2025-10-10 14:22:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:22:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:22:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:22:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2328MB allocated=2217MB
2025-10-10 14:22:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.79311501979828, 'train_avg_loss': 0.673275958498319, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 14:22:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.8960876464844, 'train_avg_loss': 0.6664501825968424, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 14:22:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 319.8960876464844, 'train_avg_loss': 0.6664501825968424, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 14:22:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 14:22:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:22:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:23:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:23:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.026245, avg_loss=0.660471, seen=480, correct=301, accuracy=0.627083
2025-10-10 14:23:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:23:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:23:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:23:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2294MB allocated=2217MB
2025-10-10 14:23:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.78402438759804, 'train_avg_loss': 0.6148668698966503, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:23:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.0262451171875, 'train_avg_loss': 0.6604713439941406, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 14:23:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 317.0262451171875, 'train_avg_loss': 0.6604713439941406, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 14:23:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:23:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:23:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:24:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:24:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.468445, avg_loss=0.648893, seen=480, correct=303, accuracy=0.631250
2025-10-10 14:24:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:24:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:24:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:24:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2288MB allocated=2217MB
2025-10-10 14:24:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31892919540405, 'train_avg_loss': 0.6776577432950338, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 14:24:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.46844482421875, 'train_avg_loss': 0.648892593383789, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 14:24:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 311.46844482421875, 'train_avg_loss': 0.648892593383789, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 14:24:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:24:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:24:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:24:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:24:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.074097, avg_loss=0.625154, seen=480, correct=327, accuracy=0.681250
2025-10-10 14:24:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:24:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:24:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:24:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2344MB allocated=2217MB
2025-10-10 14:24:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.28022783994675, 'train_avg_loss': 0.6106685653328896, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 14:24:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.0740966796875, 'train_avg_loss': 0.6251543680826823, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 14:24:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 300.0740966796875, 'train_avg_loss': 0.6251543680826823, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 14:24:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:24:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:24:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 14:24:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 14:24:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:24:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:24:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:24:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:24:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:25:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:25:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.411621, avg_loss=0.667524, seen=480, correct=294, accuracy=0.612500
2025-10-10 14:25:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:25:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:25:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:25:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2304MB allocated=2217MB
2025-10-10 14:25:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06379878520966, 'train_avg_loss': 0.6838649898767472, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 14:25:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.41162109375, 'train_avg_loss': 0.6675242106119792, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:25:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 320.41162109375, 'train_avg_loss': 0.6675242106119792, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:25:38 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #182) -------------
2025-10-10 14:25:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=182 aidx=4 | s=5 (candidates=17)
2025-10-10 14:25:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 49, 35, 18, 7] (from 17)
2025-10-10 14:25:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:25:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:25:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 14:25:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:25:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:25:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:25:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:25:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:25:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:26:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:26:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.292084, avg_loss=0.642275, seen=480, correct=298, accuracy=0.620833
2025-10-10 14:26:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:26:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:26:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:26:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2288MB allocated=2217MB
2025-10-10 14:26:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.16495651006699, 'train_avg_loss': 0.6097079709172248, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 14:26:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.2920837402344, 'train_avg_loss': 0.6422751744588217, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:26:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 308.2920837402344, 'train_avg_loss': 0.6422751744588217, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:26:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:26:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:26:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:26:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:26:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.722656, avg_loss=0.666089, seen=480, correct=288, accuracy=0.600000
2025-10-10 14:26:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:26:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:26:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:26:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2328MB allocated=2217MB
2025-10-10 14:26:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.28675228357315, 'train_avg_loss': 0.6773896023631096, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 14:26:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.72265625, 'train_avg_loss': 0.6660888671875, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 14:26:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 319.72265625, 'train_avg_loss': 0.6660888671875, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 14:26:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:27:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:27:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 14:27:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:27:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:27:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:27:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:27:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:27:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:27:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:27:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.914001, avg_loss=0.643571, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:27:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:27:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:27:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:27:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2336MB allocated=2217MB
2025-10-10 14:27:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.0898072719574, 'train_avg_loss': 0.6424150605996449, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 14:27:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.91400146484375, 'train_avg_loss': 0.6435708363850912, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:27:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 308.91400146484375, 'train_avg_loss': 0.6435708363850912, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:27:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 14:27:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:27:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:28:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:28:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.698364, avg_loss=0.653538, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:28:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:28:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:28:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:28:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2312MB allocated=2217MB
2025-10-10 14:28:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.95902687311172, 'train_avg_loss': 0.6913252239425977, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 14:28:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.6983642578125, 'train_avg_loss': 0.6535382588704427, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:28:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 313.6983642578125, 'train_avg_loss': 0.6535382588704427, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:28:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:28:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:28:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:29:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:29:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.483643, avg_loss=0.636424, seen=480, correct=310, accuracy=0.645833
2025-10-10 14:29:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:29:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:29:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:29:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2306MB allocated=2217MB
2025-10-10 14:29:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.95953798294067, 'train_avg_loss': 0.6913294831911723, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 14:29:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.483642578125, 'train_avg_loss': 0.6364242553710937, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:29:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 305.483642578125, 'train_avg_loss': 0.6364242553710937, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:29:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #183) -------------
2025-10-10 14:29:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=183 aidx=4 | s=5 (candidates=17)
2025-10-10 14:29:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 9, 35, 38, 7] (from 17)
2025-10-10 14:29:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:29:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:29:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 14:29:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 14:29:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:29:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:29:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:29:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:29:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:29:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:29:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.600098, avg_loss=0.647084, seen=480, correct=294, accuracy=0.612500
2025-10-10 14:29:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:29:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:29:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:29:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2292MB allocated=2217MB
2025-10-10 14:29:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.3842584490776, 'train_avg_loss': 0.6698688204089801, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 14:29:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.60009765625, 'train_avg_loss': 0.6470835367838542, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:29:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 310.60009765625, 'train_avg_loss': 0.6470835367838542, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 14:29:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 14:29:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:29:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:30:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:30:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.018250, avg_loss=0.656288, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:30:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:30:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:30:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:30:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2304MB allocated=2217MB
2025-10-10 14:30:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.65825664997101, 'train_avg_loss': 0.6721521387497584, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:30:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.01824951171875, 'train_avg_loss': 0.6562880198160808, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:30:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 315.01824951171875, 'train_avg_loss': 0.6562880198160808, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:30:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:30:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:30:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:31:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:31:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.774139, avg_loss=0.645363, seen=480, correct=297, accuracy=0.618750
2025-10-10 14:31:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:31:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:31:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:31:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2336MB allocated=2217MB
2025-10-10 14:31:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.2757158279419, 'train_avg_loss': 0.6522976318995158, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 14:31:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.7741394042969, 'train_avg_loss': 0.6453627904256185, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:31:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 309.7741394042969, 'train_avg_loss': 0.6453627904256185, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 14:31:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:31:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:31:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 14:31:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 14:31:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:31:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:31:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:31:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:31:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:31:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:31:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.107361, avg_loss=0.650224, seen=480, correct=296, accuracy=0.616667
2025-10-10 14:31:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:31:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:31:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:31:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2308MB allocated=2217MB
2025-10-10 14:31:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.11381614208221, 'train_avg_loss': 0.6342818011840184, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:31:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.10736083984375, 'train_avg_loss': 0.6502236684163412, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:31:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 312.10736083984375, 'train_avg_loss': 0.6502236684163412, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:31:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:31:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:31:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:32:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:32:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.439148, avg_loss=0.621748, seen=480, correct=315, accuracy=0.656250
2025-10-10 14:32:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:32:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:32:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:32:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2306MB allocated=2217MB
2025-10-10 14:32:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.48993545770645, 'train_avg_loss': 0.6874161288142204, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 14:32:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.43914794921875, 'train_avg_loss': 0.6217482248942058, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 14:32:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 298.43914794921875, 'train_avg_loss': 0.6217482248942058, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 14:32:34 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #184) -------------
2025-10-10 14:32:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=184 aidx=4 | s=5 (candidates=17)
2025-10-10 14:32:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 53, 19, 13, 49] (from 17)
2025-10-10 14:32:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 14:32:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:32:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:33:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:33:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.142517, avg_loss=0.673214, seen=480, correct=278, accuracy=0.579167
2025-10-10 14:33:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:33:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:33:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:33:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2288MB allocated=2217MB
2025-10-10 14:33:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.71723306179047, 'train_avg_loss': 0.6476436088482539, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:33:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.14251708984375, 'train_avg_loss': 0.6732135772705078, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 14:33:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 323.14251708984375, 'train_avg_loss': 0.6732135772705078, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 14:33:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 14:33:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:33:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:33:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:33:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.141357, avg_loss=0.671128, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:33:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:33:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:33:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:33:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2294MB allocated=2217MB
2025-10-10 14:33:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.61570262908936, 'train_avg_loss': 0.6051308552424113, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:33:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.141357421875, 'train_avg_loss': 0.6711278279622396, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:33:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 322.141357421875, 'train_avg_loss': 0.6711278279622396, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:33:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:33:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:33:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:34:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:34:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.970886, avg_loss=0.624939, seen=480, correct=318, accuracy=0.662500
2025-10-10 14:34:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:34:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:34:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:34:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2344MB allocated=2217MB
2025-10-10 14:34:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.0349992364645, 'train_avg_loss': 0.6002916603038708, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:34:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.97088623046875, 'train_avg_loss': 0.6249393463134766, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 14:34:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 299.97088623046875, 'train_avg_loss': 0.6249393463134766, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 14:34:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 14:34:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:34:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:35:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:35:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.015015, avg_loss=0.595865, seen=480, correct=328, accuracy=0.683333
2025-10-10 14:35:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:35:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:35:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:35:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2290MB allocated=2217MB
2025-10-10 14:35:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.4341002702713, 'train_avg_loss': 0.6119508355855942, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 14:35:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.0150146484375, 'train_avg_loss': 0.5958646138509115, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 14:35:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 286.0150146484375, 'train_avg_loss': 0.5958646138509115, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 14:35:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:35:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:35:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 14:35:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:35:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:35:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:35:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:35:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:35:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:35:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:35:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.952515, avg_loss=0.666568, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:35:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:35:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:35:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:35:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2328MB allocated=2217MB
2025-10-10 14:35:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.97273173928261, 'train_avg_loss': 0.6831060978273551, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 14:35:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.9525146484375, 'train_avg_loss': 0.6665677388509115, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:35:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 319.9525146484375, 'train_avg_loss': 0.6665677388509115, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:35:56 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #185) -------------
2025-10-10 14:35:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=185 aidx=4 | s=5 (candidates=17)
2025-10-10 14:35:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 10, 13, 9, 46] (from 17)
2025-10-10 14:35:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:35:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:35:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:36:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:36:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.289337, avg_loss=0.621436, seen=480, correct=311, accuracy=0.647917
2025-10-10 14:36:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:36:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:36:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:36:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2314MB allocated=2217MB
2025-10-10 14:36:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.74066483974457, 'train_avg_loss': 0.6061722069978714, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 14:36:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.2893371582031, 'train_avg_loss': 0.6214361190795898, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 14:36:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 298.2893371582031, 'train_avg_loss': 0.6214361190795898, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 14:36:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:36:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:36:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 14:36:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:36:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:36:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:36:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:36:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:36:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:37:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:37:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.046692, avg_loss=0.612597, seen=480, correct=313, accuracy=0.652083
2025-10-10 14:37:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:37:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:37:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:37:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2314MB allocated=2217MB
2025-10-10 14:37:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.3566705584526, 'train_avg_loss': 0.6029722546537717, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 14:37:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.04669189453125, 'train_avg_loss': 0.6125972747802735, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 14:37:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 294.04669189453125, 'train_avg_loss': 0.6125972747802735, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 14:37:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 14:37:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:37:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:37:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:37:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.654419, avg_loss=0.597197, seen=480, correct=333, accuracy=0.693750
2025-10-10 14:37:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:37:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:37:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:37:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2290MB allocated=2217MB
2025-10-10 14:37:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.66977494955063, 'train_avg_loss': 0.605581457912922, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 14:37:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.6544189453125, 'train_avg_loss': 0.5971967061360677, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 14:37:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 286.6544189453125, 'train_avg_loss': 0.5971967061360677, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 14:37:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 14:37:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:37:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:38:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:38:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.867096, avg_loss=0.655973, seen=480, correct=296, accuracy=0.616667
2025-10-10 14:38:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:38:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:38:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:38:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2304MB allocated=2217MB
2025-10-10 14:38:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.68242239952087, 'train_avg_loss': 0.6723535199960072, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 14:38:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.8670959472656, 'train_avg_loss': 0.6559731165568033, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:38:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 314.8670959472656, 'train_avg_loss': 0.6559731165568033, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:38:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 14:38:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:38:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:39:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:39:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.681580, avg_loss=0.672253, seen=480, correct=281, accuracy=0.585417
2025-10-10 14:39:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:39:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:39:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:39:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2310MB allocated=2217MB
2025-10-10 14:39:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.31095093488693, 'train_avg_loss': 0.6525912577907245, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 14:39:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.68157958984375, 'train_avg_loss': 0.6722532908121744, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 14:39:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 322.68157958984375, 'train_avg_loss': 0.6722532908121744, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 14:39:17 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #186) -------------
2025-10-10 14:39:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=186 aidx=4 | s=5 (candidates=17)
2025-10-10 14:39:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 53, 14, 46, 9] (from 17)
2025-10-10 14:39:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:39:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:39:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 14:39:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:39:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:39:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:39:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:39:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:39:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:39:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:39:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.345306, avg_loss=0.619469, seen=480, correct=321, accuracy=0.668750
2025-10-10 14:39:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:39:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:39:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:40:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2314MB allocated=2217MB
2025-10-10 14:40:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.33310657739639, 'train_avg_loss': 0.6111092214783033, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:40:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.3453063964844, 'train_avg_loss': 0.6194693883260091, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 14:40:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 297.3453063964844, 'train_avg_loss': 0.6194693883260091, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 14:40:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:40:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:40:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 14:40:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 14:40:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:40:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:40:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:40:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:40:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:40:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:40:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.756165, avg_loss=0.659909, seen=480, correct=291, accuracy=0.606250
2025-10-10 14:40:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:40:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:40:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:40:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2294MB allocated=2217MB
2025-10-10 14:40:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.87350645661354, 'train_avg_loss': 0.6072792204717795, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:40:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.75616455078125, 'train_avg_loss': 0.659908676147461, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:40:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 316.75616455078125, 'train_avg_loss': 0.659908676147461, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 14:40:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 14:40:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:40:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:41:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:41:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.302887, avg_loss=0.633964, seen=480, correct=301, accuracy=0.627083
2025-10-10 14:41:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:41:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:41:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:41:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2288MB allocated=2217MB
2025-10-10 14:41:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.02535283565521, 'train_avg_loss': 0.5918779402971268, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 14:41:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.3028869628906, 'train_avg_loss': 0.6339643478393555, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 14:41:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 304.3028869628906, 'train_avg_loss': 0.6339643478393555, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 14:41:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:41:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:41:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 14:41:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 14:41:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:41:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:41:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:41:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:41:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:42:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:42:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.842377, avg_loss=0.660088, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:42:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:42:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:42:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:42:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2310MB allocated=2217MB
2025-10-10 14:42:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.88014882802963, 'train_avg_loss': 0.6406679069002469, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 14:42:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.8423767089844, 'train_avg_loss': 0.6600882848103841, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:42:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 316.8423767089844, 'train_avg_loss': 0.6600882848103841, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:42:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 14:42:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:42:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:42:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:42:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.066589, avg_loss=0.654305, seen=480, correct=298, accuracy=0.620833
2025-10-10 14:42:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:42:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:42:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:42:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2304MB allocated=2217MB
2025-10-10 14:42:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.89208143949509, 'train_avg_loss': 0.6657673453291257, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 14:42:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.06658935546875, 'train_avg_loss': 0.6543053944905599, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:42:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 314.06658935546875, 'train_avg_loss': 0.6543053944905599, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:42:47 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #187) -------------
2025-10-10 14:42:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=187 aidx=4 | s=5 (candidates=17)
2025-10-10 14:42:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 23, 49, 10, 19] (from 17)
2025-10-10 14:42:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 14:42:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:42:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:43:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:43:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.641479, avg_loss=0.661753, seen=480, correct=296, accuracy=0.616667
2025-10-10 14:43:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:43:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:43:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:43:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2294MB allocated=2217MB
2025-10-10 14:43:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.92039358615875, 'train_avg_loss': 0.6076699465513229, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 14:43:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.6414794921875, 'train_avg_loss': 0.6617530822753906, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:43:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 317.6414794921875, 'train_avg_loss': 0.6617530822753906, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:43:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:43:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:43:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 14:43:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:43:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:43:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:43:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:43:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:43:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:44:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:44:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.524170, avg_loss=0.651092, seen=480, correct=303, accuracy=0.631250
2025-10-10 14:44:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:44:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:44:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:44:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2288MB allocated=2217MB
2025-10-10 14:44:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.47897654771805, 'train_avg_loss': 0.6789914712309837, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 14:44:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.524169921875, 'train_avg_loss': 0.6510920206705729, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 14:44:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 312.524169921875, 'train_avg_loss': 0.6510920206705729, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 14:44:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:44:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:44:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 14:44:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 14:44:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:44:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:44:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:44:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:44:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:44:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:44:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.088684, avg_loss=0.656435, seen=480, correct=295, accuracy=0.614583
2025-10-10 14:44:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:44:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:44:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:44:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2328MB allocated=2217MB
2025-10-10 14:44:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.47941249608994, 'train_avg_loss': 0.6706617708007495, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 14:44:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.08868408203125, 'train_avg_loss': 0.6564347585042317, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:44:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 315.08868408203125, 'train_avg_loss': 0.6564347585042317, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:44:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:44:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:44:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:45:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:45:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.320282, avg_loss=0.617334, seen=480, correct=308, accuracy=0.641667
2025-10-10 14:45:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:45:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:45:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:45:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2314MB allocated=2217MB
2025-10-10 14:45:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.3103996515274, 'train_avg_loss': 0.6025866637627284, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:45:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.3202819824219, 'train_avg_loss': 0.6173339207967122, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:45:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 296.3202819824219, 'train_avg_loss': 0.6173339207967122, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 14:45:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:45:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:45:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 14:45:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:45:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:45:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:45:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:45:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:45:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:46:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:46:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.465790, avg_loss=0.623887, seen=480, correct=322, accuracy=0.670833
2025-10-10 14:46:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:46:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:46:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:46:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2344MB allocated=2217MB
2025-10-10 14:46:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.71643209457397, 'train_avg_loss': 0.6059702674547831, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 14:46:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.4657897949219, 'train_avg_loss': 0.6238870620727539, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 14:46:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 299.4657897949219, 'train_avg_loss': 0.6238870620727539, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 14:46:08 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #188) -------------
2025-10-10 14:46:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=188 aidx=4 | s=5 (candidates=17)
2025-10-10 14:46:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 52, 46, 19, 35] (from 17)
2025-10-10 14:46:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:46:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:46:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 14:46:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:46:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:46:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:46:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:46:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:46:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:46:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:46:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.772888, avg_loss=0.607860, seen=480, correct=314, accuracy=0.654167
2025-10-10 14:46:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:46:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:46:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:46:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2314MB allocated=2217MB
2025-10-10 14:46:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.0226737856865, 'train_avg_loss': 0.5918556148807208, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:46:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.77288818359375, 'train_avg_loss': 0.6078601837158203, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:46:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 291.77288818359375, 'train_avg_loss': 0.6078601837158203, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:46:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:46:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:46:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 14:46:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 14:46:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:46:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:46:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:46:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:46:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:47:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:47:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.197083, avg_loss=0.646244, seen=480, correct=304, accuracy=0.633333
2025-10-10 14:47:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:47:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:47:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:47:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2288MB allocated=2217MB
2025-10-10 14:47:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.00901180505753, 'train_avg_loss': 0.6250750983754794, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:47:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.19708251953125, 'train_avg_loss': 0.6462439219156901, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:47:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 310.19708251953125, 'train_avg_loss': 0.6462439219156901, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:47:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 14:47:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:47:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:48:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:48:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.417450, avg_loss=0.659203, seen=480, correct=299, accuracy=0.622917
2025-10-10 14:48:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:48:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:48:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:48:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2310MB allocated=2217MB
2025-10-10 14:48:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.06325370073318, 'train_avg_loss': 0.6338604475061099, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 14:48:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.4174499511719, 'train_avg_loss': 0.6592030207316081, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 14:48:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 316.4174499511719, 'train_avg_loss': 0.6592030207316081, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 14:48:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:48:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:48:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:48:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:48:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.293945, avg_loss=0.604779, seen=480, correct=328, accuracy=0.683333
2025-10-10 14:48:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:48:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:48:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:48:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2344MB allocated=2217MB
2025-10-10 14:48:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.49245619773865, 'train_avg_loss': 0.579103801647822, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 14:48:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.2939453125, 'train_avg_loss': 0.604779052734375, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 14:48:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 290.2939453125, 'train_avg_loss': 0.604779052734375, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 14:48:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:48:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:48:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 14:48:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:48:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:48:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:48:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:48:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:48:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:49:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:49:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.542542, avg_loss=0.644880, seen=480, correct=298, accuracy=0.620833
2025-10-10 14:49:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:49:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:49:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:49:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2336MB allocated=2217MB
2025-10-10 14:49:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.37999510765076, 'train_avg_loss': 0.6531666258970896, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 14:49:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.54254150390625, 'train_avg_loss': 0.6448802947998047, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:49:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 309.54254150390625, 'train_avg_loss': 0.6448802947998047, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 14:49:33 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #189) -------------
2025-10-10 14:49:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=189 aidx=4 | s=5 (candidates=17)
2025-10-10 14:49:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 12, 39, 19, 35] (from 17)
2025-10-10 14:49:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:49:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:49:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:50:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:50:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.856995, avg_loss=0.653869, seen=480, correct=302, accuracy=0.629167
2025-10-10 14:50:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:50:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:50:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:50:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2288MB allocated=2217MB
2025-10-10 14:50:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.43522477149963, 'train_avg_loss': 0.6786268730958303, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 14:50:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.85699462890625, 'train_avg_loss': 0.6538687388102213, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 14:50:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 313.85699462890625, 'train_avg_loss': 0.6538687388102213, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 14:50:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 14:50:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:50:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:50:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:50:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.907959, avg_loss=0.647725, seen=480, correct=295, accuracy=0.614583
2025-10-10 14:50:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:50:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:50:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:50:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2292MB allocated=2217MB
2025-10-10 14:50:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.22580352425575, 'train_avg_loss': 0.6685483627021312, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 14:50:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.907958984375, 'train_avg_loss': 0.6477249145507813, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:50:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 310.907958984375, 'train_avg_loss': 0.6477249145507813, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:50:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:50:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:50:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 14:50:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 14:50:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:50:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:50:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:50:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:50:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:51:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:51:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.714417, avg_loss=0.672322, seen=480, correct=280, accuracy=0.583333
2025-10-10 14:51:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:51:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:51:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:51:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2288MB allocated=2217MB
2025-10-10 14:51:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.49222874641418, 'train_avg_loss': 0.6541019062201182, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 14:51:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.71441650390625, 'train_avg_loss': 0.6723217010498047, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 14:51:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 322.71441650390625, 'train_avg_loss': 0.6723217010498047, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 14:51:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:51:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:51:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:52:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:52:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.853851, avg_loss=0.608029, seen=480, correct=331, accuracy=0.689583
2025-10-10 14:52:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:52:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:52:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:52:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2344MB allocated=2217MB
2025-10-10 14:52:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.05378279089928, 'train_avg_loss': 0.5921148565908273, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 14:52:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.8538513183594, 'train_avg_loss': 0.6080288569132487, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 14:52:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 291.8538513183594, 'train_avg_loss': 0.6080288569132487, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 14:52:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 14:52:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:52:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:52:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:52:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.040985, avg_loss=0.627169, seen=480, correct=310, accuracy=0.645833
2025-10-10 14:52:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:52:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:52:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:52:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2336MB allocated=2217MB
2025-10-10 14:52:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.99523013830185, 'train_avg_loss': 0.6249602511525154, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 14:52:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.0409851074219, 'train_avg_loss': 0.6271687189737956, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:52:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 301.0409851074219, 'train_avg_loss': 0.6271687189737956, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 14:52:54 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #190) -------------
2025-10-10 14:52:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=190 aidx=4 | s=5 (candidates=17)
2025-10-10 14:52:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 12, 38, 39, 23] (from 17)
2025-10-10 14:52:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:52:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:52:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 14:52:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:52:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:52:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:52:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:52:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:52:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:53:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:53:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.097015, avg_loss=0.612702, seen=480, correct=314, accuracy=0.654167
2025-10-10 14:53:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:53:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:53:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:53:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2306MB allocated=2217MB
2025-10-10 14:53:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.09271991252899, 'train_avg_loss': 0.6757726659377415, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 14:53:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.0970153808594, 'train_avg_loss': 0.6127021153767903, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:53:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 294.0970153808594, 'train_avg_loss': 0.6127021153767903, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 14:53:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:53:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:53:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 14:53:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 14:53:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:53:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:53:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:53:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:53:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:54:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:54:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.614899, avg_loss=0.651281, seen=480, correct=296, accuracy=0.616667
2025-10-10 14:54:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:54:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:54:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:54:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2292MB allocated=2217MB
2025-10-10 14:54:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.91623294353485, 'train_avg_loss': 0.6743019411961237, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 14:54:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6148986816406, 'train_avg_loss': 0.6512810389200846, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:54:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 312.6148986816406, 'train_avg_loss': 0.6512810389200846, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 14:54:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:54:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:54:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 14:54:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 14:54:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:54:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:54:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:54:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:54:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:54:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:54:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.464691, avg_loss=0.648885, seen=480, correct=292, accuracy=0.608333
2025-10-10 14:54:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:54:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:55:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:55:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2308MB allocated=2217MB
2025-10-10 14:55:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.49898773431778, 'train_avg_loss': 0.6291582311193148, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 14:55:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.4646911621094, 'train_avg_loss': 0.6488847732543945, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:55:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 311.4646911621094, 'train_avg_loss': 0.6488847732543945, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 14:55:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 14:55:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:55:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:55:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:55:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.133301, avg_loss=0.677361, seen=480, correct=280, accuracy=0.583333
2025-10-10 14:55:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:55:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:55:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:55:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2288MB allocated=2217MB
2025-10-10 14:55:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.96421349048615, 'train_avg_loss': 0.6580351124207179, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 14:55:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.13330078125, 'train_avg_loss': 0.6773610432942708, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 14:55:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 325.13330078125, 'train_avg_loss': 0.6773610432942708, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 14:55:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 14:55:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:55:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:56:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:56:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.175354, avg_loss=0.656615, seen=480, correct=304, accuracy=0.633333
2025-10-10 14:56:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:56:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:56:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:56:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2288MB allocated=2217MB
2025-10-10 14:56:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00831210613251, 'train_avg_loss': 0.6834026008844376, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 14:56:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.17535400390625, 'train_avg_loss': 0.6566153208414713, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:56:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 315.17535400390625, 'train_avg_loss': 0.6566153208414713, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 14:56:23 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #191) -------------
2025-10-10 14:56:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=191 aidx=4 | s=5 (candidates=17)
2025-10-10 14:56:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 38, 7, 10, 19] (from 17)
2025-10-10 14:56:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 14:56:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:56:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:57:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:57:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.358887, avg_loss=0.598664, seen=480, correct=325, accuracy=0.677083
2025-10-10 14:57:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:57:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:57:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:57:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2290MB allocated=2217MB
2025-10-10 14:57:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.12119549512863, 'train_avg_loss': 0.6093432957927386, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 14:57:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.35888671875, 'train_avg_loss': 0.5986643473307292, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 14:57:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 287.35888671875, 'train_avg_loss': 0.5986643473307292, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 14:57:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 14:57:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:57:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:57:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:57:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.815948, avg_loss=0.647533, seen=480, correct=295, accuracy=0.614583
2025-10-10 14:57:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:57:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:57:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:57:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2308MB allocated=2217MB
2025-10-10 14:57:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.91611766815186, 'train_avg_loss': 0.6326343139012655, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 14:57:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8159484863281, 'train_avg_loss': 0.6475332260131836, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:57:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 310.8159484863281, 'train_avg_loss': 0.6475332260131836, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 14:57:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 14:57:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:57:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:58:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:58:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.606995, avg_loss=0.615848, seen=480, correct=315, accuracy=0.656250
2025-10-10 14:58:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:58:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:58:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:58:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2306MB allocated=2217MB
2025-10-10 14:58:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.42896431684494, 'train_avg_loss': 0.6785747026403744, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 14:58:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.60699462890625, 'train_avg_loss': 0.6158479054768881, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 14:58:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 295.60699462890625, 'train_avg_loss': 0.6158479054768881, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 14:58:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:58:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:58:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 14:58:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 14:58:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:58:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:58:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:58:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:58:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:59:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:59:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.685303, avg_loss=0.613928, seen=480, correct=312, accuracy=0.650000
2025-10-10 14:59:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:59:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:59:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:59:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2314MB allocated=2217MB
2025-10-10 14:59:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.30482369661331, 'train_avg_loss': 0.6025401974717776, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 14:59:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.685302734375, 'train_avg_loss': 0.613927714029948, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 14:59:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 294.685302734375, 'train_avg_loss': 0.613927714029948, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 14:59:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 14:59:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:59:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 14:59:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 14:59:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.409363, avg_loss=0.609186, seen=480, correct=340, accuracy=0.708333
2025-10-10 14:59:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 14:59:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:59:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 14:59:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2344MB allocated=2217MB
2025-10-10 14:59:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.51416647434235, 'train_avg_loss': 0.5876180539528529, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 14:59:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.40936279296875, 'train_avg_loss': 0.6091861724853516, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-10 14:59:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 292.40936279296875, 'train_avg_loss': 0.6091861724853516, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-10 14:59:46 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #192) -------------
2025-10-10 14:59:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=192 aidx=4 | s=5 (candidates=17)
2025-10-10 14:59:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 19, 12, 46, 52] (from 17)
2025-10-10 14:59:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 14:59:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 14:59:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:00:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:00:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.720520, avg_loss=0.605668, seen=480, correct=325, accuracy=0.677083
2025-10-10 15:00:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:00:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:00:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:00:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2314MB allocated=2217MB
2025-10-10 15:00:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.01455640792847, 'train_avg_loss': 0.5917879700660705, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 15:00:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.72052001953125, 'train_avg_loss': 0.6056677500406901, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 15:00:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 290.72052001953125, 'train_avg_loss': 0.6056677500406901, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 15:00:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 15:00:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:00:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:01:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:01:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.873657, avg_loss=0.591403, seen=480, correct=340, accuracy=0.708333
2025-10-10 15:01:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:01:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:01:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:01:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2344MB allocated=2217MB
2025-10-10 15:01:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.70227539539337, 'train_avg_loss': 0.5725189616282781, 'train_seen': 120, 'train_correct': 89, 'train_acc': 0.7416666666666667}}
2025-10-10 15:01:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.8736572265625, 'train_avg_loss': 0.5914034525553385, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-10 15:01:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 283.8736572265625, 'train_avg_loss': 0.5914034525553385, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-10 15:01:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:01:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:01:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 15:01:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:01:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:01:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:01:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:01:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:01:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:01:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:01:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.203064, avg_loss=0.648340, seen=480, correct=297, accuracy=0.618750
2025-10-10 15:01:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:01:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:01:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2292MB allocated=2217MB
2025-10-10 15:01:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.03167396783829, 'train_avg_loss': 0.6669306163986524, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 15:01:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.20306396484375, 'train_avg_loss': 0.6483397165934245, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:01:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 311.20306396484375, 'train_avg_loss': 0.6483397165934245, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:01:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:01:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:01:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 15:01:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:01:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:01:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:01:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:01:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:01:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:02:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:02:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.704681, avg_loss=0.657718, seen=480, correct=302, accuracy=0.629167
2025-10-10 15:02:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:02:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:02:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:02:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2310MB allocated=2217MB
2025-10-10 15:02:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.58423238992691, 'train_avg_loss': 0.6215352699160576, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 15:02:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.7046813964844, 'train_avg_loss': 0.6577180862426758, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:02:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 315.7046813964844, 'train_avg_loss': 0.6577180862426758, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:02:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:02:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:02:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:03:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:03:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.529449, avg_loss=0.642770, seen=480, correct=306, accuracy=0.637500
2025-10-10 15:03:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:03:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:03:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:03:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2288MB allocated=2217MB
2025-10-10 15:03:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.70369106531143, 'train_avg_loss': 0.6141974255442619, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 15:03:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.5294494628906, 'train_avg_loss': 0.6427696863810222, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 15:03:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 308.5294494628906, 'train_avg_loss': 0.6427696863810222, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 15:03:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #193) -------------
2025-10-10 15:03:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=193 aidx=4 | s=5 (candidates=17)
2025-10-10 15:03:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 49, 23, 46, 39] (from 17)
2025-10-10 15:03:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 15:03:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:03:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:03:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:03:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.011841, avg_loss=0.629191, seen=480, correct=308, accuracy=0.641667
2025-10-10 15:03:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:03:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:03:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:03:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2288MB allocated=2217MB
2025-10-10 15:03:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.81689205765724, 'train_avg_loss': 0.5901407671471437, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:03:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.0118408203125, 'train_avg_loss': 0.6291913350423177, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:03:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 302.0118408203125, 'train_avg_loss': 0.6291913350423177, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:03:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:03:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:03:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:04:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:04:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.943268, avg_loss=0.651965, seen=480, correct=296, accuracy=0.616667
2025-10-10 15:04:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:04:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:04:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:04:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2328MB allocated=2217MB
2025-10-10 15:04:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.94357830286026, 'train_avg_loss': 0.6661964858571688, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:04:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.9432678222656, 'train_avg_loss': 0.6519651412963867, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 15:04:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 312.9432678222656, 'train_avg_loss': 0.6519651412963867, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 15:04:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:04:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:04:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:05:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:05:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.615234, avg_loss=0.628365, seen=480, correct=317, accuracy=0.660417
2025-10-10 15:05:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:05:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:05:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:05:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2288MB allocated=2217MB
2025-10-10 15:05:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.09211874008179, 'train_avg_loss': 0.6591009895006815, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 15:05:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.615234375, 'train_avg_loss': 0.6283650716145833, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:05:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 301.615234375, 'train_avg_loss': 0.6283650716145833, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:05:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:05:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:05:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:05:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:05:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.514526, avg_loss=0.655239, seen=480, correct=293, accuracy=0.610417
2025-10-10 15:05:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:05:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:05:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:05:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2310MB allocated=2217MB
2025-10-10 15:05:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.24746870994568, 'train_avg_loss': 0.6270622392495473, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:05:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.5145263671875, 'train_avg_loss': 0.6552385965983073, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 15:05:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 314.5145263671875, 'train_avg_loss': 0.6552385965983073, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 15:05:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:05:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:05:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 15:05:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 15:05:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:05:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:05:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:05:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:05:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:06:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:06:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.786804, avg_loss=0.670389, seen=480, correct=283, accuracy=0.589583
2025-10-10 15:06:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:06:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:06:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:06:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2288MB allocated=2217MB
2025-10-10 15:06:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.85209321975708, 'train_avg_loss': 0.657100776831309, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 15:06:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.78680419921875, 'train_avg_loss': 0.6703891754150391, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 15:06:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 321.78680419921875, 'train_avg_loss': 0.6703891754150391, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 15:06:28 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #194) -------------
2025-10-10 15:06:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=194 aidx=4 | s=5 (candidates=17)
2025-10-10 15:06:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 52, 13, 38, 35] (from 17)
2025-10-10 15:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:06:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:06:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:07:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:07:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.459290, avg_loss=0.632207, seen=480, correct=320, accuracy=0.666667
2025-10-10 15:07:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:07:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:07:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:07:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2288MB allocated=2217MB
2025-10-10 15:07:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.02179050445557, 'train_avg_loss': 0.6668482542037963, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:07:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.45928955078125, 'train_avg_loss': 0.6322068532307943, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 15:07:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 303.45928955078125, 'train_avg_loss': 0.6322068532307943, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 15:07:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:07:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:07:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:07:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:07:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.539154, avg_loss=0.630290, seen=480, correct=315, accuracy=0.656250
2025-10-10 15:07:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:07:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:07:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:07:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2288MB allocated=2217MB
2025-10-10 15:07:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.50319981575012, 'train_avg_loss': 0.6041933317979177, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:07:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.5391540527344, 'train_avg_loss': 0.63028990427653, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 15:07:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 302.5391540527344, 'train_avg_loss': 0.63028990427653, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 15:07:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:07:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:07:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 15:07:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 15:07:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:07:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:07:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:07:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:07:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:08:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:08:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.906250, avg_loss=0.597721, seen=480, correct=336, accuracy=0.700000
2025-10-10 15:08:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:08:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:08:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:08:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2290MB allocated=2217MB
2025-10-10 15:08:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.0952396094799, 'train_avg_loss': 0.6091269967456658, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:08:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.90625, 'train_avg_loss': 0.5977213541666667, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 15:08:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 286.90625, 'train_avg_loss': 0.5977213541666667, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 15:08:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 15:08:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:08:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:09:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:09:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.039978, avg_loss=0.643833, seen=480, correct=297, accuracy=0.618750
2025-10-10 15:09:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:09:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:09:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:09:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2308MB allocated=2217MB
2025-10-10 15:09:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.05644208192825, 'train_avg_loss': 0.6254703506827355, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:09:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.03997802734375, 'train_avg_loss': 0.6438332875569661, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:09:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 309.03997802734375, 'train_avg_loss': 0.6438332875569661, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:09:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 15:09:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:09:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:09:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:09:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.669189, avg_loss=0.620144, seen=480, correct=312, accuracy=0.650000
2025-10-10 15:09:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:09:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:09:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:09:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2336MB allocated=2217MB
2025-10-10 15:09:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.52412098646164, 'train_avg_loss': 0.6127010082205137, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:09:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.669189453125, 'train_avg_loss': 0.6201441446940105, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 15:09:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 297.669189453125, 'train_avg_loss': 0.6201441446940105, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 15:09:55 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #195) -------------
2025-10-10 15:09:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=195 aidx=4 | s=5 (candidates=17)
2025-10-10 15:09:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 18, 19, 13, 46] (from 17)
2025-10-10 15:09:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 15:09:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:09:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:10:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:10:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.680939, avg_loss=0.605585, seen=480, correct=316, accuracy=0.658333
2025-10-10 15:10:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:10:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:10:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:10:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2314MB allocated=2217MB
2025-10-10 15:10:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.06628504395485, 'train_avg_loss': 0.5838857086996238, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 15:10:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.6809387207031, 'train_avg_loss': 0.6055852890014648, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:10:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 290.6809387207031, 'train_avg_loss': 0.6055852890014648, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:10:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:10:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:10:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 15:10:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 15:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:10:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:10:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:10:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:10:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:11:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:11:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.340637, avg_loss=0.652793, seen=480, correct=306, accuracy=0.637500
2025-10-10 15:11:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:11:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:11:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:11:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2314MB allocated=2217MB
2025-10-10 15:11:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73367238044739, 'train_avg_loss': 0.6977806031703949, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 15:11:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.34063720703125, 'train_avg_loss': 0.6527929941813151, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 15:11:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 313.34063720703125, 'train_avg_loss': 0.6527929941813151, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 15:11:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 15:11:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:11:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:11:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:11:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.708374, avg_loss=0.597309, seen=480, correct=335, accuracy=0.697917
2025-10-10 15:11:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:11:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:11:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:11:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2344MB allocated=2217MB
2025-10-10 15:11:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.42022109031677, 'train_avg_loss': 0.5785018424193065, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:11:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.7083740234375, 'train_avg_loss': 0.5973091125488281, 'train_seen': 480, 'train_correct': 335, 'train_acc': 0.6979166666666666}}
2025-10-10 15:11:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 286.7083740234375, 'train_avg_loss': 0.5973091125488281, 'train_seen': 480, 'train_correct': 335, 'train_acc': 0.6979166666666666}}
2025-10-10 15:11:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 15:11:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:11:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:12:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:12:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.851349, avg_loss=0.597607, seen=480, correct=336, accuracy=0.700000
2025-10-10 15:12:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:12:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:12:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:12:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2290MB allocated=2217MB
2025-10-10 15:12:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.01731169223785, 'train_avg_loss': 0.6084775974353155, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:12:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.8513488769531, 'train_avg_loss': 0.5976069768269857, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 15:12:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 286.8513488769531, 'train_avg_loss': 0.5976069768269857, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 15:12:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:12:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:12:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:13:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:13:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.561096, avg_loss=0.657419, seen=480, correct=299, accuracy=0.622917
2025-10-10 15:13:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:13:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:13:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:13:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2310MB allocated=2217MB
2025-10-10 15:13:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.35161864757538, 'train_avg_loss': 0.6279301553964615, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:13:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.56109619140625, 'train_avg_loss': 0.657418950398763, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:13:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 315.56109619140625, 'train_avg_loss': 0.657418950398763, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:13:20 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #196) -------------
2025-10-10 15:13:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=196 aidx=4 | s=5 (candidates=17)
2025-10-10 15:13:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 7, 18, 35, 12] (from 17)
2025-10-10 15:13:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:13:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:13:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 15:13:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 15:13:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:13:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:13:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:13:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:13:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:13:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:13:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.926941, avg_loss=0.599848, seen=480, correct=334, accuracy=0.695833
2025-10-10 15:13:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:13:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:14:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:14:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2290MB allocated=2217MB
2025-10-10 15:14:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.72401523590088, 'train_avg_loss': 0.606033460299174, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 15:14:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.92694091796875, 'train_avg_loss': 0.5998477935791016, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 15:14:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 287.92694091796875, 'train_avg_loss': 0.5998477935791016, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 15:14:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:14:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:14:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:14:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:14:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.094849, avg_loss=0.616864, seen=480, correct=316, accuracy=0.658333
2025-10-10 15:14:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:14:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:14:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:14:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2306MB allocated=2217MB
2025-10-10 15:14:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.24286675453186, 'train_avg_loss': 0.6686905562877655, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 15:14:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.0948486328125, 'train_avg_loss': 0.616864267985026, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:14:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 296.0948486328125, 'train_avg_loss': 0.616864267985026, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:14:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 15:14:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:14:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:15:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:15:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.981049, avg_loss=0.649961, seen=480, correct=304, accuracy=0.633333
2025-10-10 15:15:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:15:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:15:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:15:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2314MB allocated=2217MB
2025-10-10 15:15:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.02677190303802, 'train_avg_loss': 0.6918897658586503, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 15:15:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9810485839844, 'train_avg_loss': 0.6499605178833008, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:15:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 311.9810485839844, 'train_avg_loss': 0.6499605178833008, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:15:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 15:15:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:15:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:16:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:16:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=288.353699, avg_loss=0.600737, seen=480, correct=323, accuracy=0.672917
2025-10-10 15:16:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:16:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:16:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:16:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2336MB allocated=2217MB
2025-10-10 15:16:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.72020444273949, 'train_avg_loss': 0.5976683703561624, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 15:16:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 288.35369873046875, 'train_avg_loss': 0.6007368723551433, 'train_seen': 480, 'train_correct': 323, 'train_acc': 0.6729166666666667}}
2025-10-10 15:16:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 288.35369873046875, 'train_avg_loss': 0.6007368723551433, 'train_seen': 480, 'train_correct': 323, 'train_acc': 0.6729166666666667}}
2025-10-10 15:16:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:16:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:16:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 15:16:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:16:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:16:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:16:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:16:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:16:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:16:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:16:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.584167, avg_loss=0.642884, seen=480, correct=303, accuracy=0.631250
2025-10-10 15:16:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:16:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:16:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:16:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2292MB allocated=2217MB
2025-10-10 15:16:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.3764796257019, 'train_avg_loss': 0.6614706635475158, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:16:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.58416748046875, 'train_avg_loss': 0.6428836822509766, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 15:16:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 308.58416748046875, 'train_avg_loss': 0.6428836822509766, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 15:16:49 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #197) -------------
2025-10-10 15:16:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=197 aidx=4 | s=5 (candidates=17)
2025-10-10 15:16:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 18, 12, 46, 38] (from 17)
2025-10-10 15:16:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:16:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:16:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 15:16:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:16:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:16:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:16:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:16:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:16:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:17:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:17:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.295258, avg_loss=0.615198, seen=480, correct=319, accuracy=0.664583
2025-10-10 15:17:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:17:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:17:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:17:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2306MB allocated=2217MB
2025-10-10 15:17:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.02943021059036, 'train_avg_loss': 0.6752452517549197, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 15:17:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2952575683594, 'train_avg_loss': 0.6151984532674154, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 15:17:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 295.2952575683594, 'train_avg_loss': 0.6151984532674154, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 15:17:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:17:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:17:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 15:17:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 15:17:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:17:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:17:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:17:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:17:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:18:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:18:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.059937, avg_loss=0.648042, seen=480, correct=299, accuracy=0.622917
2025-10-10 15:18:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:18:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:18:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:18:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2314MB allocated=2217MB
2025-10-10 15:18:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49319022893906, 'train_avg_loss': 0.6957765852411588, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 15:18:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.0599365234375, 'train_avg_loss': 0.6480415344238282, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:18:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 311.0599365234375, 'train_avg_loss': 0.6480415344238282, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:18:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:18:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:18:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:18:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:18:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.184631, avg_loss=0.623301, seen=480, correct=310, accuracy=0.645833
2025-10-10 15:18:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:18:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:18:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:18:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2292MB allocated=2217MB
2025-10-10 15:18:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.21020239591599, 'train_avg_loss': 0.6350850199659666, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 15:18:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.18463134765625, 'train_avg_loss': 0.6233013153076172, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:18:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 299.18463134765625, 'train_avg_loss': 0.6233013153076172, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:18:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:18:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:18:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:19:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:19:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.799500, avg_loss=0.641249, seen=480, correct=299, accuracy=0.622917
2025-10-10 15:19:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:19:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:19:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:19:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2310MB allocated=2217MB
2025-10-10 15:19:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.12106931209564, 'train_avg_loss': 0.6010089109341303, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:19:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.79949951171875, 'train_avg_loss': 0.6412489573160808, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:19:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 307.79949951171875, 'train_avg_loss': 0.6412489573160808, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:19:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 15:19:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:19:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:20:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:20:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.022095, avg_loss=0.637546, seen=480, correct=299, accuracy=0.622917
2025-10-10 15:20:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:20:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:20:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:20:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2308MB allocated=2217MB
2025-10-10 15:20:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.95277100801468, 'train_avg_loss': 0.6162730917334557, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:20:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.0220947265625, 'train_avg_loss': 0.6375460306803385, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:20:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 306.0220947265625, 'train_avg_loss': 0.6375460306803385, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:20:21 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #198) -------------
2025-10-10 15:20:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=198 aidx=4 | s=5 (candidates=17)
2025-10-10 15:20:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 52, 10, 23, 17] (from 17)
2025-10-10 15:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:20:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:20:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 15:20:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 15:20:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:20:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:20:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:20:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:20:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:20:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:20:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.250763, avg_loss=0.658856, seen=480, correct=286, accuracy=0.595833
2025-10-10 15:20:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:20:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:21:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:21:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2294MB allocated=2217MB
2025-10-10 15:21:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.66105163097382, 'train_avg_loss': 0.6221754302581152, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:21:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.2507629394531, 'train_avg_loss': 0.6588557561238607, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 15:21:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 316.2507629394531, 'train_avg_loss': 0.6588557561238607, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 15:21:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:21:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:21:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:21:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:21:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.217224, avg_loss=0.629619, seen=480, correct=308, accuracy=0.641667
2025-10-10 15:21:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:21:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:21:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:21:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2288MB allocated=2217MB
2025-10-10 15:21:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.87935864925385, 'train_avg_loss': 0.607327988743782, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 15:21:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.21722412109375, 'train_avg_loss': 0.6296192169189453, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:21:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 302.21722412109375, 'train_avg_loss': 0.6296192169189453, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:21:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:21:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:21:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:22:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:22:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.444153, avg_loss=0.607175, seen=480, correct=319, accuracy=0.664583
2025-10-10 15:22:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:22:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:22:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:22:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2314MB allocated=2217MB
2025-10-10 15:22:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.61789873242378, 'train_avg_loss': 0.5884824894368649, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:22:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.44415283203125, 'train_avg_loss': 0.6071753184000651, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 15:22:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 291.44415283203125, 'train_avg_loss': 0.6071753184000651, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 15:22:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:22:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:22:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:22:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:22:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.849762, avg_loss=0.628854, seen=480, correct=314, accuracy=0.654167
2025-10-10 15:22:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:22:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:23:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:23:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2288MB allocated=2217MB
2025-10-10 15:23:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.11440542340279, 'train_avg_loss': 0.6676200451950233, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 15:23:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.8497619628906, 'train_avg_loss': 0.6288536707560222, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:23:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 301.8497619628906, 'train_avg_loss': 0.6288536707560222, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:23:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 15:23:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:23:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:23:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:23:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.208496, avg_loss=0.604601, seen=480, correct=326, accuracy=0.679167
2025-10-10 15:23:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:23:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:23:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:23:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2320MB allocated=2217MB
2025-10-10 15:23:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.3421282172203, 'train_avg_loss': 0.6028510684768359, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:23:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.20849609375, 'train_avg_loss': 0.6046010335286458, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 15:23:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 290.20849609375, 'train_avg_loss': 0.6046010335286458, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 15:23:42 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #199) -------------
2025-10-10 15:23:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=199 aidx=4 | s=5 (candidates=17)
2025-10-10 15:23:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 7, 49, 46, 9] (from 17)
2025-10-10 15:23:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:23:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:23:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:24:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:24:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.476990, avg_loss=0.623910, seen=480, correct=316, accuracy=0.658333
2025-10-10 15:24:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:24:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:24:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:24:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2288MB allocated=2217MB
2025-10-10 15:24:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.68186968564987, 'train_avg_loss': 0.5973489140470822, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:24:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.47698974609375, 'train_avg_loss': 0.623910395304362, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:24:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 299.47698974609375, 'train_avg_loss': 0.623910395304362, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 15:24:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:24:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:24:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:25:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:25:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.274658, avg_loss=0.615156, seen=480, correct=308, accuracy=0.641667
2025-10-10 15:25:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:25:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:25:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:25:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2306MB allocated=2217MB
2025-10-10 15:25:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.29672998189926, 'train_avg_loss': 0.6774727498491605, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 15:25:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.274658203125, 'train_avg_loss': 0.6151555379231771, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:25:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 295.274658203125, 'train_avg_loss': 0.6151555379231771, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 15:25:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:25:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:25:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:25:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:25:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.257446, avg_loss=0.648453, seen=480, correct=296, accuracy=0.616667
2025-10-10 15:25:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:25:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:25:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:25:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2328MB allocated=2217MB
2025-10-10 15:25:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.49523288011551, 'train_avg_loss': 0.6707936073342959, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:25:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.2574462890625, 'train_avg_loss': 0.6484530131022136, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 15:25:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 311.2574462890625, 'train_avg_loss': 0.6484530131022136, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 15:25:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:25:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:25:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:26:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:26:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.376160, avg_loss=0.638284, seen=480, correct=300, accuracy=0.625000
2025-10-10 15:26:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:26:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:26:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:26:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2310MB allocated=2217MB
2025-10-10 15:26:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.5399464070797, 'train_avg_loss': 0.5961662200589974, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:26:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.37615966796875, 'train_avg_loss': 0.6382836659749349, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 15:26:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 306.37615966796875, 'train_avg_loss': 0.6382836659749349, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 15:26:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 15:26:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:26:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:27:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:27:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.249908, avg_loss=0.650521, seen=480, correct=298, accuracy=0.620833
2025-10-10 15:27:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:27:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:27:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:27:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2304MB allocated=2217MB
2025-10-10 15:27:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.77959793806076, 'train_avg_loss': 0.6814966494838397, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 15:27:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.2499084472656, 'train_avg_loss': 0.6505206425984701, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 15:27:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 312.2499084472656, 'train_avg_loss': 0.6505206425984701, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 15:27:07 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #200) -------------
2025-10-10 15:27:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=200 aidx=4 | s=5 (candidates=17)
2025-10-10 15:27:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 49, 23, 53, 10] (from 17)
2025-10-10 15:27:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:27:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:27:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:27:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:27:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.336334, avg_loss=0.642367, seen=480, correct=292, accuracy=0.608333
2025-10-10 15:27:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:27:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:27:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:27:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2310MB allocated=2217MB
2025-10-10 15:27:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.24493724107742, 'train_avg_loss': 0.6187078103423118, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 15:27:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.3363342285156, 'train_avg_loss': 0.6423673629760742, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 15:27:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 308.3363342285156, 'train_avg_loss': 0.6423673629760742, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 15:27:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:27:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:27:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:28:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:28:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.880798, avg_loss=0.649752, seen=480, correct=295, accuracy=0.614583
2025-10-10 15:28:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:28:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:28:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:28:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2328MB allocated=2217MB
2025-10-10 15:28:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.48164463043213, 'train_avg_loss': 0.6706803719202677, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:28:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.88079833984375, 'train_avg_loss': 0.6497516632080078, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:28:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 311.88079833984375, 'train_avg_loss': 0.6497516632080078, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:28:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:28:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:28:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:29:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:29:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.132660, avg_loss=0.633610, seen=480, correct=314, accuracy=0.654167
2025-10-10 15:29:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:29:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:29:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:29:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2288MB allocated=2217MB
2025-10-10 15:29:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.25598585605621, 'train_avg_loss': 0.6604665488004684, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 15:29:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.1326599121094, 'train_avg_loss': 0.6336097081502279, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:29:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 304.1326599121094, 'train_avg_loss': 0.6336097081502279, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:29:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:29:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:29:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 15:29:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 15:29:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:29:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:29:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:29:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:29:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:29:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:29:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.961182, avg_loss=0.658252, seen=480, correct=289, accuracy=0.602083
2025-10-10 15:29:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:29:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:29:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:29:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2294MB allocated=2217MB
2025-10-10 15:29:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.71138799190521, 'train_avg_loss': 0.61426156659921, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:29:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.961181640625, 'train_avg_loss': 0.658252461751302, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 15:29:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 315.961181640625, 'train_avg_loss': 0.658252461751302, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 15:29:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:29:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:29:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:30:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:30:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.076202, avg_loss=0.610575, seen=480, correct=310, accuracy=0.645833
2025-10-10 15:30:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:30:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:30:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:30:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2314MB allocated=2217MB
2025-10-10 15:30:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.70890232920647, 'train_avg_loss': 0.5809075194100539, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 15:30:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.0762023925781, 'train_avg_loss': 0.6105754216512044, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:30:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 293.0762023925781, 'train_avg_loss': 0.6105754216512044, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:30:35 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #201) -------------
2025-10-10 15:30:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=201 aidx=4 | s=5 (candidates=17)
2025-10-10 15:30:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 10, 35, 14, 46] (from 17)
2025-10-10 15:30:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:30:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:30:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 15:30:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:30:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:30:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:30:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:30:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:30:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:31:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:31:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.377563, avg_loss=0.619537, seen=480, correct=305, accuracy=0.635417
2025-10-10 15:31:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:31:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:31:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:31:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2306MB allocated=2217MB
2025-10-10 15:31:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.45545148849487, 'train_avg_loss': 0.6871287624041239, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 15:31:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.3775634765625, 'train_avg_loss': 0.6195365905761718, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 15:31:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 297.3775634765625, 'train_avg_loss': 0.6195365905761718, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 15:31:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:31:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:31:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:31:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:31:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.367523, avg_loss=0.588266, seen=480, correct=326, accuracy=0.679167
2025-10-10 15:31:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:31:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:31:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:31:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2314MB allocated=2217MB
2025-10-10 15:31:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.39193308353424, 'train_avg_loss': 0.5615994423627854, 'train_seen': 120, 'train_correct': 88, 'train_acc': 0.7333333333333333}}
2025-10-10 15:31:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.3675231933594, 'train_avg_loss': 0.5882656733194987, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 15:31:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 282.3675231933594, 'train_avg_loss': 0.5882656733194987, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 15:31:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 15:32:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:32:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:32:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:32:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.481445, avg_loss=0.609336, seen=480, correct=321, accuracy=0.668750
2025-10-10 15:32:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:32:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:32:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:32:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2336MB allocated=2217MB
2025-10-10 15:32:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.16912797093391, 'train_avg_loss': 0.6014093997577826, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:32:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.4814453125, 'train_avg_loss': 0.6093363444010417, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 15:32:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 292.4814453125, 'train_avg_loss': 0.6093363444010417, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 15:32:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 15:32:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:32:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:33:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:33:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.349365, avg_loss=0.627811, seen=480, correct=310, accuracy=0.645833
2025-10-10 15:33:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:33:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:33:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:33:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2288MB allocated=2217MB
2025-10-10 15:33:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.24164363741875, 'train_avg_loss': 0.5853470303118229, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:33:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.349365234375, 'train_avg_loss': 0.6278111775716145, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:33:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 301.349365234375, 'train_avg_loss': 0.6278111775716145, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:33:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:33:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:33:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:34:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:34:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.336914, avg_loss=0.644452, seen=480, correct=291, accuracy=0.606250
2025-10-10 15:34:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:34:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:34:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:34:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2310MB allocated=2217MB
2025-10-10 15:34:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.33568412065506, 'train_avg_loss': 0.6027973676721256, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 15:34:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.3369140625, 'train_avg_loss': 0.644451904296875, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 15:34:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 309.3369140625, 'train_avg_loss': 0.644451904296875, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 15:34:05 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #202) -------------
2025-10-10 15:34:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=202 aidx=4 | s=5 (candidates=17)
2025-10-10 15:34:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 13, 14, 49, 38] (from 17)
2025-10-10 15:34:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:34:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:34:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 15:34:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 15:34:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:34:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:34:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:34:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:34:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:34:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:34:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.580994, avg_loss=0.655377, seen=480, correct=295, accuracy=0.614583
2025-10-10 15:34:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:34:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:34:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:34:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2288MB allocated=2217MB
2025-10-10 15:34:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.14421397447586, 'train_avg_loss': 0.6428684497872988, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:34:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.58099365234375, 'train_avg_loss': 0.6553770701090494, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:34:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 314.58099365234375, 'train_avg_loss': 0.6553770701090494, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:34:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 15:34:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:34:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:35:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:35:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.011963, avg_loss=0.589608, seen=480, correct=334, accuracy=0.695833
2025-10-10 15:35:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:35:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:35:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:35:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2290MB allocated=2217MB
2025-10-10 15:35:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.11189526319504, 'train_avg_loss': 0.592599127193292, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 15:35:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.011962890625, 'train_avg_loss': 0.5896082560221354, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 15:35:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 283.011962890625, 'train_avg_loss': 0.5896082560221354, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 15:35:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 15:35:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:35:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:36:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:36:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.675842, avg_loss=0.628491, seen=480, correct=311, accuracy=0.647917
2025-10-10 15:36:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:36:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:36:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:36:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2288MB allocated=2217MB
2025-10-10 15:36:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.91845643520355, 'train_avg_loss': 0.5909871369600296, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:36:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.67584228515625, 'train_avg_loss': 0.6284913380940755, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 15:36:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 301.67584228515625, 'train_avg_loss': 0.6284913380940755, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 15:36:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:36:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:36:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:36:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:36:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.608398, avg_loss=0.642934, seen=480, correct=293, accuracy=0.610417
2025-10-10 15:36:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:36:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:36:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:36:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2328MB allocated=2217MB
2025-10-10 15:36:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.16781163215637, 'train_avg_loss': 0.6597317636013031, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:36:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.6083984375, 'train_avg_loss': 0.6429341634114584, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 15:36:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 308.6083984375, 'train_avg_loss': 0.6429341634114584, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 15:36:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:36:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:36:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 15:36:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 15:36:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:36:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:36:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:36:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:36:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:37:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:37:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.151031, avg_loss=0.623231, seen=480, correct=302, accuracy=0.629167
2025-10-10 15:37:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:37:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:37:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:37:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2308MB allocated=2217MB
2025-10-10 15:37:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.81640151143074, 'train_avg_loss': 0.6068033459285895, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:37:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.1510314941406, 'train_avg_loss': 0.623231315612793, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:37:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 299.1510314941406, 'train_avg_loss': 0.623231315612793, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:37:37 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #203) -------------
2025-10-10 15:37:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=203 aidx=4 | s=5 (candidates=17)
2025-10-10 15:37:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 17, 23, 10, 7] (from 17)
2025-10-10 15:37:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:37:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:37:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:38:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:38:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.935303, avg_loss=0.641532, seen=480, correct=298, accuracy=0.620833
2025-10-10 15:38:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:38:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:38:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:38:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2328MB allocated=2217MB
2025-10-10 15:38:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.8349180817604, 'train_avg_loss': 0.6569576506813367, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:38:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.935302734375, 'train_avg_loss': 0.6415318806966146, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 15:38:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 307.935302734375, 'train_avg_loss': 0.6415318806966146, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 15:38:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 15:38:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:38:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:38:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:38:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=280.827332, avg_loss=0.585057, seen=480, correct=338, accuracy=0.704167
2025-10-10 15:38:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:38:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:38:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:38:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2318MB allocated=2217MB
2025-10-10 15:38:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.51495507359505, 'train_avg_loss': 0.5876246256132921, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:38:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 280.82733154296875, 'train_avg_loss': 0.5850569407145182, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 15:38:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 280.82733154296875, 'train_avg_loss': 0.5850569407145182, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 15:38:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:38:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:38:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:39:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:39:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.788818, avg_loss=0.628727, seen=480, correct=315, accuracy=0.656250
2025-10-10 15:39:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:39:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:39:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:39:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2288MB allocated=2217MB
2025-10-10 15:39:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.08171254396439, 'train_avg_loss': 0.6673476045330365, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 15:39:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.788818359375, 'train_avg_loss': 0.6287267049153645, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 15:39:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 301.788818359375, 'train_avg_loss': 0.6287267049153645, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 15:39:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:39:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:39:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:40:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:40:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.068024, avg_loss=0.589725, seen=480, correct=324, accuracy=0.675000
2025-10-10 15:40:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:40:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:40:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:40:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2314MB allocated=2217MB
2025-10-10 15:40:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.98657393455505, 'train_avg_loss': 0.5665547827879588, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 15:40:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.0680236816406, 'train_avg_loss': 0.5897250493367513, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-10 15:40:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 283.0680236816406, 'train_avg_loss': 0.5897250493367513, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-10 15:40:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:40:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:40:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:40:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:40:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.042908, avg_loss=0.625089, seen=480, correct=304, accuracy=0.633333
2025-10-10 15:40:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:40:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:40:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:40:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2306MB allocated=2217MB
2025-10-10 15:40:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.05636143684387, 'train_avg_loss': 0.683803011973699, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 15:40:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.04290771484375, 'train_avg_loss': 0.6250893910725911, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:40:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 300.04290771484375, 'train_avg_loss': 0.6250893910725911, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:40:58 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #204) -------------
2025-10-10 15:40:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=204 aidx=4 | s=5 (candidates=17)
2025-10-10 15:40:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 9, 7, 23, 49] (from 17)
2025-10-10 15:40:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:41:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:41:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 15:41:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:41:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:41:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:41:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:41:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:41:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:41:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:41:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.551636, avg_loss=0.617816, seen=480, correct=301, accuracy=0.627083
2025-10-10 15:41:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:41:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:41:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:41:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2292MB allocated=2217MB
2025-10-10 15:41:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.75158095359802, 'train_avg_loss': 0.6312631746133168, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 15:41:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.5516357421875, 'train_avg_loss': 0.617815907796224, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 15:41:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 296.5516357421875, 'train_avg_loss': 0.617815907796224, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 15:41:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 15:41:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:41:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:42:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:42:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.935394, avg_loss=0.637365, seen=480, correct=307, accuracy=0.639583
2025-10-10 15:42:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:42:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:42:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:42:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2304MB allocated=2217MB
2025-10-10 15:42:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.65250742435455, 'train_avg_loss': 0.6554375618696213, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 15:42:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.9353942871094, 'train_avg_loss': 0.6373654047648112, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 15:42:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 305.9353942871094, 'train_avg_loss': 0.6373654047648112, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 15:42:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:42:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:42:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:42:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:42:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.453979, avg_loss=0.605112, seen=480, correct=314, accuracy=0.654167
2025-10-10 15:42:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:42:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:43:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:43:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2306MB allocated=2217MB
2025-10-10 15:43:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.51285165548325, 'train_avg_loss': 0.6626070971290271, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 15:43:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.4539794921875, 'train_avg_loss': 0.6051124572753906, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:43:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 290.4539794921875, 'train_avg_loss': 0.6051124572753906, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:43:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:43:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:43:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 15:43:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:43:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:43:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:43:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:43:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:43:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:43:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:43:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.922791, avg_loss=0.637339, seen=480, correct=314, accuracy=0.654167
2025-10-10 15:43:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:43:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:43:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:43:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2288MB allocated=2217MB
2025-10-10 15:43:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.37180507183075, 'train_avg_loss': 0.6780983755985895, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 15:43:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.92279052734375, 'train_avg_loss': 0.6373391469319661, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:43:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 305.92279052734375, 'train_avg_loss': 0.6373391469319661, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:43:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:43:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:43:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:44:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:44:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.381287, avg_loss=0.644544, seen=480, correct=294, accuracy=0.612500
2025-10-10 15:44:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:44:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:44:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:44:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2328MB allocated=2217MB
2025-10-10 15:44:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.07476365566254, 'train_avg_loss': 0.6672896971305211, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:44:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.38128662109375, 'train_avg_loss': 0.6445443471272786, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 15:44:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 309.38128662109375, 'train_avg_loss': 0.6445443471272786, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 15:44:23 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #205) -------------
2025-10-10 15:44:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=205 aidx=4 | s=5 (candidates=17)
2025-10-10 15:44:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 35, 39, 7, 10] (from 17)
2025-10-10 15:44:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:44:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:44:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 15:44:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:44:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:44:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:44:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:44:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:44:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:45:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:45:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.594116, avg_loss=0.628321, seen=480, correct=302, accuracy=0.629167
2025-10-10 15:45:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:45:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:45:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:45:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2310MB allocated=2217MB
2025-10-10 15:45:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.75860577821732, 'train_avg_loss': 0.5896550481518109, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:45:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.5941162109375, 'train_avg_loss': 0.6283210754394531, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:45:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 301.5941162109375, 'train_avg_loss': 0.6283210754394531, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 15:45:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 15:45:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:45:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:45:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:45:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.805176, avg_loss=0.607927, seen=480, correct=321, accuracy=0.668750
2025-10-10 15:45:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:45:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:45:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:45:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2336MB allocated=2217MB
2025-10-10 15:45:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.51911628246307, 'train_avg_loss': 0.6043259690205256, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:45:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.80517578125, 'train_avg_loss': 0.6079274495442708, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 15:45:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 291.80517578125, 'train_avg_loss': 0.6079274495442708, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 15:45:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 15:45:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:45:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:46:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:46:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.192169, avg_loss=0.652484, seen=480, correct=291, accuracy=0.606250
2025-10-10 15:46:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:46:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:46:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:46:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2288MB allocated=2217MB
2025-10-10 15:46:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.7229990363121, 'train_avg_loss': 0.6310249919692675, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 15:46:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.1921691894531, 'train_avg_loss': 0.6524836858113606, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 15:46:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 313.1921691894531, 'train_avg_loss': 0.6524836858113606, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 15:46:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:46:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:46:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 15:46:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:46:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:46:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:46:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:46:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:46:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:47:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:47:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=288.856384, avg_loss=0.601784, seen=480, correct=317, accuracy=0.660417
2025-10-10 15:47:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:47:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:47:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:47:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2306MB allocated=2217MB
2025-10-10 15:47:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.789579808712, 'train_avg_loss': 0.6649131650726, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 15:47:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 288.85638427734375, 'train_avg_loss': 0.6017841339111328, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:47:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 288.85638427734375, 'train_avg_loss': 0.6017841339111328, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:47:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:47:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:47:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:47:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:47:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=281.807831, avg_loss=0.587100, seen=480, correct=322, accuracy=0.670833
2025-10-10 15:47:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:47:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:47:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:47:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2314MB allocated=2217MB
2025-10-10 15:47:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.14984169602394, 'train_avg_loss': 0.5595820141335328, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 15:47:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 281.8078308105469, 'train_avg_loss': 0.5870996475219726, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 15:47:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 281.8078308105469, 'train_avg_loss': 0.5870996475219726, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 15:47:48 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #206) -------------
2025-10-10 15:47:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=206 aidx=4 | s=5 (candidates=17)
2025-10-10 15:47:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 52, 17, 23, 10] (from 17)
2025-10-10 15:47:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 15:47:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:47:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:48:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:48:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.719299, avg_loss=0.653582, seen=480, correct=295, accuracy=0.614583
2025-10-10 15:48:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:48:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:48:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:48:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2288MB allocated=2217MB
2025-10-10 15:48:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.27623051404953, 'train_avg_loss': 0.6356352542837461, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 15:48:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.71929931640625, 'train_avg_loss': 0.6535818735758464, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:48:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 313.71929931640625, 'train_avg_loss': 0.6535818735758464, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 15:48:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:48:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:48:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:49:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:49:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.945892, avg_loss=0.626971, seen=480, correct=310, accuracy=0.645833
2025-10-10 15:49:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:49:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:49:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:49:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2288MB allocated=2217MB
2025-10-10 15:49:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.03028413653374, 'train_avg_loss': 0.6002523678044478, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 15:49:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.9458923339844, 'train_avg_loss': 0.6269706090291342, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:49:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 300.9458923339844, 'train_avg_loss': 0.6269706090291342, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 15:49:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 15:49:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:49:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:49:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:49:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=281.847229, avg_loss=0.587182, seen=480, correct=329, accuracy=0.685417
2025-10-10 15:49:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:49:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:49:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:49:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2320MB allocated=2217MB
2025-10-10 15:49:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.6510037779808, 'train_avg_loss': 0.5887583648165067, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:49:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 281.84722900390625, 'train_avg_loss': 0.5871817270914713, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 15:49:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 281.84722900390625, 'train_avg_loss': 0.5871817270914713, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 15:49:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 15:49:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:49:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:50:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:50:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.677216, avg_loss=0.634744, seen=480, correct=313, accuracy=0.652083
2025-10-10 15:50:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:50:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:50:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:50:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2288MB allocated=2217MB
2025-10-10 15:50:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.622334420681, 'train_avg_loss': 0.6718527868390083, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 15:50:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.6772155761719, 'train_avg_loss': 0.6347441991170247, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 15:50:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 304.6772155761719, 'train_avg_loss': 0.6347441991170247, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 15:50:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:50:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:50:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 15:50:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:50:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:50:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:50:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:50:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:50:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:51:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:51:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=275.114166, avg_loss=0.573155, seen=480, correct=331, accuracy=0.689583
2025-10-10 15:51:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:51:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:51:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:51:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2314MB allocated=2217MB
2025-10-10 15:51:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 65.20926651358604, 'train_avg_loss': 0.5434105542798837, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-10 15:51:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 275.1141662597656, 'train_avg_loss': 0.5731545130411784, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 15:51:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 275.1141662597656, 'train_avg_loss': 0.5731545130411784, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 15:51:12 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #207) -------------
2025-10-10 15:51:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=207 aidx=4 | s=5 (candidates=17)
2025-10-10 15:51:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 39, 52, 14, 12] (from 17)
2025-10-10 15:51:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:51:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:51:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 15:51:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 15:51:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:51:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:51:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:51:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:51:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:51:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:51:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.276642, avg_loss=0.633910, seen=480, correct=304, accuracy=0.633333
2025-10-10 15:51:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:51:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:51:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:51:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2328MB allocated=2217MB
2025-10-10 15:51:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.20616948604584, 'train_avg_loss': 0.6433847457170486, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:51:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.2766418457031, 'train_avg_loss': 0.6339096705118815, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:51:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 304.2766418457031, 'train_avg_loss': 0.6339096705118815, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 15:51:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 15:51:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:51:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:52:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:52:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.748596, avg_loss=0.657810, seen=480, correct=299, accuracy=0.622917
2025-10-10 15:52:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:52:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:52:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:52:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2288MB allocated=2217MB
2025-10-10 15:52:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.3438241481781, 'train_avg_loss': 0.6361985345681508, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:52:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.74859619140625, 'train_avg_loss': 0.6578095753987631, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:52:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 315.74859619140625, 'train_avg_loss': 0.6578095753987631, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 15:52:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:52:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:52:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:53:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:53:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.810638, avg_loss=0.628772, seen=480, correct=312, accuracy=0.650000
2025-10-10 15:53:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:53:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:53:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:53:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2288MB allocated=2217MB
2025-10-10 15:53:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.23741868138313, 'train_avg_loss': 0.6019784890115261, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:53:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.8106384277344, 'train_avg_loss': 0.6287721633911133, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 15:53:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 301.8106384277344, 'train_avg_loss': 0.6287721633911133, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 15:53:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 15:53:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:53:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:53:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:53:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.201050, avg_loss=0.619169, seen=480, correct=317, accuracy=0.660417
2025-10-10 15:53:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:53:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:53:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:54:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2288MB allocated=2217MB
2025-10-10 15:54:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.09269747138023, 'train_avg_loss': 0.5674391455948353, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 15:54:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.2010498046875, 'train_avg_loss': 0.6191688537597656, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:54:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 297.2010498046875, 'train_avg_loss': 0.6191688537597656, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 15:54:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:54:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:54:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:54:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:54:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.496674, avg_loss=0.619785, seen=480, correct=307, accuracy=0.639583
2025-10-10 15:54:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:54:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:54:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:54:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2292MB allocated=2217MB
2025-10-10 15:54:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.0780545771122, 'train_avg_loss': 0.617317121475935, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 15:54:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.4966735839844, 'train_avg_loss': 0.6197847366333008, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 15:54:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 297.4966735839844, 'train_avg_loss': 0.6197847366333008, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 15:54:41 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #208) -------------
2025-10-10 15:54:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=208 aidx=4 | s=5 (candidates=17)
2025-10-10 15:54:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 12, 52, 46, 7] (from 17)
2025-10-10 15:54:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 15:54:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:54:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:55:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:55:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=267.474182, avg_loss=0.557238, seen=480, correct=346, accuracy=0.720833
2025-10-10 15:55:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:55:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:55:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:55:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2314MB allocated=2217MB
2025-10-10 15:55:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 63.44775706529617, 'train_avg_loss': 0.5287313088774681, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-10 15:55:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 267.47418212890625, 'train_avg_loss': 0.5572378794352214, 'train_seen': 480, 'train_correct': 346, 'train_acc': 0.7208333333333333}}
2025-10-10 15:55:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 267.47418212890625, 'train_avg_loss': 0.5572378794352214, 'train_seen': 480, 'train_correct': 346, 'train_acc': 0.7208333333333333}}
2025-10-10 15:55:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:55:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:55:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 15:55:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 15:55:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:55:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:55:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:55:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:55:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:55:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:55:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=288.070221, avg_loss=0.600146, seen=480, correct=318, accuracy=0.662500
2025-10-10 15:55:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:55:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:56:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:56:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2292MB allocated=2217MB
2025-10-10 15:56:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.09568236768246, 'train_avg_loss': 0.6007973530640205, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 15:56:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 288.0702209472656, 'train_avg_loss': 0.6001462936401367, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 15:56:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 288.0702209472656, 'train_avg_loss': 0.6001462936401367, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 15:56:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:56:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:56:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 15:56:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 15:56:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:56:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:56:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:56:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:56:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:56:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:56:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.697449, avg_loss=0.624370, seen=480, correct=314, accuracy=0.654167
2025-10-10 15:56:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:56:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:56:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:56:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2288MB allocated=2217MB
2025-10-10 15:56:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.86366587877274, 'train_avg_loss': 0.6071972156564395, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 15:56:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.69744873046875, 'train_avg_loss': 0.6243696848551432, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:56:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 299.69744873046875, 'train_avg_loss': 0.6243696848551432, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 15:56:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 15:56:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:56:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:57:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:57:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.780640, avg_loss=0.637043, seen=480, correct=297, accuracy=0.618750
2025-10-10 15:57:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:57:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:57:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:57:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2310MB allocated=2217MB
2025-10-10 15:57:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.28410577774048, 'train_avg_loss': 0.5857008814811706, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 15:57:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.7806396484375, 'train_avg_loss': 0.6370429992675781, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:57:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 305.7806396484375, 'train_avg_loss': 0.6370429992675781, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 15:57:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 15:57:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:57:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:58:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:58:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.420532, avg_loss=0.607126, seen=480, correct=318, accuracy=0.662500
2025-10-10 15:58:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:58:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:58:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:58:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2306MB allocated=2217MB
2025-10-10 15:58:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91529378294945, 'train_avg_loss': 0.6826274481912454, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 15:58:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.4205322265625, 'train_avg_loss': 0.6071261088053386, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 15:58:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 291.4205322265625, 'train_avg_loss': 0.6071261088053386, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 15:58:09 (federatedscope.core.workers.server:471) INFO: ----------- Starting a new training round (Round #209) -------------
2025-10-10 15:58:10 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=209 aidx=4 | s=5 (candidates=17)
2025-10-10 15:58:10 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 19, 38, 39, 53] (from 17)
2025-10-10 15:58:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:58:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:58:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 15:58:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 15:58:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:58:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:58:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:58:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:58:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:58:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:58:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=277.921204, avg_loss=0.579003, seen=480, correct=339, accuracy=0.706250
2025-10-10 15:58:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:58:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:58:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:58:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2290MB allocated=2217MB
2025-10-10 15:58:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.62252998352051, 'train_avg_loss': 0.5801877498626709, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 15:58:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 277.92120361328125, 'train_avg_loss': 0.5790025075276692, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 15:58:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 277.92120361328125, 'train_avg_loss': 0.5790025075276692, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 15:58:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:58:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:58:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 15:58:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 15:58:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:58:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:58:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:58:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:58:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 15:59:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 15:59:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.899994, avg_loss=0.589375, seen=480, correct=339, accuracy=0.706250
2025-10-10 15:59:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 15:59:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:59:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 15:59:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2344MB allocated=2217MB
2025-10-10 15:59:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.30418959259987, 'train_avg_loss': 0.5692015799383322, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 15:59:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.8999938964844, 'train_avg_loss': 0.5893749872843425, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 15:59:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 282.8999938964844, 'train_avg_loss': 0.5893749872843425, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-10 15:59:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 15:59:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 15:59:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 16:00:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 16:00:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.680969, avg_loss=0.618085, seen=480, correct=300, accuracy=0.625000
2025-10-10 16:00:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 16:00:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 16:00:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 16:00:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2308MB allocated=2217MB
2025-10-10 16:00:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.8250880241394, 'train_avg_loss': 0.5902090668678284, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 16:00:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.68096923828125, 'train_avg_loss': 0.6180853525797526, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 16:00:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 296.68096923828125, 'train_avg_loss': 0.6180853525797526, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 16:00:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 16:00:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 16:00:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 16:00:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 16:00:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.464569, avg_loss=0.659301, seen=480, correct=296, accuracy=0.616667
2025-10-10 16:00:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 16:00:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 16:00:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 16:00:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2288MB allocated=2217MB
2025-10-10 16:00:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.06233930587769, 'train_avg_loss': 0.6338528275489808, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 16:00:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.4645690917969, 'train_avg_loss': 0.6593011856079102, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 16:00:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 316.4645690917969, 'train_avg_loss': 0.6593011856079102, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 16:00:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 16:00:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 16:00:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 16:01:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 16:01:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.114685, avg_loss=0.671072, seen=480, correct=289, accuracy=0.602083
2025-10-10 16:01:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 16:01:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140250747764736 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 16:01:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 16:01:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2294MB allocated=2217MB
2025-10-10 16:01:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.14759370684624, 'train_avg_loss': 0.626229947557052, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 16:01:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.11468505859375, 'train_avg_loss': 0.671072260538737, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 16:01:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 322.11468505859375, 'train_avg_loss': 0.671072260538737, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 16:01:34 (federatedscope.core.workers.server:493) INFO: Server: Training is finished! (skip final evaluation)
2025-10-10 16:01:34 (federatedscope.core.monitors.monitor:268) INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 702.4760547000001, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 154520, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:34 (federatedscope.core.workers.client:842) INFO: ================= client 1 received finish message =================
2025-10-10 16:01:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:35 (federatedscope.core.monitors.monitor:268) INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 702.4939377333334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:35 (federatedscope.core.workers.client:842) INFO: ================= client 2 received finish message =================
2025-10-10 16:01:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:35 (federatedscope.core.monitors.monitor:268) INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 702.4242642833334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510240, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:35 (federatedscope.core.workers.client:842) INFO: ================= client 3 received finish message =================
2025-10-10 16:01:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:35 (federatedscope.core.monitors.monitor:268) INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 702.3855498666667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:35 (federatedscope.core.workers.client:842) INFO: ================= client 4 received finish message =================
2025-10-10 16:01:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:35 (federatedscope.core.monitors.monitor:268) INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 702.3398822, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:35 (federatedscope.core.workers.client:842) INFO: ================= client 5 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 702.2985586333333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 11377056, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 6 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 702.2571928166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 7 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 702.2159220166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 8 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 702.1694501666666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510240, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 9 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 702.1277690833334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 10665992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 10 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 702.0859319166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16354504, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 11 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #11, the system-related metrics are: {'id': 11, 'fl_end_time_minutes': 702.0448785666666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510240, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 12 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #12, the system-related metrics are: {'id': 12, 'fl_end_time_minutes': 702.0036533166666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 13 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #13, the system-related metrics are: {'id': 13, 'fl_end_time_minutes': 701.9572046333334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15643440, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 14 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #14, the system-related metrics are: {'id': 14, 'fl_end_time_minutes': 701.8985297833333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 15 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #15, the system-related metrics are: {'id': 15, 'fl_end_time_minutes': 701.8560551833333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 16 received finish message =================
2025-10-10 16:01:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:36 (federatedscope.core.monitors.monitor:268) INFO: In worker #16, the system-related metrics are: {'id': 16, 'fl_end_time_minutes': 701.8155128333333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 9243864, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:36 (federatedscope.core.workers.client:842) INFO: ================= client 17 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #17, the system-related metrics are: {'id': 17, 'fl_end_time_minutes': 701.7744490666666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 18 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #18, the system-related metrics are: {'id': 18, 'fl_end_time_minutes': 701.7314168833333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 11377056, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 19 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #19, the system-related metrics are: {'id': 19, 'fl_end_time_minutes': 701.68731965, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 20 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #20, the system-related metrics are: {'id': 20, 'fl_end_time_minutes': 701.6459628833333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12088120, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 21 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #21, the system-related metrics are: {'id': 21, 'fl_end_time_minutes': 701.6043817833332, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 22 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #22, the system-related metrics are: {'id': 22, 'fl_end_time_minutes': 701.56328835, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12088120, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 23 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #23, the system-related metrics are: {'id': 23, 'fl_end_time_minutes': 701.5222180833333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 24 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #24, the system-related metrics are: {'id': 24, 'fl_end_time_minutes': 701.4809224166668, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 25 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #25, the system-related metrics are: {'id': 25, 'fl_end_time_minutes': 701.4396780166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 26 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #26, the system-related metrics are: {'id': 26, 'fl_end_time_minutes': 701.3968998333334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 27 received finish message =================
2025-10-10 16:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:37 (federatedscope.core.monitors.monitor:268) INFO: In worker #27, the system-related metrics are: {'id': 27, 'fl_end_time_minutes': 701.3525523000001, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:37 (federatedscope.core.workers.client:842) INFO: ================= client 28 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #28, the system-related metrics are: {'id': 28, 'fl_end_time_minutes': 701.29429915, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14932376, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 29 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #29, the system-related metrics are: {'id': 29, 'fl_end_time_minutes': 701.2527540833332, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 30 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #30, the system-related metrics are: {'id': 30, 'fl_end_time_minutes': 701.2113411666667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12088120, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 31 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #31, the system-related metrics are: {'id': 31, 'fl_end_time_minutes': 701.1704461166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 11377056, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 32 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #32, the system-related metrics are: {'id': 32, 'fl_end_time_minutes': 701.1292771333334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17065568, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 33 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #33, the system-related metrics are: {'id': 33, 'fl_end_time_minutes': 701.0881743833332, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 34 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #34, the system-related metrics are: {'id': 34, 'fl_end_time_minutes': 701.04729905, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 35 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #35, the system-related metrics are: {'id': 35, 'fl_end_time_minutes': 701.0046185166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14932376, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 36 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #36, the system-related metrics are: {'id': 36, 'fl_end_time_minutes': 700.9602464333333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12088120, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 37 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #37, the system-related metrics are: {'id': 37, 'fl_end_time_minutes': 700.9189342333334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 11377056, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 38 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #38, the system-related metrics are: {'id': 38, 'fl_end_time_minutes': 700.8775974, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 9954928, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 39 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #39, the system-related metrics are: {'id': 39, 'fl_end_time_minutes': 700.8358468833334, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 11377056, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 40 received finish message =================
2025-10-10 16:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:38 (federatedscope.core.monitors.monitor:268) INFO: In worker #40, the system-related metrics are: {'id': 40, 'fl_end_time_minutes': 700.7943263, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 10665992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:38 (federatedscope.core.workers.client:842) INFO: ================= client 41 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #41, the system-related metrics are: {'id': 41, 'fl_end_time_minutes': 700.7357644333333, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12088120, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 42 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #42, the system-related metrics are: {'id': 42, 'fl_end_time_minutes': 700.6942781500001, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15643440, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 43 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #43, the system-related metrics are: {'id': 43, 'fl_end_time_minutes': 700.6542330666667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15643440, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 44 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #44, the system-related metrics are: {'id': 44, 'fl_end_time_minutes': 700.6098067166666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 10665992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 45 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #45, the system-related metrics are: {'id': 45, 'fl_end_time_minutes': 700.5663826166667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18487696, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 46 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #46, the system-related metrics are: {'id': 46, 'fl_end_time_minutes': 700.5249333166666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14932376, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 47 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #47, the system-related metrics are: {'id': 47, 'fl_end_time_minutes': 700.4832492, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 48 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #48, the system-related metrics are: {'id': 48, 'fl_end_time_minutes': 700.4415739, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12799184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 49 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #49, the system-related metrics are: {'id': 49, 'fl_end_time_minutes': 700.39997835, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14221312, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 50 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #50, the system-related metrics are: {'id': 50, 'fl_end_time_minutes': 700.3586465999999, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15643440, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 51 received finish message =================
2025-10-10 16:01:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:39 (federatedscope.core.monitors.monitor:268) INFO: In worker #51, the system-related metrics are: {'id': 51, 'fl_end_time_minutes': 700.3172533666667, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:39 (federatedscope.core.workers.client:842) INFO: ================= client 52 received finish message =================
2025-10-10 16:01:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:40 (federatedscope.core.monitors.monitor:268) INFO: In worker #52, the system-related metrics are: {'id': 52, 'fl_end_time_minutes': 700.2759862, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13510248, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:40 (federatedscope.core.workers.client:842) INFO: ================= client 53 received finish message =================
2025-10-10 16:01:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2016 skipped=0 missing=291 unexpected=0
2025-10-10 16:01:40 (federatedscope.core.monitors.monitor:268) INFO: In worker #53, the system-related metrics are: {'id': 53, 'fl_end_time_minutes': 700.2341796666666, 'total_model_size': 520167552, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 9243864, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 16:01:40 (federatedscope.core.monitors.monitor:359) INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 701.3690900635803, 'sys_avg/total_model_size': '486.88M', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '0.0', 'sys_avg/total_download_bytes': '12.71M', 'sys_avg/global_convergence_round': 0.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 0.0, 'sys_avg/local_convergence_time_minutes': 0.0})
2025-10-10 16:01:40 (federatedscope.core.monitors.monitor:360) INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.672030478792388, 'sys_std/total_model_size': '66.88M', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '0.0', 'sys_std/total_download_bytes': '2.67M', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.0, 'sys_std/local_convergence_time_minutes': 0.0})
