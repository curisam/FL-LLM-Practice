{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d95d293",
   "metadata": {},
   "source": [
    "\n",
    "# Average multiple LoRA checkpoints (simple FedAvg)\n",
    "\n",
    "이 노트북은 디렉토리에 모아둔 **LoRA 전용 ckpt(state_dict)**들을 불러와 **단순 평균**(equal weight)한 뒤 `local_only_ensemble.ckpt`와 같은 하나의 파일로 저장합니다.\n",
    "\n",
    "## 사용 방법\n",
    "1. 아래 **설정(경로/패턴)** 셀에서 경로를 본인 환경에 맞게 수정합니다.  \n",
    "2. **실행** 셀을 실행하면, 평균 결과가 `out_path`에 저장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5dc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "\n",
    "def average_lora_ckpts(\n",
    "    in_dir: str,\n",
    "    out_path: str,\n",
    "    pattern: str = \"local_only_tldr_choice_qwen_client_*.ckpt\",\n",
    "    strict_keys: bool = False,\n",
    "    save_dtype = torch.float32,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    디렉토리(in_dir)에서 pattern에 매칭되는 ckpt들을 모두 불러와\n",
    "    공통 키의 float 텐서만 simple average하여 out_path로 저장합니다.\n",
    "\n",
    "    - strict_keys=False: 교집합 키만 평균 (누락/shape 불일치 키는 첫 ckpt 값 유지)\n",
    "    - strict_keys=True : 모든 파일이 동일한 키/shape를 가져야 함 (아니면 에러)\n",
    "\n",
    "    반환: 평균된 state_dict (메모리 상의 dict)\n",
    "    \"\"\"\n",
    "    in_dir = str(in_dir)\n",
    "    out_path = str(out_path)\n",
    "    paths = sorted(glob.glob(os.path.join(in_dir, pattern)))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No ckpt matches: {os.path.join(in_dir, pattern)}\")\n",
    "\n",
    "    # Load all state_dicts on CPU\n",
    "    state_dicts: List[Dict[str, torch.Tensor]] = []\n",
    "    for p in paths:\n",
    "        sd = torch.load(p, map_location=\"cpu\")\n",
    "        if not isinstance(sd, dict):\n",
    "            raise RuntimeError(f\"Checkpoint is not a state_dict: {p}\")\n",
    "        state_dicts.append(sd)\n",
    "\n",
    "    # Decide key set\n",
    "    if strict_keys:\n",
    "        # Intersection of keys across all checkpoints\n",
    "        key_set = set(state_dicts[0].keys())\n",
    "        for sd in state_dicts[1:]:\n",
    "            key_set &= set(sd.keys())\n",
    "        # Validate shapes for strict mode\n",
    "        for k in key_set:\n",
    "            shape0 = tuple(state_dicts[0][k].shape) if torch.is_tensor(state_dicts[0][k]) else None\n",
    "            for sd in state_dicts[1:]:\n",
    "                v = sd[k]\n",
    "                if not torch.is_tensor(v):\n",
    "                    raise RuntimeError(f\"Non-tensor value for key={k} in strict mode.\")\n",
    "                if tuple(v.shape) != shape0:\n",
    "                    raise RuntimeError(f\"Shape mismatch for key={k}: {shape0} vs {tuple(v.shape)}\")\n",
    "    else:\n",
    "        # Start from the first dict's keys; allow missing keys later\n",
    "        key_set = set(state_dicts[0].keys())\n",
    "\n",
    "    # Prepare output dict: start from first state_dict as base\n",
    "    out_sd: Dict[str, torch.Tensor] = {}\n",
    "    base = state_dicts[0]\n",
    "\n",
    "    # Build per-key accumulator\n",
    "    num_ckpts = len(state_dicts)\n",
    "    for k in key_set:\n",
    "        v0 = base.get(k, None)\n",
    "        if not torch.is_tensor(v0) or not v0.dtype.is_floating_point:\n",
    "            # Keep as-is (buffers / non-float) from base\n",
    "            if v0 is not None:\n",
    "                out_sd[k] = v0.clone()\n",
    "            continue\n",
    "\n",
    "        # Accumulate tensors that exist with same shape\n",
    "        acc = None\n",
    "        shape0 = tuple(v0.shape)\n",
    "        count = 0\n",
    "        for sd in state_dicts:\n",
    "            v = sd.get(k, None)\n",
    "            if v is None or (not torch.is_tensor(v)) or (tuple(v.shape) != shape0) or (not v.dtype.is_floating_point):\n",
    "                if strict_keys:\n",
    "                    raise RuntimeError(f\"Key {k} missing or shape/dtype mismatch in strict mode.\")\n",
    "                # skip in non-strict\n",
    "                continue\n",
    "            if acc is None:\n",
    "                acc = v.to(dtype=save_dtype, copy=True)\n",
    "            else:\n",
    "                acc.add_(v.to(dtype=save_dtype))\n",
    "            count += 1\n",
    "\n",
    "        if acc is None or count == 0:\n",
    "            # No valid contributors → keep base value\n",
    "            out_sd[k] = v0.to(dtype=save_dtype, copy=True)\n",
    "        else:\n",
    "            acc.div_(float(count))\n",
    "            out_sd[k] = acc\n",
    "\n",
    "    # If not strict, also copy over extra (non-intersection) keys from base that we didn't visit\n",
    "    if not strict_keys:\n",
    "        for k, v in base.items():\n",
    "            if k in out_sd:\n",
    "                continue\n",
    "            if torch.is_tensor(v) and v.dtype.is_floating_point:\n",
    "                out_sd[k] = v.to(dtype=save_dtype, copy=True)\n",
    "            else:\n",
    "                out_sd[k] = v\n",
    "\n",
    "    # Save\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(out_sd, out_path)\n",
    "    print(f\"[OK] Averaged {num_ckpts} ckpts → {out_path}\")\n",
    "    return out_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 설정(경로/패턴) ===\n",
    "in_dir   = \"./checkpoints_1.0_local_only_official/official/\"   # LoRA ckpt 저장 폴더\n",
    "pattern  = \"local_only_tldr_choice_qwen_client_*.ckpt\"  # 파일 패턴\n",
    "out_path = \"./checkpoints_1.0_local_only_official/local_only_ensemble_official.ckpt\"     # 결과 저장 경로\n",
    "\n",
    "# strict_keys=True 로 두면 키/shape가 전부 동일해야만 동작 (안전하지만 빡셈)\n",
    "strict_keys = False\n",
    "save_dtype  = None  # 예: torch.float32 로 강제 변환하고 싶다면 torch.float32 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8196abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Averaged 53 ckpts → ./checkpoints_1.0_local_only_officia/local_only_ensemble_official.ckpt\n",
      "Averaged state_dict: tensors=336, total_params=4399104\n",
      "Saved to: ./checkpoints_1.0_local_only_officia/local_only_ensemble_official.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 실행 ===\n",
    "import torch\n",
    "\n",
    "sd = average_lora_ckpts(\n",
    "    in_dir=in_dir,\n",
    "    out_path=out_path,\n",
    "    pattern=pattern,\n",
    "    strict_keys=strict_keys,\n",
    "    save_dtype=(save_dtype if save_dtype is not None else torch.float32),\n",
    ")\n",
    "\n",
    "# 간단한 요약 출력\n",
    "num_params = sum(p.numel() for p in sd.values() if torch.is_tensor(p))\n",
    "num_tensors = sum(1 for p in sd.values() if torch.is_tensor(p))\n",
    "print(f\"Averaged state_dict: tensors={num_tensors}, total_params={num_params}\")\n",
    "print(f\"Saved to: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedfn",
   "language": "python",
   "name": "fedfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
